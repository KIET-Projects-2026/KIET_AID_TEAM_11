2026-01-03 11:51:24,684 - app - INFO - Configuration loaded: Config
2026-01-03 11:51:24,684 - app - INFO - CORS enabled
2026-01-03 11:51:24,684 - app - INFO - JWT initialized
2026-01-03 11:51:24,690 - app - INFO - Blueprints registered
2026-01-03 11:51:35,230 - __main__ - INFO - Configuration loaded: Config
2026-01-03 11:51:35,231 - __main__ - INFO - CORS enabled
2026-01-03 11:51:35,231 - __main__ - INFO - JWT initialized
2026-01-03 11:51:35,235 - __main__ - INFO - Blueprints registered
2026-01-03 11:51:35,236 - __main__ - INFO - ============================================================
2026-01-03 11:51:35,236 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 11:51:35,236 - __main__ - INFO - ============================================================
2026-01-03 11:51:35,237 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 11:51:35,238 - __main__ - INFO - Port: 5000
2026-01-03 11:51:35,238 - __main__ - INFO - Debug: True
2026-01-03 11:51:35,238 - __main__ - INFO - ============================================================
2026-01-03 11:51:35,337 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 11:51:35,337 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 11:51:35,431 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 11:51:35,862 - __main__ - INFO - Configuration loaded: Config
2026-01-03 11:51:35,862 - __main__ - INFO - CORS enabled
2026-01-03 11:51:35,862 - __main__ - INFO - JWT initialized
2026-01-03 11:51:35,864 - __main__ - INFO - Blueprints registered
2026-01-03 11:51:35,865 - __main__ - INFO - ============================================================
2026-01-03 11:51:35,866 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 11:51:35,866 - __main__ - INFO - ============================================================
2026-01-03 11:51:35,866 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 11:51:35,866 - __main__ - INFO - Port: 5000
2026-01-03 11:51:35,866 - __main__ - INFO - Debug: True
2026-01-03 11:51:35,866 - __main__ - INFO - ============================================================
2026-01-03 11:51:35,873 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 11:51:35,877 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 11:51:53,996 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:51:53] "OPTIONS /auth/register HTTP/1.1" 200 -
2026-01-03 11:51:54,245 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:51:54] "[31m[1mPOST /auth/register HTTP/1.1[0m" 400 -
2026-01-03 11:51:56,426 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:51:56] "[31m[1mPOST /auth/register HTTP/1.1[0m" 400 -
2026-01-03 11:57:52,083 - __main__ - INFO - Configuration loaded: Config
2026-01-03 11:57:52,084 - __main__ - INFO - CORS enabled
2026-01-03 11:57:52,085 - __main__ - INFO - JWT initialized
2026-01-03 11:57:52,089 - __main__ - INFO - Blueprints registered
2026-01-03 11:57:52,091 - __main__ - INFO - ============================================================
2026-01-03 11:57:52,091 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 11:57:52,092 - __main__ - INFO - ============================================================
2026-01-03 11:57:52,092 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 11:57:52,092 - __main__ - INFO - Port: 5000
2026-01-03 11:57:52,092 - __main__ - INFO - Debug: True
2026-01-03 11:57:52,092 - __main__ - INFO - ============================================================
2026-01-03 11:57:52,172 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 11:57:52,172 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 11:57:52,181 - werkzeug - INFO -  * Restarting with stat
2026-01-03 11:57:52,695 - __main__ - INFO - Configuration loaded: Config
2026-01-03 11:57:52,696 - __main__ - INFO - CORS enabled
2026-01-03 11:57:52,696 - __main__ - INFO - JWT initialized
2026-01-03 11:57:52,701 - __main__ - INFO - Blueprints registered
2026-01-03 11:57:52,702 - __main__ - INFO - ============================================================
2026-01-03 11:57:52,702 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 11:57:52,703 - __main__ - INFO - ============================================================
2026-01-03 11:57:52,703 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 11:57:52,703 - __main__ - INFO - Port: 5000
2026-01-03 11:57:52,703 - __main__ - INFO - Debug: True
2026-01-03 11:57:52,703 - __main__ - INFO - ============================================================
2026-01-03 11:57:52,717 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 11:57:52,720 - werkzeug - INFO -  * Debugger PIN: 698-641-950
2026-01-03 11:58:33,104 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:58:33] "[31m[1mPOST /auth/register HTTP/1.1[0m" 409 -
2026-01-03 11:58:41,116 - routes.auth_routes - INFO - New user registered: prasad879023@gmail.com
2026-01-03 11:58:41,127 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:58:41] "[35m[1mPOST /auth/register HTTP/1.1[0m" 201 -
2026-01-03 11:59:00,686 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:00] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-03 11:59:01,217 - routes.auth_routes - INFO - User logged in: prasad879023@gmail.com
2026-01-03 11:59:01,218 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 11:59:01,279 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "OPTIONS /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 11:59:01,584 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "OPTIONS /chat/history HTTP/1.1" 200 -
2026-01-03 11:59:01,586 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "OPTIONS /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 11:59:01,593 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "OPTIONS /chat/history HTTP/1.1" 200 -
2026-01-03 11:59:01,641 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 11:59:01,911 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 11:59:01,985 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:01] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 11:59:02,223 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:02] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 11:59:13,374 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:13] "OPTIONS /chat/ask HTTP/1.1" 200 -
2026-01-03 11:59:13,674 - routes.chat_routes - INFO - Created new chat for user 6958b719a2b8fbfb92700ac3
2026-01-03 11:59:18,035 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 11:59:18,653 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 11:59:52,786 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:52] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 11:59:53,095 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:53] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 11:59:53,102 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:53] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 11:59:53,426 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 11:59:53] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:00:10,247 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:00:10] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:00:10,583 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:00:10] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:00:10,621 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:00:10] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:00:10,900 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:00:10] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:00:40,082 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:00:40,083 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:00:40,257 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 12:00:40,257 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:00:40,257 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 12:00:40,258 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:01:12,591 - routes.chat_routes - INFO - Answer generated for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:01:12,593 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:01:12] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:01:14,922 - routes.chat_routes - INFO - Answer generated for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:01:14,923 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:01:14] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:02:35,879 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:02:35] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:02:35,906 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:02:35] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:02:36,139 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:02:36] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:02:36,201 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:02:36] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:02:53,304 - routes.chat_routes - INFO - Created new chat for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:02:58,970 - routes.chat_routes - INFO - Answer generated for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:02:58,971 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:02:58] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:03:24,138 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:03:24] "GET /health HTTP/1.1" 200 -
2026-01-03 12:03:35,766 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:03:35,767 - __main__ - INFO - CORS enabled
2026-01-03 12:03:35,767 - __main__ - INFO - JWT initialized
2026-01-03 12:03:35,769 - __main__ - INFO - Blueprints registered
2026-01-03 12:03:35,770 - __main__ - INFO - ============================================================
2026-01-03 12:03:35,770 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:03:35,770 - __main__ - INFO - ============================================================
2026-01-03 12:03:35,771 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:03:35,771 - __main__ - INFO - Port: 5000
2026-01-03 12:03:35,771 - __main__ - INFO - Debug: True
2026-01-03 12:03:35,772 - __main__ - INFO - ============================================================
2026-01-03 12:03:35,794 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 12:03:35,795 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 12:03:35,813 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:03:36,227 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:03:36,228 - __main__ - INFO - CORS enabled
2026-01-03 12:03:36,228 - __main__ - INFO - JWT initialized
2026-01-03 12:03:36,230 - __main__ - INFO - Blueprints registered
2026-01-03 12:03:36,231 - __main__ - INFO - ============================================================
2026-01-03 12:03:36,231 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:03:36,231 - __main__ - INFO - ============================================================
2026-01-03 12:03:36,231 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:03:36,231 - __main__ - INFO - Port: 5000
2026-01-03 12:03:36,232 - __main__ - INFO - Debug: True
2026-01-03 12:03:36,232 - __main__ - INFO - ============================================================
2026-01-03 12:03:36,238 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:03:36,244 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:04:39,293 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 12:04:39,372 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 12:06:13,105 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-03 12:06:13,119 - datasets - INFO - Polars version 1.36.1 available.
2026-01-03 12:06:13,120 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-03 12:06:16,817 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:16] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:06:16,823 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:16] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:06:17,080 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:17] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:06:17,127 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:17] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:06:21,665 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:21] "OPTIONS /chat/clear HTTP/1.1" 200 -
2026-01-03 12:06:22,064 - routes.chat_routes - INFO - Chat cleared for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:06:22,072 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:22] "DELETE /chat/clear HTTP/1.1" 200 -
2026-01-03 12:06:30,913 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-03 12:06:37,916 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:06:37,928 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-03 12:06:37,932 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:06:39,806 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:06:39,815 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-03 12:06:39,815 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:06:49,007 - services.rag_service - WARNING - Weak context retrieved for query: why headace comes
2026-01-03 12:06:49,010 - routes.chat_routes - WARNING - No context found for question: why headace comes
2026-01-03 12:06:49,016 - routes.chat_routes - INFO - Answer generated for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:06:49,022 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:49] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:06:53,477 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 12:06:53,480 - services.rag_service - WARNING - ML models not loaded for context retrieval
2026-01-03 12:06:53,481 - routes.chat_routes - WARNING - No context found for question: What are the symptoms of diabetes?
2026-01-03 12:06:53,486 - routes.chat_routes - INFO - Answer generated for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:06:53,487 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:06:53] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:07:31,452 - services.rag_service - WARNING - Weak context retrieved for query: What is hypertension?
2026-01-03 12:07:31,452 - routes.chat_routes - WARNING - No context found for question: What is hypertension?
2026-01-03 12:07:31,454 - routes.chat_routes - INFO - Answer generated for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:07:31,454 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:07:31] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:08:21,422 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:21] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-03 12:08:21,905 - routes.auth_routes - INFO - User logged in: prasad879023@gmail.com
2026-01-03 12:08:21,906 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:21] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 12:08:21,952 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:21] "OPTIONS /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:08:22,263 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:22] "OPTIONS /chat/history HTTP/1.1" 200 -
2026-01-03 12:08:22,265 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:22] "OPTIONS /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:08:22,270 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:22] "OPTIONS /chat/history HTTP/1.1" 200 -
2026-01-03 12:08:22,281 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:22] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:08:22,593 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:22] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:08:22,597 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:22] "GET /chat/recent?limit=10 HTTP/1.1" 200 -
2026-01-03 12:08:22,906 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:22] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:08:42,799 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:42] "OPTIONS /chat/ask HTTP/1.1" 200 -
2026-01-03 12:08:43,067 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:08:43] "[31m[1mPOST /chat/ask HTTP/1.1[0m" 400 -
2026-01-03 12:09:27,720 - routes.chat_routes - INFO - Answer generated for user 6958b719a2b8fbfb92700ac3
2026-01-03 12:09:27,720 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:09:27] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:21:28,092 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:21:28,092 - __main__ - INFO - CORS enabled
2026-01-03 12:21:28,093 - __main__ - INFO - JWT initialized
2026-01-03 12:21:28,096 - __main__ - INFO - Blueprints registered
2026-01-03 12:21:28,097 - __main__ - INFO - ============================================================
2026-01-03 12:21:28,097 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:21:28,098 - __main__ - INFO - ============================================================
2026-01-03 12:21:28,098 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:21:28,098 - __main__ - INFO - Port: 5000
2026-01-03 12:21:28,098 - __main__ - INFO - Debug: True
2026-01-03 12:21:28,098 - __main__ - INFO - ============================================================
2026-01-03 12:21:28,118 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 12:21:28,118 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 12:21:28,133 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:21:28,619 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:21:28,620 - __main__ - INFO - CORS enabled
2026-01-03 12:21:28,620 - __main__ - INFO - JWT initialized
2026-01-03 12:21:28,627 - __main__ - INFO - Blueprints registered
2026-01-03 12:21:28,627 - __main__ - INFO - ============================================================
2026-01-03 12:21:28,628 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:21:28,628 - __main__ - INFO - ============================================================
2026-01-03 12:21:28,628 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:21:28,628 - __main__ - INFO - Port: 5000
2026-01-03 12:21:28,628 - __main__ - INFO - Debug: True
2026-01-03 12:21:28,628 - __main__ - INFO - ============================================================
2026-01-03 12:21:28,642 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:21:28,646 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:21:31,034 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:21:31] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-03 12:21:32,029 - routes.auth_routes - INFO - User logged in: prasad879023@gmail.com
2026-01-03 12:21:32,035 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:21:32] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 12:22:26,884 - routes.auth_routes - INFO - User logged in: prasad879023@gmail.com
2026-01-03 12:22:26,887 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:22:26] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 12:23:12,226 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 12:23:12,232 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:23:12,233 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 12:23:12,233 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\models\\chat_model.py', reloading
2026-01-03 12:23:12,234 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:23:12,234 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 12:23:12,235 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:23:12,235 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\models\\chat_model.py', reloading
2026-01-03 12:23:12,747 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:23:13,161 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:23:13,161 - __main__ - INFO - CORS enabled
2026-01-03 12:23:13,162 - __main__ - INFO - JWT initialized
2026-01-03 12:23:13,168 - __main__ - INFO - Blueprints registered
2026-01-03 12:23:13,169 - __main__ - INFO - ============================================================
2026-01-03 12:23:13,170 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:23:13,170 - __main__ - INFO - ============================================================
2026-01-03 12:23:13,170 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:23:13,170 - __main__ - INFO - Port: 5000
2026-01-03 12:23:13,171 - __main__ - INFO - Debug: True
2026-01-03 12:23:13,171 - __main__ - INFO - ============================================================
2026-01-03 12:23:13,182 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:23:13,186 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:24:39,776 - routes.auth_routes - INFO - New user registered: prasad8790237@gmail.com
2026-01-03 12:24:39,781 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:39] "[35m[1mPOST /auth/register HTTP/1.1[0m" 201 -
2026-01-03 12:24:46,594 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-03 12:24:46,594 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:46] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 12:24:46,952 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:46] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-03 12:24:46,955 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:46] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-03 12:24:46,960 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:46] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-03 12:24:46,973 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:46] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-03 12:24:47,216 - routes.chat_routes - INFO - Created new chat 54f340c3-2dfe-4b8a-9d74-7956ef662229 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:24:47,219 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:47] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:24:47,288 - routes.chat_routes - INFO - Created new chat 203340e0-2efb-4ff6-991b-f083b0211365 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:24:47,291 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:24:47,292 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:47] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:24:47,300 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:24:49,384 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:49] "OPTIONS /chat/history?chatId=54f340c3-2dfe-4b8a-9d74-7956ef662229 HTTP/1.1" 200 -
2026-01-03 12:24:49,656 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:49] "GET /chat/history?chatId=54f340c3-2dfe-4b8a-9d74-7956ef662229 HTTP/1.1" 200 -
2026-01-03 12:24:52,007 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:52] "OPTIONS /chat/delete/54f340c3-2dfe-4b8a-9d74-7956ef662229 HTTP/1.1" 200 -
2026-01-03 12:24:52,320 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:24:52,325 - routes.chat_routes - INFO - Deleted chat 54f340c3-2dfe-4b8a-9d74-7956ef662229 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:24:52,329 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:52] "DELETE /chat/delete/54f340c3-2dfe-4b8a-9d74-7956ef662229 HTTP/1.1" 200 -
2026-01-03 12:24:52,664 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:24:55,102 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:55] "OPTIONS /chat/delete/203340e0-2efb-4ff6-991b-f083b0211365 HTTP/1.1" 200 -
2026-01-03 12:24:55,421 - routes.chat_routes - INFO - Deleted chat 203340e0-2efb-4ff6-991b-f083b0211365 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:24:55,423 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:55] "DELETE /chat/delete/203340e0-2efb-4ff6-991b-f083b0211365 HTTP/1.1" 200 -
2026-01-03 12:24:55,685 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:55] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:24:56,653 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:24:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:00,849 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 12:25:00,879 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 12:25:01,690 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:06,973 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:12,318 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:12] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:16,833 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-03 12:25:16,835 - datasets - INFO - Polars version 1.36.1 available.
2026-01-03 12:25:16,836 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-03 12:25:17,274 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:17] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:22,013 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-03 12:25:22,280 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:22,419 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:25:22,421 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-03 12:25:22,422 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:25:27,270 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:29,361 - services.rag_service - WARNING - Weak context retrieved for query: What are the symptoms of diabetes?
2026-01-03 12:25:31,976 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:32,996 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:32] "OPTIONS /chat/history?chatId=3f94a1ac-30ea-4e96-9175-69c6a8281cca HTTP/1.1" 200 -
2026-01-03 12:25:33,309 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:33] "GET /chat/history?chatId=3f94a1ac-30ea-4e96-9175-69c6a8281cca HTTP/1.1" 200 -
2026-01-03 12:25:36,195 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:36] "OPTIONS /chat/delete/3f94a1ac-30ea-4e96-9175-69c6a8281cca HTTP/1.1" 200 -
2026-01-03 12:25:36,514 - routes.chat_routes - INFO - Deleted chat 3f94a1ac-30ea-4e96-9175-69c6a8281cca for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:25:36,516 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:36] "DELETE /chat/delete/3f94a1ac-30ea-4e96-9175-69c6a8281cca HTTP/1.1" 200 -
2026-01-03 12:25:36,779 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:36,841 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:41,946 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:46,957 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:49,120 - services.rag_service - WARNING - Weak context retrieved for query: What is hypertension?
2026-01-03 12:25:51,971 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:25:56,977 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:25:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:01,973 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:04,055 - routes.chat_routes - INFO - Answer generated for chat 3f94a1ac-30ea-4e96-9175-69c6a8281cca
2026-01-03 12:26:04,056 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:04] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:26:06,967 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:11,973 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:16,961 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:21,967 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:21] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:24,804 - routes.chat_routes - INFO - Answer generated for chat 59daa694-bb4e-4762-96e5-5aac1f5ffb3d
2026-01-03 12:26:24,804 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:24] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:26:26,651 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:31,967 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:36,947 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:42,254 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:46,953 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:52,252 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:26:56,945 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:26:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:02,256 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:02] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:06,940 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:12,251 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:12] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:13,482 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\config.py', reloading
2026-01-03 12:27:13,482 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\config.py', reloading
2026-01-03 12:27:16,033 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:27:16,542 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:27:16,543 - __main__ - INFO - CORS enabled
2026-01-03 12:27:16,543 - __main__ - INFO - JWT initialized
2026-01-03 12:27:16,548 - __main__ - INFO - Blueprints registered
2026-01-03 12:27:16,549 - __main__ - INFO - ============================================================
2026-01-03 12:27:16,549 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:27:16,549 - __main__ - INFO - ============================================================
2026-01-03 12:27:16,549 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:27:16,549 - __main__ - INFO - Port: 5000
2026-01-03 12:27:16,550 - __main__ - INFO - Debug: True
2026-01-03 12:27:16,550 - __main__ - INFO - ============================================================
2026-01-03 12:27:16,566 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:27:16,573 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:27:17,294 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:17] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:21,955 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:21] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:23,634 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\start_server.py', reloading
2026-01-03 12:27:24,210 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:27:24,615 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:27:24,615 - __main__ - INFO - CORS enabled
2026-01-03 12:27:24,616 - __main__ - INFO - JWT initialized
2026-01-03 12:27:24,620 - __main__ - INFO - Blueprints registered
2026-01-03 12:27:24,621 - __main__ - INFO - ============================================================
2026-01-03 12:27:24,621 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:27:24,621 - __main__ - INFO - ============================================================
2026-01-03 12:27:24,621 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:27:24,622 - __main__ - INFO - Port: 5000
2026-01-03 12:27:24,622 - __main__ - INFO - Debug: True
2026-01-03 12:27:24,622 - __main__ - INFO - ============================================================
2026-01-03 12:27:24,631 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:27:24,637 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:27:24,863 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\start_server.py', reloading
2026-01-03 12:27:24,863 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\start_server.py', reloading
2026-01-03 12:27:24,864 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\start_server.py', reloading
2026-01-03 12:27:26,226 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:27:26,574 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:27:26,575 - __main__ - INFO - CORS enabled
2026-01-03 12:27:26,575 - __main__ - INFO - JWT initialized
2026-01-03 12:27:26,577 - __main__ - INFO - Blueprints registered
2026-01-03 12:27:26,578 - __main__ - INFO - ============================================================
2026-01-03 12:27:26,578 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:27:26,578 - __main__ - INFO - ============================================================
2026-01-03 12:27:26,578 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:27:26,578 - __main__ - INFO - Port: 5000
2026-01-03 12:27:26,579 - __main__ - INFO - Debug: True
2026-01-03 12:27:26,579 - __main__ - INFO - ============================================================
2026-01-03 12:27:26,586 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:27:26,590 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:27:27,287 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:32,002 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:32] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:32,319 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:32] "OPTIONS /health HTTP/1.1" 200 -
2026-01-03 12:27:32,323 - routes.chat_routes - INFO - Created new chat 15e058ee-0355-47e9-98c8-82084999a5cc for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:27:32,324 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:32] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:27:32,645 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:32] "GET /health HTTP/1.1" 200 -
2026-01-03 12:27:37,960 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:37] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:43,245 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:47,941 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:53,248 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:27:56,457 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:56] "OPTIONS /chat/history?chatId=59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:27:56,777 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:56] "GET /chat/history?chatId=59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:27:57,037 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:27:57] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:01,995 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:07,301 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:07] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:10,003 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:10] "OPTIONS /chat/history?chatId=15e058ee-0355-47e9-98c8-82084999a5cc HTTP/1.1" 200 -
2026-01-03 12:28:10,327 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:10] "GET /chat/history?chatId=15e058ee-0355-47e9-98c8-82084999a5cc HTTP/1.1" 200 -
2026-01-03 12:28:10,909 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:10] "GET /chat/history?chatId=59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:28:12,155 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:12] "GET /chat/history?chatId=59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:28:12,295 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:12] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:13,206 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:13] "GET /chat/history?chatId=15e058ee-0355-47e9-98c8-82084999a5cc HTTP/1.1" 200 -
2026-01-03 12:28:16,122 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:16] "GET /chat/history?chatId=59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:28:16,995 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:19,176 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:19] "GET /chat/history?chatId=59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:28:20,341 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:20] "GET /chat/history?chatId=59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:28:23,047 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:23] "OPTIONS /chat/delete/59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:28:23,065 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:23] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:23,297 - routes.chat_routes - INFO - Deleted chat 59daa694-bb4e-4762-96e5-5aac1f5ffb3d for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:28:23,298 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:23] "DELETE /chat/delete/59daa694-bb4e-4762-96e5-5aac1f5ffb3d HTTP/1.1" 200 -
2026-01-03 12:28:23,367 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:23] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:23,978 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:23] "GET /chat/history?chatId=15e058ee-0355-47e9-98c8-82084999a5cc HTTP/1.1" 200 -
2026-01-03 12:28:27,287 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:27,446 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 12:28:27,485 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 12:28:32,001 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:32] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:37,319 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:37] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:42,311 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:46,068 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-03 12:28:46,075 - datasets - INFO - Polars version 1.36.1 available.
2026-01-03 12:28:46,077 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-03 12:28:47,308 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:52,322 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:28:55,601 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-03 12:28:55,984 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:28:55,987 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-03 12:28:55,987 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:28:58,273 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:28:58] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:03,269 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:03] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:04,439 - services.rag_service - WARNING - Weak context retrieved for query: How to treat a fever?
2026-01-03 12:29:08,273 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:08] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:13,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:17,297 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:17] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:22,303 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:27,308 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:31,649 - routes.chat_routes - INFO - Answer generated for chat 15e058ee-0355-47e9-98c8-82084999a5cc
2026-01-03 12:29:31,650 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:31] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:29:32,000 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:32] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:38,263 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:38] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:42,000 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:43,242 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:43,248 - routes.chat_routes - INFO - Created new chat 8a8053ba-7fc5-405c-9b7b-fd3209b404ea for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:29:43,249 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:43] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:29:43,260 - routes.chat_routes - INFO - Created new chat 188159c4-91ea-4529-9ee8-2c99904f143d for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:29:43,266 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:43] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:29:43,264 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:43] "GET /health HTTP/1.1" 200 -
2026-01-03 12:29:43,509 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:43,569 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:43] "GET /health HTTP/1.1" 200 -
2026-01-03 12:29:45,573 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:45] "GET /chat/history?chatId=15e058ee-0355-47e9-98c8-82084999a5cc HTTP/1.1" 200 -
2026-01-03 12:29:48,255 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:48] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:51,026 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:51] "OPTIONS /chat/delete/188159c4-91ea-4529-9ee8-2c99904f143d HTTP/1.1" 200 -
2026-01-03 12:29:51,345 - routes.chat_routes - INFO - Deleted chat 188159c4-91ea-4529-9ee8-2c99904f143d for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:29:51,347 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:51] "DELETE /chat/delete/188159c4-91ea-4529-9ee8-2c99904f143d HTTP/1.1" 200 -
2026-01-03 12:29:51,604 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:53,613 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:53] "OPTIONS /chat/delete/8a8053ba-7fc5-405c-9b7b-fd3209b404ea HTTP/1.1" 200 -
2026-01-03 12:29:53,936 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:53,941 - routes.chat_routes - INFO - Deleted chat 8a8053ba-7fc5-405c-9b7b-fd3209b404ea for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:29:53,943 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:53] "DELETE /chat/delete/8a8053ba-7fc5-405c-9b7b-fd3209b404ea HTTP/1.1" 200 -
2026-01-03 12:29:54,275 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:56,190 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:56] "OPTIONS /chat/delete/15e058ee-0355-47e9-98c8-82084999a5cc HTTP/1.1" 200 -
2026-01-03 12:29:56,510 - routes.chat_routes - INFO - Deleted chat 15e058ee-0355-47e9-98c8-82084999a5cc for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:29:56,513 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:56] "DELETE /chat/delete/15e058ee-0355-47e9-98c8-82084999a5cc HTTP/1.1" 200 -
2026-01-03 12:29:56,778 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:29:58,956 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:29:58] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:04,253 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:04] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:08,951 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:08] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:13,260 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:18,952 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:18] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:24,259 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:24] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:28,952 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:28] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:34,259 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:34] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:38,951 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:38] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:44,253 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:44] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:48,953 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:48] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:30:54,253 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:30:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:31:05,041 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:31:05,041 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:31:07,911 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:31:08,388 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:31:08,388 - __main__ - INFO - CORS enabled
2026-01-03 12:31:08,388 - __main__ - INFO - JWT initialized
2026-01-03 12:31:08,392 - __main__ - INFO - Blueprints registered
2026-01-03 12:31:08,393 - __main__ - INFO - ============================================================
2026-01-03 12:31:08,393 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:31:08,393 - __main__ - INFO - ============================================================
2026-01-03 12:31:08,393 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:31:08,393 - __main__ - INFO - Port: 5000
2026-01-03 12:31:08,393 - __main__ - INFO - Debug: True
2026-01-03 12:31:08,393 - __main__ - INFO - ============================================================
2026-01-03 12:31:08,402 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:31:08,406 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:31:12,975 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:31:12,975 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:31:14,069 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:31:14,489 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:31:14,489 - __main__ - INFO - CORS enabled
2026-01-03 12:31:14,490 - __main__ - INFO - JWT initialized
2026-01-03 12:31:14,497 - __main__ - INFO - Blueprints registered
2026-01-03 12:31:14,498 - __main__ - INFO - ============================================================
2026-01-03 12:31:14,498 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:31:14,499 - __main__ - INFO - ============================================================
2026-01-03 12:31:14,499 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:31:14,500 - __main__ - INFO - Port: 5000
2026-01-03 12:31:14,500 - __main__ - INFO - Debug: True
2026-01-03 12:31:14,500 - __main__ - INFO - ============================================================
2026-01-03 12:31:14,512 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:31:14,524 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:31:22,615 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:31:22,615 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:31:23,128 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:31:23,561 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:31:23,563 - __main__ - INFO - CORS enabled
2026-01-03 12:31:23,564 - __main__ - INFO - JWT initialized
2026-01-03 12:31:23,573 - __main__ - INFO - Blueprints registered
2026-01-03 12:31:23,575 - __main__ - INFO - ============================================================
2026-01-03 12:31:23,575 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:31:23,575 - __main__ - INFO - ============================================================
2026-01-03 12:31:23,575 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:31:23,576 - __main__ - INFO - Port: 5000
2026-01-03 12:31:23,576 - __main__ - INFO - Debug: True
2026-01-03 12:31:23,576 - __main__ - INFO - ============================================================
2026-01-03 12:31:23,591 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:31:23,596 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:31:30,342 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\verify_gpu.py', reloading
2026-01-03 12:31:31,140 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:31:31,583 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:31:31,583 - __main__ - INFO - CORS enabled
2026-01-03 12:31:31,583 - __main__ - INFO - JWT initialized
2026-01-03 12:31:31,588 - __main__ - INFO - Blueprints registered
2026-01-03 12:31:31,589 - __main__ - INFO - ============================================================
2026-01-03 12:31:31,589 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:31:31,589 - __main__ - INFO - ============================================================
2026-01-03 12:31:31,590 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:31:31,590 - __main__ - INFO - Port: 5000
2026-01-03 12:31:31,590 - __main__ - INFO - Debug: True
2026-01-03 12:31:31,590 - __main__ - INFO - ============================================================
2026-01-03 12:31:31,599 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:31:31,604 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:31:31,702 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\verify_gpu.py', reloading
2026-01-03 12:31:31,703 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\verify_gpu.py', reloading
2026-01-03 12:31:31,703 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\verify_gpu.py', reloading
2026-01-03 12:31:33,175 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:31:33,555 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:31:33,555 - __main__ - INFO - CORS enabled
2026-01-03 12:31:33,555 - __main__ - INFO - JWT initialized
2026-01-03 12:31:33,559 - __main__ - INFO - Blueprints registered
2026-01-03 12:31:33,559 - __main__ - INFO - ============================================================
2026-01-03 12:31:33,560 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:31:33,560 - __main__ - INFO - ============================================================
2026-01-03 12:31:33,560 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:31:33,560 - __main__ - INFO - Port: 5000
2026-01-03 12:31:33,560 - __main__ - INFO - Debug: True
2026-01-03 12:31:33,561 - __main__ - INFO - ============================================================
2026-01-03 12:31:33,568 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:31:33,573 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:31:39,282 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:31:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:32:10,070 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:32:10] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:32:13,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:32:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:32:18,968 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:32:18] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:32:24,254 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:32:24] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:32:28,946 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:32:28] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:32:33,928 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:32:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:28,219 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-03 12:33:28,220 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:28] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 12:33:28,555 - routes.chat_routes - INFO - Created new chat 8ff40b9e-0d3b-4c79-a4b2-296dbc6c3ff8 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:33:28,556 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:28] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:33:28,557 - routes.chat_routes - INFO - Created new chat 446b313b-9340-4aa1-8fc1-e5d6be6920c2 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:33:28,558 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:28] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:33:28,560 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:28] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:28,821 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:28] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:33,955 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:39,255 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:43,943 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:49,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:49] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:53,949 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:33:59,252 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:33:59] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:03,954 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:03] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:09,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:09] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:13,946 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:20,291 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:20] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:20,291 - routes.chat_routes - INFO - Created new chat fe1e557c-8401-41f4-9aaa-0fb85dac2dea for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:34:20,293 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:20] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:34:20,298 - routes.chat_routes - INFO - Created new chat f62b1c74-f02c-4123-84a2-567042e17cd5 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:34:20,299 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:20] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:34:20,550 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:20] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:25,947 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:25] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:31,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:35,959 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:35] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:41,264 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:45,963 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:45] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:51,256 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:34:55,942 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:34:55] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:35:01,266 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:35:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:35:05,943 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:35:05] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:35:11,266 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:35:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:35:15,954 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:35:15] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:35:39,251 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:35:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:11,348 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:15,278 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:15] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:20,543 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:20] "OPTIONS /chat/delete/f62b1c74-f02c-4123-84a2-567042e17cd5 HTTP/1.1" 200 -
2026-01-03 12:36:20,859 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:20] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:20,859 - routes.chat_routes - INFO - Deleted chat f62b1c74-f02c-4123-84a2-567042e17cd5 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:36:20,860 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:20] "DELETE /chat/delete/f62b1c74-f02c-4123-84a2-567042e17cd5 HTTP/1.1" 200 -
2026-01-03 12:36:21,210 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:21] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:23,137 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:23] "OPTIONS /chat/delete/fe1e557c-8401-41f4-9aaa-0fb85dac2dea HTTP/1.1" 200 -
2026-01-03 12:36:23,445 - routes.chat_routes - INFO - Deleted chat fe1e557c-8401-41f4-9aaa-0fb85dac2dea for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:36:23,446 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:23] "DELETE /chat/delete/fe1e557c-8401-41f4-9aaa-0fb85dac2dea HTTP/1.1" 200 -
2026-01-03 12:36:23,706 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:23] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:25,803 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:25] "OPTIONS /chat/delete/446b313b-9340-4aa1-8fc1-e5d6be6920c2 HTTP/1.1" 200 -
2026-01-03 12:36:26,120 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:26,120 - routes.chat_routes - INFO - Deleted chat 446b313b-9340-4aa1-8fc1-e5d6be6920c2 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:36:26,121 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:26] "DELETE /chat/delete/446b313b-9340-4aa1-8fc1-e5d6be6920c2 HTTP/1.1" 200 -
2026-01-03 12:36:26,445 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:28,786 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:28] "OPTIONS /chat/delete/8ff40b9e-0d3b-4c79-a4b2-296dbc6c3ff8 HTTP/1.1" 200 -
2026-01-03 12:36:29,096 - routes.chat_routes - INFO - Deleted chat 8ff40b9e-0d3b-4c79-a4b2-296dbc6c3ff8 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:36:29,097 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:29] "DELETE /chat/delete/8ff40b9e-0d3b-4c79-a4b2-296dbc6c3ff8 HTTP/1.1" 200 -
2026-01-03 12:36:29,384 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:29,971 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:35,678 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:35] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:39,975 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:41,510 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 12:36:41,583 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 12:36:45,948 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:45] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:51,259 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:53,113 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-03 12:36:53,115 - datasets - INFO - Polars version 1.36.1 available.
2026-01-03 12:36:53,116 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-03 12:36:56,307 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:36:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:36:56,873 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-03 12:36:57,245 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:36:57,251 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-03 12:36:57,251 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:37:01,254 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:04,799 - services.rag_service - WARNING - Weak context retrieved for query: What are the symptoms of diabetes?
2026-01-03 12:37:06,262 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:10,285 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:10] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:15,293 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:15] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:20,290 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:20] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:25,284 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:25] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:30,491 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:35,293 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:35] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:40,287 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:40] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:41,586 - routes.chat_routes - INFO - Answer generated for chat 8018e4f3-3e60-49a7-bcba-8230d681e14b
2026-01-03 12:37:41,587 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:41] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:37:46,253 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:50,935 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:50] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:37:56,266 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:37:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:00,946 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:00] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:06,254 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:10,957 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:10] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:16,255 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:20,951 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:20] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:26,264 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:30,958 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:36,254 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:38:40,948 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:38:40] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:39:39,263 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:39:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:40:38,959 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:40:38] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:41:39,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:41:46,283 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:41:49,656 - routes.chat_routes - INFO - Created new chat b6f5a850-bd14-4275-84e9-12635022474a for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:41:49,660 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:49] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:41:49,661 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:49] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:41:49,661 - routes.chat_routes - INFO - Created new chat 1e85b7a0-f8aa-4730-a1e7-36eb364cdf5c for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:41:49,664 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:49] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:41:49,907 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:49] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:41:51,607 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:51] "OPTIONS /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 12:41:51,926 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:51] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 12:41:54,351 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:41:59,657 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:41:59] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:04,949 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:04] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:10,257 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:10] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:14,951 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:20,260 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:20] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:24,947 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:24] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:30,262 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:34,945 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:34] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:40,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:40] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:44,950 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:44] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:50,254 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:50] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:42:54,939 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:42:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:43:00,260 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:43:00] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:43:39,263 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:43:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:43:40,448 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 12:43:40,448 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 12:43:42,650 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:43:45,318 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:43:45,318 - __main__ - INFO - CORS enabled
2026-01-03 12:43:45,319 - __main__ - INFO - JWT initialized
2026-01-03 12:43:45,324 - __main__ - INFO - Blueprints registered
2026-01-03 12:43:45,324 - __main__ - INFO - ============================================================
2026-01-03 12:43:45,324 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:43:45,325 - __main__ - INFO - ============================================================
2026-01-03 12:43:45,325 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:43:45,325 - __main__ - INFO - Port: 5000
2026-01-03 12:43:45,325 - __main__ - INFO - Debug: True
2026-01-03 12:43:45,325 - __main__ - INFO - ============================================================
2026-01-03 12:43:45,384 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:43:45,389 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:43:54,662 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:43:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:43:58,673 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:43:58] "OPTIONS /chat/delete/1e85b7a0-f8aa-4730-a1e7-36eb364cdf5c HTTP/1.1" 200 -
2026-01-03 12:43:58,996 - routes.chat_routes - INFO - Deleted chat 1e85b7a0-f8aa-4730-a1e7-36eb364cdf5c for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:43:58,998 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:43:58] "DELETE /chat/delete/1e85b7a0-f8aa-4730-a1e7-36eb364cdf5c HTTP/1.1" 200 -
2026-01-03 12:43:59,266 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:43:59] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:43:59,347 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:43:59] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:01,401 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:01] "OPTIONS /chat/delete/b6f5a850-bd14-4275-84e9-12635022474a HTTP/1.1" 200 -
2026-01-03 12:44:01,652 - routes.chat_routes - INFO - Deleted chat b6f5a850-bd14-4275-84e9-12635022474a for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:44:01,653 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:01] "DELETE /chat/delete/b6f5a850-bd14-4275-84e9-12635022474a HTTP/1.1" 200 -
2026-01-03 12:44:01,716 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:03,072 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:03] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 12:44:04,655 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:04] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:05,551 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:05] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:44:06,171 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:09,354 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:09] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:11,507 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:11,527 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:11] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:44:11,544 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:11] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:44:11,738 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:16,954 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:21,489 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:21] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:26,189 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:32,256 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:32] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:36,484 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:37,650 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 12:44:37,694 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 12:44:41,485 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:47,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:52,479 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:52] "OPTIONS /chat/delete/28e30145-c67d-4c22-a28b-ca8110afd807 HTTP/1.1" 200 -
2026-01-03 12:44:52,484 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:52,790 - routes.chat_routes - INFO - Deleted chat 28e30145-c67d-4c22-a28b-ca8110afd807 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:44:52,792 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:52] "DELETE /chat/delete/28e30145-c67d-4c22-a28b-ca8110afd807 HTTP/1.1" 200 -
2026-01-03 12:44:53,101 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:55,179 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:55] "OPTIONS /chat/delete/09bad5da-8f6c-40ce-9c76-2c706c9f34a3 HTTP/1.1" 200 -
2026-01-03 12:44:55,495 - routes.chat_routes - INFO - Deleted chat 09bad5da-8f6c-40ce-9c76-2c706c9f34a3 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:44:55,496 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:55] "DELETE /chat/delete/09bad5da-8f6c-40ce-9c76-2c706c9f34a3 HTTP/1.1" 200 -
2026-01-03 12:44:55,812 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:55] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:56,486 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:44:58,948 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:58] "OPTIONS /chat/delete/909a941a-53ea-4f3f-b1c0-92abfcaa4080 HTTP/1.1" 200 -
2026-01-03 12:44:59,259 - routes.chat_routes - INFO - Deleted chat 909a941a-53ea-4f3f-b1c0-92abfcaa4080 for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:44:59,260 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:59] "DELETE /chat/delete/909a941a-53ea-4f3f-b1c0-92abfcaa4080 HTTP/1.1" 200 -
2026-01-03 12:44:59,574 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:44:59] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:01,563 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:02,733 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-03 12:45:02,737 - datasets - INFO - Polars version 1.36.1 available.
2026-01-03 12:45:02,739 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-03 12:45:06,521 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:11,009 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-03 12:45:11,487 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:11,764 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:45:11,792 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-03 12:45:11,797 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:45:16,515 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:19,055 - services.rag_service - WARNING - Weak context retrieved for query: How to treat a fever?
2026-01-03 12:45:21,498 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:21] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:26,484 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:31,479 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:36,494 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:41,174 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:46,489 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:48,477 - routes.chat_routes - INFO - Answer generated for chat 28e30145-c67d-4c22-a28b-ca8110afd807
2026-01-03 12:45:48,477 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:48] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:45:51,183 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:53,679 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:53,719 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:53] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:45:53,736 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:53] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:45:53,929 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:58,240 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:58] "OPTIONS /chat/delete/d03290bd-4a86-4ec8-852c-e1704db625bd HTTP/1.1" 200 -
2026-01-03 12:45:58,570 - routes.chat_routes - INFO - Deleted chat d03290bd-4a86-4ec8-852c-e1704db625bd for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:45:58,573 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:58] "DELETE /chat/delete/d03290bd-4a86-4ec8-852c-e1704db625bd HTTP/1.1" 200 -
2026-01-03 12:45:58,682 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:58] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:45:58,822 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:45:58] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:01,162 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:01] "OPTIONS /chat/delete/254c6def-5544-4140-ab0b-c2ceae7ffd7b HTTP/1.1" 200 -
2026-01-03 12:46:01,485 - routes.chat_routes - INFO - Deleted chat 254c6def-5544-4140-ab0b-c2ceae7ffd7b for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:46:01,487 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:01] "DELETE /chat/delete/254c6def-5544-4140-ab0b-c2ceae7ffd7b HTTP/1.1" 200 -
2026-01-03 12:46:01,739 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:03,362 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:03] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:09,255 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:09] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:13,946 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:19,265 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:19] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:21,673 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:46:21,675 - __main__ - INFO - CORS enabled
2026-01-03 12:46:21,675 - __main__ - INFO - JWT initialized
2026-01-03 12:46:21,685 - __main__ - INFO - Blueprints registered
2026-01-03 12:46:21,685 - __main__ - INFO - ============================================================
2026-01-03 12:46:21,685 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:46:21,685 - __main__ - INFO - ============================================================
2026-01-03 12:46:21,685 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:46:21,685 - __main__ - INFO - Port: 5000
2026-01-03 12:46:21,685 - __main__ - INFO - Debug: True
2026-01-03 12:46:21,685 - __main__ - INFO - ============================================================
2026-01-03 12:46:21,704 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 12:46:21,705 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 12:46:21,715 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:46:22,137 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:46:22,137 - __main__ - INFO - CORS enabled
2026-01-03 12:46:22,137 - __main__ - INFO - JWT initialized
2026-01-03 12:46:22,141 - __main__ - INFO - Blueprints registered
2026-01-03 12:46:22,141 - __main__ - INFO - ============================================================
2026-01-03 12:46:22,141 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:46:22,141 - __main__ - INFO - ============================================================
2026-01-03 12:46:22,142 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:46:22,142 - __main__ - INFO - Port: 5000
2026-01-03 12:46:22,142 - __main__ - INFO - Debug: True
2026-01-03 12:46:22,142 - __main__ - INFO - ============================================================
2026-01-03 12:46:22,150 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:46:22,154 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:46:23,952 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:23] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:30,598 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:30] "GET /chat/history HTTP/1.1" 200 -
2026-01-03 12:46:33,943 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:38,186 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:38] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 12:46:38,444 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:38] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:43,359 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:48,687 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:48] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:53,370 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:46:58,682 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:46:58] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:03,374 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:03] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:08,684 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:08] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:11,006 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 12:47:11,038 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 12:47:13,676 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:19,244 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:19] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:21,049 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-03 12:47:21,051 - datasets - INFO - Polars version 1.36.1 available.
2026-01-03 12:47:21,052 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-03 12:47:23,701 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:23] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:26,668 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-03 12:47:27,028 - services.rag_service - INFO - Loading ML models...
2026-01-03 12:47:27,033 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-03 12:47:27,033 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 12:47:29,257 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:33,678 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:35,161 - services.rag_service - WARNING - Weak context retrieved for query: cure of diabetes
2026-01-03 12:47:38,680 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:38] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:43,675 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:48,675 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:48] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:53,681 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:58,664 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:58] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:47:59,595 - routes.chat_routes - INFO - Answer generated for chat 8018e4f3-3e60-49a7-bcba-8230d681e14b
2026-01-03 12:47:59,596 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:47:59] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:48:03,671 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:03] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:08,361 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:08] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:13,676 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:18,368 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:18] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:23,685 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:23] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:28,366 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:28] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:33,683 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:38,358 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:38] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:39,324 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:39] "[31m[1mPOST /chat/ask HTTP/1.1[0m" 400 -
2026-01-03 12:48:43,359 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:47,647 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:47] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:48:48,367 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:48] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:53,663 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:48:58,372 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:48:58] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:01,974 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:01] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:49:02,217 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:02] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:03,358 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:03] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:07,176 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:07] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:07,186 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:07] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:49:07,192 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:07] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 12:49:07,428 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:07] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:11,853 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:17,253 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:17] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:21,942 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:21] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:27,246 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:31,948 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:37,255 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:37] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:41,952 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:49:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:49:45,228 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:49:45,228 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 12:49:45,229 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:49:45,246 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:49:45,247 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\config.py', reloading
2026-01-03 12:49:45,248 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 12:49:45,248 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\config.py', reloading
2026-01-03 12:49:45,252 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\verify_gpu.py', reloading
2026-01-03 12:49:45,253 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\start_server.py', reloading
2026-01-03 12:49:45,253 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\verify_gpu.py', reloading
2026-01-03 12:49:45,254 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\start_server.py', reloading
2026-01-03 12:50:27,353 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:50:27,354 - __main__ - INFO - CORS enabled
2026-01-03 12:50:27,354 - __main__ - INFO - JWT initialized
2026-01-03 12:50:27,359 - __main__ - INFO - Blueprints registered
2026-01-03 12:50:27,360 - __main__ - INFO - ============================================================
2026-01-03 12:50:27,360 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:50:27,360 - __main__ - INFO - ============================================================
2026-01-03 12:50:27,360 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:50:27,361 - __main__ - INFO - Port: 5000
2026-01-03 12:50:27,361 - __main__ - INFO - Debug: True
2026-01-03 12:50:27,361 - __main__ - INFO - ============================================================
2026-01-03 12:50:27,381 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 12:50:27,381 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 12:50:27,390 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:50:27,866 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:50:27,867 - __main__ - INFO - CORS enabled
2026-01-03 12:50:27,868 - __main__ - INFO - JWT initialized
2026-01-03 12:50:27,884 - __main__ - INFO - Blueprints registered
2026-01-03 12:50:27,885 - __main__ - INFO - ============================================================
2026-01-03 12:50:27,886 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:50:27,886 - __main__ - INFO - ============================================================
2026-01-03 12:50:27,886 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:50:27,887 - __main__ - INFO - Port: 5000
2026-01-03 12:50:27,888 - __main__ - INFO - Debug: True
2026-01-03 12:50:27,888 - __main__ - INFO - ============================================================
2026-01-03 12:50:27,919 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:50:27,924 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:50:27,967 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:50:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:50:31,951 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:50:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:50:37,255 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:50:37] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:50:41,946 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:50:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:50:47,248 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:50:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:50:51,967 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:50:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:50:57,253 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:50:57] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:29,245 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:33,608 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:33] "OPTIONS /chat/delete/c9242281-da00-4c84-947f-f31905e7306b HTTP/1.1" 200 -
2026-01-03 12:51:33,623 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:33,875 - routes.chat_routes - INFO - Deleted chat c9242281-da00-4c84-947f-f31905e7306b for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:51:33,878 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:33] "DELETE /chat/delete/c9242281-da00-4c84-947f-f31905e7306b HTTP/1.1" 200 -
2026-01-03 12:51:33,925 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:36,091 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:36] "OPTIONS /chat/delete/ea94f080-99e2-4885-b53a-bfaa633c7f7b HTTP/1.1" 200 -
2026-01-03 12:51:36,404 - routes.chat_routes - INFO - Deleted chat ea94f080-99e2-4885-b53a-bfaa633c7f7b for user 6958bd2f226bdd90f9c905fb
2026-01-03 12:51:36,406 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:36] "DELETE /chat/delete/ea94f080-99e2-4885-b53a-bfaa633c7f7b HTTP/1.1" 200 -
2026-01-03 12:51:36,670 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:36,918 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:38,227 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:38] "OPTIONS /chat/history?chatId=508c4715-0088-41e7-9136-06bb1e3b269b HTTP/1.1" 200 -
2026-01-03 12:51:38,496 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:38] "GET /chat/history?chatId=508c4715-0088-41e7-9136-06bb1e3b269b HTTP/1.1" 200 -
2026-01-03 12:51:41,383 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:41] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:51:42,240 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:46,931 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:52,234 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:51:56,937 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:51:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:01,881 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:01] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:52:02,147 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:02] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:06,919 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:12,243 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:12] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:13,675 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:13] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:52:17,267 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:17] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:21,942 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:21] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:27,259 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:31,949 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:37,259 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:37] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:41,950 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:47,260 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:50,894 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:52:50,894 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:52:51,447 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:52:51,933 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:52:51,934 - __main__ - INFO - CORS enabled
2026-01-03 12:52:51,935 - __main__ - INFO - JWT initialized
2026-01-03 12:52:51,948 - __main__ - INFO - Blueprints registered
2026-01-03 12:52:51,951 - __main__ - INFO - ============================================================
2026-01-03 12:52:51,952 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:52:51,953 - __main__ - INFO - ============================================================
2026-01-03 12:52:51,953 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:52:51,954 - __main__ - INFO - Port: 5000
2026-01-03 12:52:51,955 - __main__ - INFO - Debug: True
2026-01-03 12:52:51,956 - __main__ - INFO - ============================================================
2026-01-03 12:52:51,978 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:52:51,988 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:52:52,276 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:52:56,930 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:52:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:53:02,245 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:53:02] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:53:03,372 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:53:03] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 12:53:07,242 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:53:07] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:53:10,509 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:53:10,511 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:53:10,513 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 12:53:11,078 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-03 12:53:11,498 - __main__ - INFO - Configuration loaded: Config
2026-01-03 12:53:11,498 - __main__ - INFO - CORS enabled
2026-01-03 12:53:11,499 - __main__ - INFO - JWT initialized
2026-01-03 12:53:11,511 - __main__ - INFO - Blueprints registered
2026-01-03 12:53:11,513 - __main__ - INFO - ============================================================
2026-01-03 12:53:11,514 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 12:53:11,514 - __main__ - INFO - ============================================================
2026-01-03 12:53:11,515 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 12:53:11,515 - __main__ - INFO - Port: 5000
2026-01-03 12:53:11,516 - __main__ - INFO - Debug: True
2026-01-03 12:53:11,516 - __main__ - INFO - ============================================================
2026-01-03 12:53:11,533 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 12:53:11,542 - werkzeug - INFO -  * Debugger PIN: 980-082-225
2026-01-03 12:53:12,286 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:53:12] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:53:16,957 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:53:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 12:53:22,257 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 12:53:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:05:24,872 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:05:24,874 - __main__ - INFO - CORS enabled
2026-01-03 14:05:24,874 - __main__ - INFO - JWT initialized
2026-01-03 14:05:24,879 - __main__ - INFO - Blueprints registered
2026-01-03 14:05:24,880 - __main__ - INFO - ============================================================
2026-01-03 14:05:24,880 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:05:24,881 - __main__ - INFO - ============================================================
2026-01-03 14:05:24,881 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:05:24,881 - __main__ - INFO - Port: 5000
2026-01-03 14:05:24,882 - __main__ - INFO - Debug: True
2026-01-03 14:05:24,882 - __main__ - INFO - ============================================================
2026-01-03 14:05:25,077 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 14:05:25,078 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 14:05:25,084 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:05:25,521 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:05:25,522 - __main__ - INFO - CORS enabled
2026-01-03 14:05:25,522 - __main__ - INFO - JWT initialized
2026-01-03 14:05:25,527 - __main__ - INFO - Blueprints registered
2026-01-03 14:05:25,528 - __main__ - INFO - ============================================================
2026-01-03 14:05:25,528 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:05:25,528 - __main__ - INFO - ============================================================
2026-01-03 14:05:25,529 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:05:25,529 - __main__ - INFO - Port: 5000
2026-01-03 14:05:25,529 - __main__ - INFO - Debug: True
2026-01-03 14:05:25,529 - __main__ - INFO - ============================================================
2026-01-03 14:05:25,548 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:05:25,553 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:05:56,506 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:56] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-03 14:05:57,173 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-03 14:05:57,174 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:57] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 14:05:57,230 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:57] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-03 14:05:57,538 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:57] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-03 14:05:57,539 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:57] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-03 14:05:57,540 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:57] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-03 14:05:57,569 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:57] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:05:57,886 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:57] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:05:58,025 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:58] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:05:58,046 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:05:58] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:06:49,291 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:06:49] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:06:49,299 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:06:49] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:06:49,303 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:06:49] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:06:49,558 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:06:49] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:06:54,913 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:06:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:00,225 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:00] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:04,914 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:04] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:10,224 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:10] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:14,919 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:30,466 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:33,973 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:38,835 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:38] "OPTIONS /chat/ask HTTP/1.1" 200 -
2026-01-03 14:07:39,156 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:42,954 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:07:43,540 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:07:43,980 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:43] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:51,768 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:54,298 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:07:59,287 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:07:59] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:04,290 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:04] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:09,284 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:09] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:14,291 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:19,297 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:19] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:24,287 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:24] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:30,229 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:35,227 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:35] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:40,229 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:40] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:44,909 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:44] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:50,221 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:50] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:54,912 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:08:59,297 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:08:59] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:01,083 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:01] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:09:01,388 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:01,453 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:01] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:09:01,777 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:03,393 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:03] "OPTIONS /chat/history?chatId=508c4715-0088-41e7-9136-06bb1e3b269b HTTP/1.1" 200 -
2026-01-03 14:09:03,665 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:03] "GET /chat/history?chatId=508c4715-0088-41e7-9136-06bb1e3b269b HTTP/1.1" 200 -
2026-01-03 14:09:06,082 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:11,391 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:14,141 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:14] "OPTIONS /chat/delete/508c4715-0088-41e7-9136-06bb1e3b269b HTTP/1.1" 200 -
2026-01-03 14:09:14,460 - routes.chat_routes - INFO - Deleted chat 508c4715-0088-41e7-9136-06bb1e3b269b for user 6958bd2f226bdd90f9c905fb
2026-01-03 14:09:14,462 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:14] "DELETE /chat/delete/508c4715-0088-41e7-9136-06bb1e3b269b HTTP/1.1" 200 -
2026-01-03 14:09:14,719 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:14,901 - services.rag_service - INFO - Loading ML models...
2026-01-03 14:09:15,136 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:09:15,138 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-mpnet-base-v2
2026-01-03 14:09:16,077 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:22,061 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:09:22,229 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:24,657 - services.rag_service - WARNING - Weak context retrieved for query: What is hypertension?
2026-01-03 14:09:26,913 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:28,534 - routes.chat_routes - INFO - Answer generated for chat 4f97796d-9145-4aef-9a23-7d4f45aaab67
2026-01-03 14:09:28,535 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:28] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 14:09:31,417 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:31] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:09:31,555 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:31,565 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:31] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:09:31,571 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:32,896 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:32] "OPTIONS /chat/history?chatId=4f97796d-9145-4aef-9a23-7d4f45aaab67 HTTP/1.1" 200 -
2026-01-03 14:09:33,165 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:33] "GET /chat/history?chatId=4f97796d-9145-4aef-9a23-7d4f45aaab67 HTTP/1.1" 200 -
2026-01-03 14:09:36,245 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:42,217 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:46,911 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:52,219 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:09:56,922 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:09:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:02,244 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:02] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:06,914 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:12,229 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:12] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:16,917 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:16] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:22,221 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:26,911 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:32,218 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:32] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:36,244 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:42,227 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:46,918 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:46] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:52,222 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:10:56,236 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:10:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:11:01,550 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:11:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:11:06,922 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:11:06] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:11:13,253 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:11:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:11:13,257 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:11:13] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:11:13,261 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:11:13] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:11:13,506 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:11:13] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:12:28,962 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:12:28] "GET /chat/history?chatId=4f97796d-9145-4aef-9a23-7d4f45aaab67 HTTP/1.1" 200 -
2026-01-03 14:12:32,745 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:12:32] "OPTIONS /chat/delete/4f97796d-9145-4aef-9a23-7d4f45aaab67 HTTP/1.1" 200 -
2026-01-03 14:12:33,068 - routes.chat_routes - INFO - Deleted chat 4f97796d-9145-4aef-9a23-7d4f45aaab67 for user 6958bd2f226bdd90f9c905fb
2026-01-03 14:12:33,069 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:12:33] "DELETE /chat/delete/4f97796d-9145-4aef-9a23-7d4f45aaab67 HTTP/1.1" 200 -
2026-01-03 14:12:33,317 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:12:33] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:12:37,916 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:12:39,247 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:12:39,800 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:12:39,802 - __main__ - INFO - CORS enabled
2026-01-03 14:12:39,802 - __main__ - INFO - JWT initialized
2026-01-03 14:12:39,812 - __main__ - INFO - Blueprints registered
2026-01-03 14:12:39,813 - __main__ - INFO - ============================================================
2026-01-03 14:12:39,814 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:12:39,814 - __main__ - INFO - ============================================================
2026-01-03 14:12:39,814 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:12:39,815 - __main__ - INFO - Port: 5000
2026-01-03 14:12:39,815 - __main__ - INFO - Debug: True
2026-01-03 14:12:39,815 - __main__ - INFO - ============================================================
2026-01-03 14:12:39,845 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:12:39,849 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:27:05,996 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:27:06,549 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:27:07,045 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:27:07,046 - __main__ - INFO - CORS enabled
2026-01-03 14:27:07,047 - __main__ - INFO - JWT initialized
2026-01-03 14:27:07,058 - __main__ - INFO - Blueprints registered
2026-01-03 14:27:07,060 - __main__ - INFO - ============================================================
2026-01-03 14:27:07,061 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:27:07,062 - __main__ - INFO - ============================================================
2026-01-03 14:27:07,062 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:27:07,063 - __main__ - INFO - Port: 5000
2026-01-03 14:27:07,063 - __main__ - INFO - Debug: True
2026-01-03 14:27:07,063 - __main__ - INFO - ============================================================
2026-01-03 14:27:07,099 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:27:07,103 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:27:27,902 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-03 14:27:27,907 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:27] "POST /auth/login HTTP/1.1" 200 -
2026-01-03 14:27:27,932 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:27] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:27:28,260 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:28] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:27:28,287 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:28] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:27:28,298 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:28] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:27:31,914 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:27:31,943 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:27:34,515 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:27:35,335 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:27:35,802 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:27:35,802 - __main__ - INFO - CORS enabled
2026-01-03 14:27:35,803 - __main__ - INFO - JWT initialized
2026-01-03 14:27:35,813 - __main__ - INFO - Blueprints registered
2026-01-03 14:27:35,815 - __main__ - INFO - ============================================================
2026-01-03 14:27:35,815 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:27:35,816 - __main__ - INFO - ============================================================
2026-01-03 14:27:35,816 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:27:35,817 - __main__ - INFO - Port: 5000
2026-01-03 14:27:35,817 - __main__ - INFO - Debug: True
2026-01-03 14:27:35,818 - __main__ - INFO - ============================================================
2026-01-03 14:27:35,843 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:27:35,852 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:27:41,427 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:27:41,448 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:41] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:27:41,461 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:41] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:27:41,668 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:27:55,720 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:55] "OPTIONS /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:27:56,046 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:27:56] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:27:57,597 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:27:57,913 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:27:58,431 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:27:58,432 - __main__ - INFO - CORS enabled
2026-01-03 14:27:58,433 - __main__ - INFO - JWT initialized
2026-01-03 14:27:58,444 - __main__ - INFO - Blueprints registered
2026-01-03 14:27:58,447 - __main__ - INFO - ============================================================
2026-01-03 14:27:58,448 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:27:58,448 - __main__ - INFO - ============================================================
2026-01-03 14:27:58,450 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:27:58,451 - __main__ - INFO - Port: 5000
2026-01-03 14:27:58,452 - __main__ - INFO - Debug: True
2026-01-03 14:27:58,452 - __main__ - INFO - ============================================================
2026-01-03 14:27:58,477 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:27:58,481 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:28:49,795 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:28:49,952 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:28:50,405 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:28:50,406 - __main__ - INFO - CORS enabled
2026-01-03 14:28:50,406 - __main__ - INFO - JWT initialized
2026-01-03 14:28:50,412 - __main__ - INFO - Blueprints registered
2026-01-03 14:28:50,413 - __main__ - INFO - ============================================================
2026-01-03 14:28:50,414 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:28:50,414 - __main__ - INFO - ============================================================
2026-01-03 14:28:50,415 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:28:50,415 - __main__ - INFO - Port: 5000
2026-01-03 14:28:50,416 - __main__ - INFO - Debug: True
2026-01-03 14:28:50,417 - __main__ - INFO - ============================================================
2026-01-03 14:28:50,438 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:28:50,444 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:29:01,042 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:29:01,434 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:29:01,847 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:29:01,848 - __main__ - INFO - CORS enabled
2026-01-03 14:29:01,848 - __main__ - INFO - JWT initialized
2026-01-03 14:29:01,855 - __main__ - INFO - Blueprints registered
2026-01-03 14:29:01,857 - __main__ - INFO - ============================================================
2026-01-03 14:29:01,857 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:29:01,857 - __main__ - INFO - ============================================================
2026-01-03 14:29:01,858 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:29:01,858 - __main__ - INFO - Port: 5000
2026-01-03 14:29:01,858 - __main__ - INFO - Debug: True
2026-01-03 14:29:01,858 - __main__ - INFO - ============================================================
2026-01-03 14:29:01,882 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:29:01,886 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:29:38,751 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:29:39,018 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:29:39,539 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:29:39,540 - __main__ - INFO - CORS enabled
2026-01-03 14:29:39,540 - __main__ - INFO - JWT initialized
2026-01-03 14:29:39,547 - __main__ - INFO - Blueprints registered
2026-01-03 14:29:39,549 - __main__ - INFO - ============================================================
2026-01-03 14:29:39,549 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:29:39,549 - __main__ - INFO - ============================================================
2026-01-03 14:29:39,549 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:29:39,549 - __main__ - INFO - Port: 5000
2026-01-03 14:29:39,550 - __main__ - INFO - Debug: True
2026-01-03 14:29:39,550 - __main__ - INFO - ============================================================
2026-01-03 14:29:39,569 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:29:39,573 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:30:15,005 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:30:15] "POST /chat/ask HTTP/1.1" 200 -
2026-01-03 14:31:14,948 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:31:14] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:31:15,244 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:31:15] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:31:39,239 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:31:39] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:32:29,755 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\app.py', reloading
2026-01-03 14:32:30,285 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:32:30,809 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:32:30,810 - __main__ - INFO - CORS enabled
2026-01-03 14:32:30,810 - __main__ - INFO - JWT initialized
2026-01-03 14:32:30,815 - __main__ - INFO - Blueprints registered
2026-01-03 14:32:30,816 - __main__ - INFO - ============================================================
2026-01-03 14:32:30,816 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:32:30,816 - __main__ - INFO - ============================================================
2026-01-03 14:32:30,817 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:32:30,817 - __main__ - INFO - Port: 5000
2026-01-03 14:32:30,817 - __main__ - INFO - Debug: True
2026-01-03 14:32:30,817 - __main__ - INFO - ============================================================
2026-01-03 14:32:30,830 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:32:30,834 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:32:45,557 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\app.py', reloading
2026-01-03 14:32:45,956 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:32:46,516 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:32:46,516 - __main__ - INFO - CORS enabled
2026-01-03 14:32:46,516 - __main__ - INFO - JWT initialized
2026-01-03 14:32:46,519 - __main__ - INFO - Blueprints registered
2026-01-03 14:32:46,520 - __main__ - INFO - ============================================================
2026-01-03 14:32:46,520 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:32:46,520 - __main__ - INFO - ============================================================
2026-01-03 14:32:46,520 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:32:46,520 - __main__ - INFO - Port: 5000
2026-01-03 14:32:46,520 - __main__ - INFO - Debug: True
2026-01-03 14:32:46,520 - __main__ - INFO - ============================================================
2026-01-03 14:32:46,548 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:32:46,553 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:32:46,691 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:32:46,712 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:32:53,691 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:32:53,692 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:32:54,825 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:32:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:32:54,867 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:32:54] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:32:54,883 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:32:54] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:32:54,900 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:32:54,901 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:32:55,055 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:32:55] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:32:58,947 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:32:59,301 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:33:00,408 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\app.py', reloading
2026-01-03 14:33:01,498 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:33:01,972 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:33:01,972 - __main__ - INFO - CORS enabled
2026-01-03 14:33:01,973 - __main__ - INFO - JWT initialized
2026-01-03 14:33:01,976 - __main__ - INFO - Blueprints registered
2026-01-03 14:33:01,977 - __main__ - INFO - ============================================================
2026-01-03 14:33:01,977 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:33:01,977 - __main__ - INFO - ============================================================
2026-01-03 14:33:01,977 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:33:01,977 - __main__ - INFO - Port: 5000
2026-01-03 14:33:01,977 - __main__ - INFO - Debug: True
2026-01-03 14:33:01,978 - __main__ - INFO - ============================================================
2026-01-03 14:33:02,004 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:33:02,011 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:33:02,114 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:33:02,128 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:33:07,035 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:33:07,036 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:33:12,788 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:33:25,210 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:25] "OPTIONS /chat/stream HTTP/1.1" 200 -
2026-01-03 14:33:25,456 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:25] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:33:25,540 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:25] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:33:30,621 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:30] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:33:30,923 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:33:30,932 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:30] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:33:31,255 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:33:32,490 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:32] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:33:38,898 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\config.py', reloading
2026-01-03 14:33:41,590 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:33:42,068 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:33:42,068 - __main__ - INFO - CORS enabled
2026-01-03 14:33:42,069 - __main__ - INFO - JWT initialized
2026-01-03 14:33:42,072 - __main__ - INFO - Blueprints registered
2026-01-03 14:33:42,073 - __main__ - INFO - ============================================================
2026-01-03 14:33:42,073 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:33:42,073 - __main__ - INFO - ============================================================
2026-01-03 14:33:42,074 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:33:42,074 - __main__ - INFO - Port: 5000
2026-01-03 14:33:42,074 - __main__ - INFO - Debug: True
2026-01-03 14:33:42,074 - __main__ - INFO - ============================================================
2026-01-03 14:33:42,106 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:33:42,112 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:33:42,221 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:33:42,237 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:42] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:33:42,239 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:33:42,260 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:33:45,534 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:45] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:33:45,865 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:45] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:33:51,581 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:51] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:33:51,685 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:33:51,736 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:51] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:33:52,051 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:33:54,612 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:33:54] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:33:55,966 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:33:55,972 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:33:55,985 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:33:55,985 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:34:02,116 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:34:02,148 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:34:03,081 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:34:30,948 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:30] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:34:31,739 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:31] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:34:33,603 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:34:33,951 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:33] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:34:51,151 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:34:53,000 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:34:53,605 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:34:53,606 - __main__ - INFO - CORS enabled
2026-01-03 14:34:53,607 - __main__ - INFO - JWT initialized
2026-01-03 14:34:53,611 - __main__ - INFO - Blueprints registered
2026-01-03 14:34:53,611 - __main__ - INFO - ============================================================
2026-01-03 14:34:53,612 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:34:53,612 - __main__ - INFO - ============================================================
2026-01-03 14:34:53,613 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:34:53,615 - __main__ - INFO - Port: 5000
2026-01-03 14:34:53,615 - __main__ - INFO - Debug: True
2026-01-03 14:34:53,615 - __main__ - INFO - ============================================================
2026-01-03 14:34:53,652 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:34:53,662 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:34:53,744 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:34:53,750 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:34:53,775 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:34:53,793 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:34:53,827 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:53] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:34:53,882 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:53] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:34:53,898 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:53] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:34:54,250 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:34:54,844 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:54] "OPTIONS /chat/history?chatId=c7224500-fe72-41c3-9d79-2ba0da6f6364 HTTP/1.1" 200 -
2026-01-03 14:34:55,166 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:55] "GET /chat/history?chatId=c7224500-fe72-41c3-9d79-2ba0da6f6364 HTTP/1.1" 200 -
2026-01-03 14:34:58,744 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:34:58] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:35:00,820 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:35:00] "GET /chat/history?chatId=c7224500-fe72-41c3-9d79-2ba0da6f6364 HTTP/1.1" 200 -
2026-01-03 14:35:03,839 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:35:03,840 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:35:03,843 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:35:03,843 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:35:08,760 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:35:08,766 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:35:09,008 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:35:10,052 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:35:10,199 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5140, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\big_modeling.py", line 502, in dispatch_model
    model.to(device)
    ~~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 4343, in to
    return super().to(*args, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:36:28,780 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:36:30,000 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:36:30,542 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:36:30,543 - __main__ - INFO - CORS enabled
2026-01-03 14:36:30,543 - __main__ - INFO - JWT initialized
2026-01-03 14:36:30,549 - __main__ - INFO - Blueprints registered
2026-01-03 14:36:30,550 - __main__ - INFO - ============================================================
2026-01-03 14:36:30,551 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:36:30,551 - __main__ - INFO - ============================================================
2026-01-03 14:36:30,551 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:36:30,551 - __main__ - INFO - Port: 5000
2026-01-03 14:36:30,552 - __main__ - INFO - Debug: True
2026-01-03 14:36:30,552 - __main__ - INFO - ============================================================
2026-01-03 14:36:30,583 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:36:30,589 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:36:30,699 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:36:30,715 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:36:35,442 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:36:36,963 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:36:37,434 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:36:37,434 - __main__ - INFO - CORS enabled
2026-01-03 14:36:37,436 - __main__ - INFO - JWT initialized
2026-01-03 14:36:37,445 - __main__ - INFO - Blueprints registered
2026-01-03 14:36:37,447 - __main__ - INFO - ============================================================
2026-01-03 14:36:37,447 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:36:37,448 - __main__ - INFO - ============================================================
2026-01-03 14:36:37,449 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:36:37,449 - __main__ - INFO - Port: 5000
2026-01-03 14:36:37,450 - __main__ - INFO - Debug: True
2026-01-03 14:36:37,451 - __main__ - INFO - ============================================================
2026-01-03 14:36:37,496 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:36:37,515 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:36:37,656 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:36:37,674 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:36:42,268 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:36:42] "OPTIONS /chat/delete/c7224500-fe72-41c3-9d79-2ba0da6f6364 HTTP/1.1" 200 -
2026-01-03 14:36:42,510 - routes.chat_routes - INFO - Deleted chat c7224500-fe72-41c3-9d79-2ba0da6f6364 for user 6958bd2f226bdd90f9c905fb
2026-01-03 14:36:42,515 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:36:42] "DELETE /chat/delete/c7224500-fe72-41c3-9d79-2ba0da6f6364 HTTP/1.1" 200 -
2026-01-03 14:36:42,592 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:36:42] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:36:43,759 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:36:43] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:36:44,557 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:36:44] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:36:49,258 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:36:49,274 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:36:49,285 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:36:49,289 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:36:49,298 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:36:49,298 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:36:52,118 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:36:53,798 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:36:54,357 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:36:54,357 - __main__ - INFO - CORS enabled
2026-01-03 14:36:54,358 - __main__ - INFO - JWT initialized
2026-01-03 14:36:54,361 - __main__ - INFO - Blueprints registered
2026-01-03 14:36:54,362 - __main__ - INFO - ============================================================
2026-01-03 14:36:54,362 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:36:54,363 - __main__ - INFO - ============================================================
2026-01-03 14:36:54,363 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:36:54,363 - __main__ - INFO - Port: 5000
2026-01-03 14:36:54,363 - __main__ - INFO - Debug: True
2026-01-03 14:36:54,363 - __main__ - INFO - ============================================================
2026-01-03 14:36:54,391 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:36:54,398 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:36:54,506 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:36:54,523 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:37:00,865 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:00,868 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:00,869 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:00,869 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:00,873 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:00,873 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:00,882 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:37:02,060 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:37:02,454 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:37:02,455 - __main__ - INFO - CORS enabled
2026-01-03 14:37:02,455 - __main__ - INFO - JWT initialized
2026-01-03 14:37:02,458 - __main__ - INFO - Blueprints registered
2026-01-03 14:37:02,459 - __main__ - INFO - ============================================================
2026-01-03 14:37:02,459 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:37:02,459 - __main__ - INFO - ============================================================
2026-01-03 14:37:02,459 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:37:02,459 - __main__ - INFO - Port: 5000
2026-01-03 14:37:02,459 - __main__ - INFO - Debug: True
2026-01-03 14:37:02,459 - __main__ - INFO - ============================================================
2026-01-03 14:37:02,485 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:37:02,491 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:37:02,581 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:37:02,595 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:37:08,906 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:08,919 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:08,923 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:08,923 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:08,931 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:08,940 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:09,394 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:37:09,507 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:09] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:37:10,642 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:37:11,142 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:37:11,145 - __main__ - INFO - CORS enabled
2026-01-03 14:37:11,147 - __main__ - INFO - JWT initialized
2026-01-03 14:37:11,157 - __main__ - INFO - Blueprints registered
2026-01-03 14:37:11,158 - __main__ - INFO - ============================================================
2026-01-03 14:37:11,159 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:37:11,160 - __main__ - INFO - ============================================================
2026-01-03 14:37:11,160 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:37:11,161 - __main__ - INFO - Port: 5000
2026-01-03 14:37:11,162 - __main__ - INFO - Debug: True
2026-01-03 14:37:11,162 - __main__ - INFO - ============================================================
2026-01-03 14:37:11,205 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:37:11,213 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:37:11,309 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:37:11,330 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:37:11,332 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:11] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:37:11,349 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:37:11,798 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:11] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:37:17,955 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:17,958 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:17,960 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:17,960 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:17,963 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:17,964 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:23,339 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:37:24,551 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:37:24,702 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:37:24,712 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:24] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:37:25,098 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:25] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:37:25,107 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:25] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:37:25,423 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:25] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:37:27,239 - services.rag_service - ERROR - Failed to load ML models: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 248.00 MiB is free. 4.80 GiB allowed; Of the allocated memory 4.61 GiB is allocated by PyTorch, and 174.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2026-01-03 14:37:27,240 - services.rag_service - ERROR - Failed to load ML models: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 228.00 MiB is free. 4.80 GiB allowed; Of the allocated memory 4.62 GiB is allocated by PyTorch, and 185.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2026-01-03 14:37:27,240 - services.rag_service - ERROR - Failed to load ML models: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 228.00 MiB is free. 4.80 GiB allowed; Of the allocated memory 4.62 GiB is allocated by PyTorch, and 185.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2026-01-03 14:37:27,273 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        model,
        ^^^^^^
    ...<12 lines>...
        weights_only=weights_only,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ~~~~~~~~~~~~~~~^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
        model,
    ...<8 lines>...
        device_mesh=device_mesh,
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 750, in _load_state_dict_into_meta_model
    param = param.to(casting_dtype)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 248.00 MiB is free. 4.80 GiB allowed; Of the allocated memory 4.61 GiB is allocated by PyTorch, and 174.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2026-01-03 14:37:27,275 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        model,
        ^^^^^^
    ...<12 lines>...
        weights_only=weights_only,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ~~~~~~~~~~~~~~~^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
        model,
    ...<8 lines>...
        device_mesh=device_mesh,
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 748, in _load_state_dict_into_meta_model
    param = param[...]
            ~~~~~^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 228.00 MiB is free. 4.80 GiB allowed; Of the allocated memory 4.62 GiB is allocated by PyTorch, and 185.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2026-01-03 14:37:27,277 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5048, in from_pretrained
    ) = cls._load_pretrained_model(
        ~~~~~~~~~~~~~~~~~~~~~~~~~~^
        model,
        ^^^^^^
    ...<12 lines>...
        weights_only=weights_only,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5468, in _load_pretrained_model
    _error_msgs, disk_offload_index = load_shard_file(args)
                                      ~~~~~~~~~~~~~~~^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 843, in load_shard_file
    disk_offload_index = _load_state_dict_into_meta_model(
        model,
    ...<8 lines>...
        device_mesh=device_mesh,
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\utils\_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 750, in _load_state_dict_into_meta_model
    param = param.to(casting_dtype)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 228.00 MiB is free. 4.80 GiB allowed; Of the allocated memory 4.62 GiB is allocated by PyTorch, and 185.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

2026-01-03 14:37:27,936 - services.rag_service - WARNING - ML models not loaded for context retrieval
2026-01-03 14:37:28,123 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:28,124 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:28,125 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:28,127 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:33,495 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:37:34,048 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:37:35,113 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:37:35,116 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5140, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\big_modeling.py", line 502, in dispatch_model
    model.to(device)
    ~~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 4343, in to
    return super().to(*args, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 2 more times]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:37:35,117 - services.rag_service - WARNING - ML models not loaded for context retrieval
2026-01-03 14:37:35,143 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:37:35,143 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:37:36,645 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:36] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:37:40,756 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:37:41,856 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:37:41] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:38:14,188 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:14] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:38:14,491 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:38:14,548 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:14] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:38:14,817 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:38:16,001 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:16] "OPTIONS /chat/history?chatId=e63d397f-837d-40c5-a0aa-2833bc4bba99 HTTP/1.1" 200 -
2026-01-03 14:38:16,275 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:16] "GET /chat/history?chatId=e63d397f-837d-40c5-a0aa-2833bc4bba99 HTTP/1.1" 200 -
2026-01-03 14:38:18,463 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:18] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:38:19,654 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:19] "GET /chat/history?chatId=e63d397f-837d-40c5-a0aa-2833bc4bba99 HTTP/1.1" 200 -
2026-01-03 14:38:20,611 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:20] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:38:22,614 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:22] "GET /chat/history?chatId=e63d397f-837d-40c5-a0aa-2833bc4bba99 HTTP/1.1" 200 -
2026-01-03 14:38:26,146 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:26] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:38:26,473 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:26] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:38:41,396 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:41] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:38:41,728 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:38:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:39:55,263 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:39:55,755 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:39:55] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:40:22,364 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:40:23,676 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:41:12,352 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:41:12,353 - __main__ - INFO - CORS enabled
2026-01-03 14:41:12,353 - __main__ - INFO - JWT initialized
2026-01-03 14:41:12,358 - __main__ - INFO - Blueprints registered
2026-01-03 14:41:12,359 - __main__ - INFO - ============================================================
2026-01-03 14:41:12,359 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:41:12,360 - __main__ - INFO - ============================================================
2026-01-03 14:41:12,360 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:41:12,360 - __main__ - INFO - Port: 5000
2026-01-03 14:41:12,360 - __main__ - INFO - Debug: True
2026-01-03 14:41:12,361 - __main__ - INFO - ============================================================
2026-01-03 14:41:12,412 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-03 14:41:12,413 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-03 14:41:12,415 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:41:12,510 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:41:12,526 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:41:12,832 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:41:12,832 - __main__ - INFO - CORS enabled
2026-01-03 14:41:12,833 - __main__ - INFO - JWT initialized
2026-01-03 14:41:12,836 - __main__ - INFO - Blueprints registered
2026-01-03 14:41:12,837 - __main__ - INFO - ============================================================
2026-01-03 14:41:12,837 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:41:12,837 - __main__ - INFO - ============================================================
2026-01-03 14:41:12,837 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:41:12,837 - __main__ - INFO - Port: 5000
2026-01-03 14:41:12,838 - __main__ - INFO - Debug: True
2026-01-03 14:41:12,838 - __main__ - INFO - ============================================================
2026-01-03 14:41:12,867 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:41:12,871 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:41:12,972 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:41:12,986 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:41:21,805 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:41:21,805 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:41:21,961 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:41:21,975 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:41:22,023 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:41:22,024 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:41:22,031 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:41:22,033 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:41:27,408 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:41:27,423 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:41:27,537 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:41:27,540 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 5 more times]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:41:27,583 - services.rag_service - WARNING - ML models not loaded for context retrieval
2026-01-03 14:41:27,584 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:41:27,608 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:41:27,782 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:41:27,783 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:41:28,430 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:41:33,393 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-03 14:41:33,396 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-03 14:41:33,399 - services.rag_service - ERROR - Failed to load model for streaming
2026-01-03 14:41:33,399 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:41:33] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:44:09,306 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:09] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:44:09,316 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:09] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:44:09,330 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:09] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:44:09,571 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:09] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:44:10,431 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:10] "GET /chat/history?chatId=e63d397f-837d-40c5-a0aa-2833bc4bba99 HTTP/1.1" 200 -
2026-01-03 14:44:38,122 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:38] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:44:38,391 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:38] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:44:45,043 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:45] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:44:45,375 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:44:45] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:46:18,865 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:46:20,028 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:46:20,521 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:46:20,522 - __main__ - INFO - CORS enabled
2026-01-03 14:46:20,523 - __main__ - INFO - JWT initialized
2026-01-03 14:46:20,533 - __main__ - INFO - Blueprints registered
2026-01-03 14:46:20,534 - __main__ - INFO - ============================================================
2026-01-03 14:46:20,535 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:46:20,535 - __main__ - INFO - ============================================================
2026-01-03 14:46:20,535 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:46:20,536 - __main__ - INFO - Port: 5000
2026-01-03 14:46:20,536 - __main__ - INFO - Debug: True
2026-01-03 14:46:20,536 - __main__ - INFO - ============================================================
2026-01-03 14:46:20,573 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:46:20,579 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:46:20,692 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:46:20,708 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:46:25,983 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:46:25,983 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:46:30,952 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:46:54,178 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:46:55,503 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:46:55,969 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:46:55,971 - __main__ - INFO - CORS enabled
2026-01-03 14:46:55,971 - __main__ - INFO - JWT initialized
2026-01-03 14:46:55,981 - __main__ - INFO - Blueprints registered
2026-01-03 14:46:55,983 - __main__ - INFO - ============================================================
2026-01-03 14:46:55,984 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:46:55,984 - __main__ - INFO - ============================================================
2026-01-03 14:46:55,985 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:46:55,985 - __main__ - INFO - Port: 5000
2026-01-03 14:46:55,985 - __main__ - INFO - Debug: True
2026-01-03 14:46:55,986 - __main__ - INFO - ============================================================
2026-01-03 14:46:56,027 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:46:56,032 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:46:56,131 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:46:56,145 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:47:01,318 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:47:01,319 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:47:04,743 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:47:05,740 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:47:06,158 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:47:06,158 - __main__ - INFO - CORS enabled
2026-01-03 14:47:06,158 - __main__ - INFO - JWT initialized
2026-01-03 14:47:06,161 - __main__ - INFO - Blueprints registered
2026-01-03 14:47:06,162 - __main__ - INFO - ============================================================
2026-01-03 14:47:06,162 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:47:06,163 - __main__ - INFO - ============================================================
2026-01-03 14:47:06,163 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:47:06,163 - __main__ - INFO - Port: 5000
2026-01-03 14:47:06,163 - __main__ - INFO - Debug: True
2026-01-03 14:47:06,163 - __main__ - INFO - ============================================================
2026-01-03 14:47:06,187 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:47:06,193 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:47:06,286 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:47:06,301 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:47:11,571 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:47:11,572 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:47:18,111 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:47:22,495 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:47:22] "OPTIONS /chat/delete/e63d397f-837d-40c5-a0aa-2833bc4bba99 HTTP/1.1" 200 -
2026-01-03 14:47:22,727 - routes.chat_routes - INFO - Deleted chat e63d397f-837d-40c5-a0aa-2833bc4bba99 for user 6958bd2f226bdd90f9c905fb
2026-01-03 14:47:22,730 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:47:22] "DELETE /chat/delete/e63d397f-837d-40c5-a0aa-2833bc4bba99 HTTP/1.1" 200 -
2026-01-03 14:47:22,816 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:47:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:47:24,471 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:47:24] "GET /chat/history?chatId=8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-03 14:47:30,269 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:47:32,825 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:47:33,312 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:47:33,314 - __main__ - INFO - CORS enabled
2026-01-03 14:47:33,315 - __main__ - INFO - JWT initialized
2026-01-03 14:47:33,330 - __main__ - INFO - Blueprints registered
2026-01-03 14:47:33,333 - __main__ - INFO - ============================================================
2026-01-03 14:47:33,334 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:47:33,337 - __main__ - INFO - ============================================================
2026-01-03 14:47:33,338 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:47:33,339 - __main__ - INFO - Port: 5000
2026-01-03 14:47:33,339 - __main__ - INFO - Debug: True
2026-01-03 14:47:33,340 - __main__ - INFO - ============================================================
2026-01-03 14:47:33,405 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:47:33,413 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:47:33,529 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:47:33,545 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:47:40,845 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:47:40,846 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:47:46,038 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:47:56,579 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:47:56] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:47:56,801 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:47:56] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:48:00,362 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:48:00,690 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:00] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:48:33,680 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:33] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:48:40,611 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:40] "OPTIONS /chat/history HTTP/1.1" 200 -
2026-01-03 14:48:40,710 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:40] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:48:40,885 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:40] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:48:41,043 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:41] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:48:41,059 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:41] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:48:43,345 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:43] "OPTIONS /chat/history?chatId=28db68e0-8f41-45ef-b029-575a65c6b5ac HTTP/1.1" 200 -
2026-01-03 14:48:43,667 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:43] "GET /chat/history?chatId=28db68e0-8f41-45ef-b029-575a65c6b5ac HTTP/1.1" 200 -
2026-01-03 14:48:46,365 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:46] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:48:47,161 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:47] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:48:49,569 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:48:50,022 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:48:50] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:49:17,572 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:49:17] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:49:17,869 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:49:17] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:49:17,875 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:49:17] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-03 14:49:18,182 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:49:18] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:50:36,244 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:50:36] "GET /chat/list HTTP/1.1" 200 -
2026-01-03 14:50:53,003 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:50:54,226 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:50:54,695 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:50:54,696 - __main__ - INFO - CORS enabled
2026-01-03 14:50:54,696 - __main__ - INFO - JWT initialized
2026-01-03 14:50:54,699 - __main__ - INFO - Blueprints registered
2026-01-03 14:50:54,700 - __main__ - INFO - ============================================================
2026-01-03 14:50:54,700 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:50:54,700 - __main__ - INFO - ============================================================
2026-01-03 14:50:54,701 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:50:54,701 - __main__ - INFO - Port: 5000
2026-01-03 14:50:54,701 - __main__ - INFO - Debug: True
2026-01-03 14:50:54,701 - __main__ - INFO - ============================================================
2026-01-03 14:50:54,726 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:50:54,734 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:50:54,847 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:50:54,863 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:51:00,128 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:51:00,129 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:51:04,694 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:51:08,086 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\extensions\\db.py', reloading
2026-01-03 14:51:09,410 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:51:09,967 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:51:09,968 - __main__ - INFO - CORS enabled
2026-01-03 14:51:09,968 - __main__ - INFO - JWT initialized
2026-01-03 14:51:09,972 - __main__ - INFO - Blueprints registered
2026-01-03 14:51:09,973 - __main__ - INFO - ============================================================
2026-01-03 14:51:09,973 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:51:09,973 - __main__ - INFO - ============================================================
2026-01-03 14:51:09,973 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:51:09,973 - __main__ - INFO - Port: 5000
2026-01-03 14:51:09,973 - __main__ - INFO - Debug: True
2026-01-03 14:51:09,973 - __main__ - INFO - ============================================================
2026-01-03 14:51:09,998 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:51:10,003 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:51:10,090 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:51:10,105 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:51:15,312 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:51:15,312 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:51:19,604 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:51:50,210 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:51:50,672 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:51:50] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:52:00,928 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-03 14:52:00,930 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:52:00] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-03 14:52:21,182 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:52:21,706 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:52:21] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:53:50,276 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:53:51,606 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:53:52,110 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:53:52,110 - __main__ - INFO - CORS enabled
2026-01-03 14:53:52,110 - __main__ - INFO - JWT initialized
2026-01-03 14:53:52,114 - __main__ - INFO - Blueprints registered
2026-01-03 14:53:52,115 - __main__ - INFO - ============================================================
2026-01-03 14:53:52,115 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:53:52,115 - __main__ - INFO - ============================================================
2026-01-03 14:53:52,116 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:53:52,116 - __main__ - INFO - Port: 5000
2026-01-03 14:53:52,116 - __main__ - INFO - Debug: True
2026-01-03 14:53:52,116 - __main__ - INFO - ============================================================
2026-01-03 14:53:52,136 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:53:52,140 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:53:52,281 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:53:52,306 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:53:58,367 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:53:58,367 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:54:03,379 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:54:36,129 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:54:36,671 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:54:36] "POST /chat/stream HTTP/1.1" 200 -
2026-01-03 14:55:08,748 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:55:10,254 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:55:10,675 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:55:10,676 - __main__ - INFO - CORS enabled
2026-01-03 14:55:10,676 - __main__ - INFO - JWT initialized
2026-01-03 14:55:10,679 - __main__ - INFO - Blueprints registered
2026-01-03 14:55:10,680 - __main__ - INFO - ============================================================
2026-01-03 14:55:10,680 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:55:10,681 - __main__ - INFO - ============================================================
2026-01-03 14:55:10,681 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:55:10,681 - __main__ - INFO - Port: 5000
2026-01-03 14:55:10,681 - __main__ - INFO - Debug: True
2026-01-03 14:55:10,682 - __main__ - INFO - ============================================================
2026-01-03 14:55:10,710 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:55:10,716 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:55:10,830 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:55:10,847 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:55:15,695 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-03 14:55:16,725 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:55:17,121 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:55:17,121 - __main__ - INFO - CORS enabled
2026-01-03 14:55:17,121 - __main__ - INFO - JWT initialized
2026-01-03 14:55:17,125 - __main__ - INFO - Blueprints registered
2026-01-03 14:55:17,126 - __main__ - INFO - ============================================================
2026-01-03 14:55:17,126 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:55:17,126 - __main__ - INFO - ============================================================
2026-01-03 14:55:17,126 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:55:17,126 - __main__ - INFO - Port: 5000
2026-01-03 14:55:17,127 - __main__ - INFO - Debug: True
2026-01-03 14:55:17,127 - __main__ - INFO - ============================================================
2026-01-03 14:55:17,153 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:55:17,159 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:55:17,273 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:55:17,286 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:55:22,531 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:55:22,531 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:55:27,207 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:55:33,318 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-03 14:55:34,657 - werkzeug - INFO -  * Restarting with stat
2026-01-03 14:55:35,097 - __main__ - INFO - Configuration loaded: Config
2026-01-03 14:55:35,097 - __main__ - INFO - CORS enabled
2026-01-03 14:55:35,098 - __main__ - INFO - JWT initialized
2026-01-03 14:55:35,100 - __main__ - INFO - Blueprints registered
2026-01-03 14:55:35,101 - __main__ - INFO - ============================================================
2026-01-03 14:55:35,102 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-03 14:55:35,102 - __main__ - INFO - ============================================================
2026-01-03 14:55:35,102 - __main__ - INFO - Host: 0.0.0.0
2026-01-03 14:55:35,102 - __main__ - INFO - Port: 5000
2026-01-03 14:55:35,102 - __main__ - INFO - Debug: True
2026-01-03 14:55:35,102 - __main__ - INFO - ============================================================
2026-01-03 14:55:35,130 - werkzeug - WARNING -  * Debugger is active!
2026-01-03 14:55:35,134 - werkzeug - INFO -  * Debugger PIN: 121-325-526
2026-01-03 14:55:35,241 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-03 14:55:35,256 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-03 14:55:40,444 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-03 14:55:40,444 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-03 14:55:44,880 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-03 14:56:00,092 - services.rag_service - ERROR - Error retrieving context: 
2026-01-03 14:56:00,499 - werkzeug - INFO - 127.0.0.1 - - [03/Jan/2026 14:56:00] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 10:11:02,028 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:11:02,029 - __main__ - INFO - CORS enabled
2026-01-05 10:11:02,029 - __main__ - INFO - JWT initialized
2026-01-05 10:11:02,033 - __main__ - INFO - Blueprints registered
2026-01-05 10:11:02,034 - __main__ - INFO - ============================================================
2026-01-05 10:11:02,034 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:11:02,034 - __main__ - INFO - ============================================================
2026-01-05 10:11:02,035 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:11:02,035 - __main__ - INFO - Port: 5000
2026-01-05 10:11:02,035 - __main__ - INFO - Debug: True
2026-01-05 10:11:02,035 - __main__ - INFO - ============================================================
2026-01-05 10:11:03,515 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 10:11:03,515 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 10:11:03,530 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:11:03,958 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:11:03,959 - __main__ - INFO - CORS enabled
2026-01-05 10:11:03,959 - __main__ - INFO - JWT initialized
2026-01-05 10:11:03,964 - __main__ - INFO - Blueprints registered
2026-01-05 10:11:03,965 - __main__ - INFO - ============================================================
2026-01-05 10:11:03,965 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:11:03,965 - __main__ - INFO - ============================================================
2026-01-05 10:11:03,965 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:11:03,966 - __main__ - INFO - Port: 5000
2026-01-05 10:11:03,966 - __main__ - INFO - Debug: True
2026-01-05 10:11:03,966 - __main__ - INFO - ============================================================
2026-01-05 10:11:03,996 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:11:04,006 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:11:04,236 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:11:04,244 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:11:04,410 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:11:04,418 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:11:23,719 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:23] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-05 10:11:24,167 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-05 10:11:24,170 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:24] "POST /auth/login HTTP/1.1" 200 -
2026-01-05 10:11:24,307 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:24] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 10:11:24,628 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:24] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 10:11:24,629 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:24] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 10:11:24,632 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:24] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 10:11:24,654 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:24,655 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:24] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:24,971 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:24,973 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:24] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:25,090 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:25] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:25,128 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:25] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:28,763 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:28] "OPTIONS /chat/stream HTTP/1.1" 200 -
2026-01-05 10:11:40,770 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:40] "OPTIONS /chat/ask HTTP/1.1" 200 -
2026-01-05 10:11:40,961 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:40,980 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:40] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:41,023 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:41] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:41,024 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:41] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:41,039 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:41,041 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:41] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:42,657 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:42,675 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:42] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:42,700 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:42] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:42,700 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:42] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:42,914 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:42,916 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:42] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:50,277 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:50,279 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:50] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:51,373 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:51,510 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:51,566 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:51,568 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:51,683 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:51,704 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:51,705 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:51,783 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:51,817 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:51,817 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:51,985 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:51,989 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:51] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:52,020 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:52,168 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:52,174 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:52,193 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:52,175 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:52,358 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:52,360 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:52,553 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:52,719 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:52,729 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:52,750 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:52,751 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:52,909 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:52,916 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:52,917 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:52] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:53,089 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:53,091 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:53] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:53,317 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:53] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:53,334 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:53] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:11:53,397 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:53,398 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:53] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:11:53,400 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:11:53,401 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:11:53] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:12:27,236 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:12:27,239 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:12:27,241 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:12:27,253 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:12:27,271 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:12:27,272 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:12:27,290 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:12:27,293 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:12:33,205 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:12:33,250 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:12:34,248 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:12:34,839 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:12:35,222 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:12:35,224 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:12:35] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:12:35,245 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:12:35] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:12:35,265 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:12:35] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:12:35,480 - routes.chat_routes - ERROR - Error listing chats: Cannot do inclusion on field chatId in exclusion projection, full error: {'ok': 0.0, 'errmsg': 'Cannot do inclusion on field chatId in exclusion projection', 'code': 31253, 'codeName': 'Location31253'}
2026-01-05 10:12:35,483 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:12:35] "[35m[1mGET /chat/list HTTP/1.1[0m" 500 -
2026-01-05 10:12:38,169 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:12:39,145 - services.rag_service - ERROR - Failed to load ML models: weight is on the meta device, we need a `value` to put in on 0.
2026-01-05 10:12:39,210 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5140, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\big_modeling.py", line 426, in dispatch_model
    attach_align_device_hook_on_blocks(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        model,
        ^^^^^^
    ...<6 lines>...
        tied_params_map=tied_params_map,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\hooks.py", line 676, in attach_align_device_hook_on_blocks
    attach_align_device_hook_on_blocks(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        child,
        ^^^^^^
    ...<7 lines>...
        tied_params_map=tied_params_map,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\hooks.py", line 676, in attach_align_device_hook_on_blocks
    attach_align_device_hook_on_blocks(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        child,
        ^^^^^^
    ...<7 lines>...
        tied_params_map=tied_params_map,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\hooks.py", line 634, in attach_align_device_hook_on_blocks
    add_hook_to_module(module, hook)
    ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\hooks.py", line 166, in add_hook_to_module
    module = hook.init_hook(module)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\hooks.py", line 288, in init_hook
    set_module_tensor_to_device(module, name, self.execution_device, tied_params_map=self.tied_params_map)
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\utils\modeling.py", line 289, in set_module_tensor_to_device
    raise ValueError(f"{tensor_name} is on the meta device, we need a `value` to put in on {device}.")
ValueError: weight is on the meta device, we need a `value` to put in on 0.

2026-01-05 10:12:40,306 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 10:12:40,945 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:12:40] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 10:13:42,665 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 10:13:44,928 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:13:45,421 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:13:45,423 - __main__ - INFO - CORS enabled
2026-01-05 10:13:45,427 - __main__ - INFO - JWT initialized
2026-01-05 10:13:45,436 - __main__ - INFO - Blueprints registered
2026-01-05 10:13:45,438 - __main__ - INFO - ============================================================
2026-01-05 10:13:45,438 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:13:45,439 - __main__ - INFO - ============================================================
2026-01-05 10:13:45,440 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:13:45,441 - __main__ - INFO - Port: 5000
2026-01-05 10:13:45,442 - __main__ - INFO - Debug: True
2026-01-05 10:13:45,442 - __main__ - INFO - ============================================================
2026-01-05 10:13:45,491 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:13:45,500 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:13:45,621 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:13:45,636 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:13:51,066 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:51] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-05 10:13:51,561 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-05 10:13:51,561 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:51] "POST /auth/login HTTP/1.1" 200 -
2026-01-05 10:13:51,628 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:51] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 10:13:51,933 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:51] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 10:13:51,936 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:51] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 10:13:51,936 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:51] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 10:13:51,954 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:51] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:13:52,250 - routes.chat_routes - INFO - [OK] Created new chat 87e9b6df-62ca-4497-b2be-650d0c575c7a for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:13:52,252 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:13:52,252 - routes.chat_routes - INFO - [OK] Created new chat e9a45298-0153-439f-a910-1a270b42da6a for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:13:52,264 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:52] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:13:52,285 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:13:52] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:13:57,836 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:13:57,837 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:13:57,838 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:13:57,838 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:14:03,614 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:14:04,594 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:14:04,788 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:04] "OPTIONS /chat/history?chatId=d31f01d9-dbe1-4b6c-a851-deb65cf21663 HTTP/1.1" 200 -
2026-01-05 10:14:05,036 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:05] "GET /chat/history?chatId=d31f01d9-dbe1-4b6c-a851-deb65cf21663 HTTP/1.1" 200 -
2026-01-05 10:14:09,931 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:14:09,956 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5140, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\big_modeling.py", line 502, in dispatch_model
    model.to(device)
    ~~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 4343, in to
    return super().to(*args, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 2 more times]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:14:11,787 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:11] "OPTIONS /chat/delete/d31f01d9-dbe1-4b6c-a851-deb65cf21663 HTTP/1.1" 200 -
2026-01-05 10:14:12,043 - routes.chat_routes - INFO - Deleted chat d31f01d9-dbe1-4b6c-a851-deb65cf21663 for user 6958bd2f226bdd90f9c905fb
2026-01-05 10:14:12,044 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:12] "DELETE /chat/delete/d31f01d9-dbe1-4b6c-a851-deb65cf21663 HTTP/1.1" 200 -
2026-01-05 10:14:13,596 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:13] "OPTIONS /chat/delete/0f6720c3-2e66-4fb1-b025-285a16d80264 HTTP/1.1" 200 -
2026-01-05 10:14:13,916 - routes.chat_routes - INFO - Deleted chat 0f6720c3-2e66-4fb1-b025-285a16d80264 for user 6958bd2f226bdd90f9c905fb
2026-01-05 10:14:13,918 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:13] "DELETE /chat/delete/0f6720c3-2e66-4fb1-b025-285a16d80264 HTTP/1.1" 200 -
2026-01-05 10:14:15,572 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:15,845 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:15] "OPTIONS /chat/delete/28db68e0-8f41-45ef-b029-575a65c6b5ac HTTP/1.1" 200 -
2026-01-05 10:14:18,020 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:18,499 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:18,503 - __main__ - INFO - CORS enabled
2026-01-05 10:14:18,510 - __main__ - INFO - JWT initialized
2026-01-05 10:14:18,517 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:18,521 - __main__ - INFO - ============================================================
2026-01-05 10:14:18,526 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:18,526 - __main__ - INFO - ============================================================
2026-01-05 10:14:18,527 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:18,528 - __main__ - INFO - Port: 5000
2026-01-05 10:14:18,529 - __main__ - INFO - Debug: True
2026-01-05 10:14:18,529 - __main__ - INFO - ============================================================
2026-01-05 10:14:18,582 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:18,593 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:18,710 - routes.chat_routes - INFO - Deleted chat 28db68e0-8f41-45ef-b029-575a65c6b5ac for user 6958bd2f226bdd90f9c905fb
2026-01-05 10:14:18,711 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:18] "DELETE /chat/delete/28db68e0-8f41-45ef-b029-575a65c6b5ac HTTP/1.1" 200 -
2026-01-05 10:14:18,729 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:18,745 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:19,819 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:19] "[33mDELETE /chat/delete/28db68e0-8f41-45ef-b029-575a65c6b5ac HTTP/1.1[0m" 404 -
2026-01-05 10:14:20,940 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:21,609 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:22,046 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:22,047 - __main__ - INFO - CORS enabled
2026-01-05 10:14:22,047 - __main__ - INFO - JWT initialized
2026-01-05 10:14:22,050 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:22,051 - __main__ - INFO - ============================================================
2026-01-05 10:14:22,051 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:22,051 - __main__ - INFO - ============================================================
2026-01-05 10:14:22,051 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:22,051 - __main__ - INFO - Port: 5000
2026-01-05 10:14:22,052 - __main__ - INFO - Debug: True
2026-01-05 10:14:22,052 - __main__ - INFO - ============================================================
2026-01-05 10:14:22,080 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:22,084 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:22,188 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:22,203 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:22,627 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:22] "OPTIONS /chat/delete/8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-05 10:14:22,671 - routes.chat_routes - INFO - Deleted chat 8018e4f3-3e60-49a7-bcba-8230d681e14b for user 6958bd2f226bdd90f9c905fb
2026-01-05 10:14:22,673 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:22] "DELETE /chat/delete/8018e4f3-3e60-49a7-bcba-8230d681e14b HTTP/1.1" 200 -
2026-01-05 10:14:25,890 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:26,885 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:27,517 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:27,518 - __main__ - INFO - CORS enabled
2026-01-05 10:14:27,519 - __main__ - INFO - JWT initialized
2026-01-05 10:14:27,522 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:27,525 - __main__ - INFO - ============================================================
2026-01-05 10:14:27,525 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:27,526 - __main__ - INFO - ============================================================
2026-01-05 10:14:27,526 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:27,526 - __main__ - INFO - Port: 5000
2026-01-05 10:14:27,526 - __main__ - INFO - Debug: True
2026-01-05 10:14:27,526 - __main__ - INFO - ============================================================
2026-01-05 10:14:27,549 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:27,558 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:27,652 - routes.chat_routes - INFO - [OK] Created new chat ea4633cd-56d4-43ad-9b30-3bf8b6db6ced for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:14:27,653 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:27] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:14:27,675 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:27,692 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:27,742 - routes.chat_routes - INFO - [OK] Created new chat 9422afbb-fa21-4c31-8263-84b4196b630f for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:14:27,743 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:27] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:14:29,908 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:30,667 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:31,219 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:31,219 - __main__ - INFO - CORS enabled
2026-01-05 10:14:31,221 - __main__ - INFO - JWT initialized
2026-01-05 10:14:31,224 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:31,225 - __main__ - INFO - ============================================================
2026-01-05 10:14:31,226 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:31,226 - __main__ - INFO - ============================================================
2026-01-05 10:14:31,226 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:31,226 - __main__ - INFO - Port: 5000
2026-01-05 10:14:31,227 - __main__ - INFO - Debug: True
2026-01-05 10:14:31,227 - __main__ - INFO - ============================================================
2026-01-05 10:14:31,257 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:31,264 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:31,383 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:31,401 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:31,416 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:31] "OPTIONS /chat/stream HTTP/1.1" 200 -
2026-01-05 10:14:34,989 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:35,703 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:36,208 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:36,209 - __main__ - INFO - CORS enabled
2026-01-05 10:14:36,209 - __main__ - INFO - JWT initialized
2026-01-05 10:14:36,214 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:36,216 - __main__ - INFO - ============================================================
2026-01-05 10:14:36,217 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:36,217 - __main__ - INFO - ============================================================
2026-01-05 10:14:36,217 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:36,217 - __main__ - INFO - Port: 5000
2026-01-05 10:14:36,218 - __main__ - INFO - Debug: True
2026-01-05 10:14:36,218 - __main__ - INFO - ============================================================
2026-01-05 10:14:36,250 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:36,254 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:36,329 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:14:36] "OPTIONS /chat/ask HTTP/1.1" 200 -
2026-01-05 10:14:36,365 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:36,384 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:38,600 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:38,850 - services.rag_service - ERROR - Failed to load ML models: can't register atexit after shutdown
2026-01-05 10:14:38,859 - services.rag_service - ERROR - Failed to load ML models: can't register atexit after shutdown
2026-01-05 10:14:38,871 - services.rag_service - ERROR - Failed to load ML models: can't register atexit after shutdown
2026-01-05 10:14:39,773 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:40,242 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:40,242 - __main__ - INFO - CORS enabled
2026-01-05 10:14:40,243 - __main__ - INFO - JWT initialized
2026-01-05 10:14:40,246 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:40,246 - __main__ - INFO - ============================================================
2026-01-05 10:14:40,247 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:40,247 - __main__ - INFO - ============================================================
2026-01-05 10:14:40,248 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:40,249 - __main__ - INFO - Port: 5000
2026-01-05 10:14:40,249 - __main__ - INFO - Debug: True
2026-01-05 10:14:40,249 - __main__ - INFO - ============================================================
2026-01-05 10:14:40,278 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:40,286 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:40,406 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:40,424 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:42,696 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:43,291 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:43,807 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:43,808 - __main__ - INFO - CORS enabled
2026-01-05 10:14:43,809 - __main__ - INFO - JWT initialized
2026-01-05 10:14:43,814 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:43,815 - __main__ - INFO - ============================================================
2026-01-05 10:14:43,817 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:43,817 - __main__ - INFO - ============================================================
2026-01-05 10:14:43,817 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:43,817 - __main__ - INFO - Port: 5000
2026-01-05 10:14:43,818 - __main__ - INFO - Debug: True
2026-01-05 10:14:43,818 - __main__ - INFO - ============================================================
2026-01-05 10:14:43,871 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:43,879 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:44,003 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:44,021 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:48,718 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:49,771 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:50,219 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:50,220 - __main__ - INFO - CORS enabled
2026-01-05 10:14:50,220 - __main__ - INFO - JWT initialized
2026-01-05 10:14:50,223 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:50,224 - __main__ - INFO - ============================================================
2026-01-05 10:14:50,224 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:50,225 - __main__ - INFO - ============================================================
2026-01-05 10:14:50,225 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:50,225 - __main__ - INFO - Port: 5000
2026-01-05 10:14:50,226 - __main__ - INFO - Debug: True
2026-01-05 10:14:50,226 - __main__ - INFO - ============================================================
2026-01-05 10:14:50,252 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:50,258 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:50,367 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:50,382 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:52,585 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:53,076 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:53,530 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:53,530 - __main__ - INFO - CORS enabled
2026-01-05 10:14:53,530 - __main__ - INFO - JWT initialized
2026-01-05 10:14:53,534 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:53,534 - __main__ - INFO - ============================================================
2026-01-05 10:14:53,535 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:53,535 - __main__ - INFO - ============================================================
2026-01-05 10:14:53,535 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:53,535 - __main__ - INFO - Port: 5000
2026-01-05 10:14:53,535 - __main__ - INFO - Debug: True
2026-01-05 10:14:53,535 - __main__ - INFO - ============================================================
2026-01-05 10:14:53,558 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:53,562 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:53,680 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:53,697 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:14:57,212 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:14:58,075 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:14:58,563 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:14:58,564 - __main__ - INFO - CORS enabled
2026-01-05 10:14:58,565 - __main__ - INFO - JWT initialized
2026-01-05 10:14:58,571 - __main__ - INFO - Blueprints registered
2026-01-05 10:14:58,573 - __main__ - INFO - ============================================================
2026-01-05 10:14:58,574 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:14:58,574 - __main__ - INFO - ============================================================
2026-01-05 10:14:58,574 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:14:58,574 - __main__ - INFO - Port: 5000
2026-01-05 10:14:58,575 - __main__ - INFO - Debug: True
2026-01-05 10:14:58,575 - __main__ - INFO - ============================================================
2026-01-05 10:14:58,613 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:14:58,623 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:14:58,759 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:14:58,775 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:15:04,190 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:15:04,210 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:15:04,211 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:15:04,288 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:15:04,289 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:15:09,269 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:15:09,332 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:15:09,371 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:15:09,810 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:15:11,799 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:15:11,800 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:15:11,800 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 7.61s - Ready for FAST inference on CUDA
2026-01-05 10:15:12,739 - services.rag_service - INFO - [OK] Response generated in 0.94s (153 chars)
2026-01-05 10:15:14,675 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\app.py', reloading
2026-01-05 10:15:15,837 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:15:16,275 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:15:16,275 - __main__ - INFO - CORS enabled
2026-01-05 10:15:16,275 - __main__ - INFO - JWT initialized
2026-01-05 10:15:16,279 - __main__ - INFO - Blueprints registered
2026-01-05 10:15:16,280 - __main__ - INFO - ============================================================
2026-01-05 10:15:16,280 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:15:16,280 - __main__ - INFO - ============================================================
2026-01-05 10:15:16,281 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:15:16,281 - __main__ - INFO - Port: 5000
2026-01-05 10:15:16,281 - __main__ - INFO - Debug: True
2026-01-05 10:15:16,281 - __main__ - INFO - ============================================================
2026-01-05 10:15:16,281 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:15:16,309 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:15:16,313 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:15:16,398 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:15:16,413 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:15:21,660 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:15:21,674 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:15:21,674 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:15:21,718 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:15:21,719 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:15:23,894 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\app.py', reloading
2026-01-05 10:15:24,990 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:15:25,405 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:15:25,406 - __main__ - INFO - CORS enabled
2026-01-05 10:15:25,406 - __main__ - INFO - JWT initialized
2026-01-05 10:15:25,409 - __main__ - INFO - Blueprints registered
2026-01-05 10:15:25,410 - __main__ - INFO - ============================================================
2026-01-05 10:15:25,410 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:15:25,410 - __main__ - INFO - ============================================================
2026-01-05 10:15:25,410 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:15:25,411 - __main__ - INFO - Port: 5000
2026-01-05 10:15:25,411 - __main__ - INFO - Debug: True
2026-01-05 10:15:25,411 - __main__ - INFO - ============================================================
2026-01-05 10:15:25,411 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:15:25,435 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:15:25,440 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:15:25,554 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:15:25,573 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:15:30,634 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:15:30,650 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:15:30,650 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:15:30,705 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:15:30,705 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:15:35,854 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:15:35,876 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:15:35,910 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:15:36,100 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:15:38,178 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:15:38,179 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:15:38,179 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 7.54s - Ready for FAST inference on CUDA
2026-01-05 10:15:38,179 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:15:39,050 - services.rag_service - INFO - [OK] Response generated in 0.87s (161 chars)
2026-01-05 10:15:39,051 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever is an increase in body temperature beyond th...
2026-01-05 10:15:39,051 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:15:39,672 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:15:40,982 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:15:41,440 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:15:41,440 - __main__ - INFO - CORS enabled
2026-01-05 10:15:41,440 - __main__ - INFO - JWT initialized
2026-01-05 10:15:41,444 - __main__ - INFO - Blueprints registered
2026-01-05 10:15:41,445 - __main__ - INFO - ============================================================
2026-01-05 10:15:41,445 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:15:41,445 - __main__ - INFO - ============================================================
2026-01-05 10:15:41,445 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:15:41,445 - __main__ - INFO - Port: 5000
2026-01-05 10:15:41,445 - __main__ - INFO - Debug: True
2026-01-05 10:15:41,445 - __main__ - INFO - ============================================================
2026-01-05 10:15:41,446 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:15:41,478 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:15:41,482 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:15:41,595 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:15:41,611 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:15:54,156 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:15:54,156 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 10:15:54,194 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:15:54] "OPTIONS /chat/clear-all HTTP/1.1" 200 -
2026-01-05 10:15:54,384 - routes.chat_routes - INFO - Cleared 58 chats for user 6958bd2f226bdd90f9c905fb
2026-01-05 10:15:54,387 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:15:54] "DELETE /chat/clear-all HTTP/1.1" 200 -
2026-01-05 10:15:54,528 - routes.chat_routes - INFO - [OK] Created new chat 43e3b2f0-3651-45ec-bb42-351d6d90ccd7 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:15:54,530 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:15:54] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:15:54,709 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:15:54] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:16:05,984 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:16:05,984 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:16:06,057 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:16:06,058 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:16:06,058 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:16:06,058 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:16:06,132 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:16:06,132 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:16:06,132 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:16:06,133 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:16:06,376 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:16:07,258 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:16:15,106 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:16:15,107 - __main__ - INFO - CORS enabled
2026-01-05 10:16:15,107 - __main__ - INFO - JWT initialized
2026-01-05 10:16:15,112 - __main__ - INFO - Blueprints registered
2026-01-05 10:16:15,114 - __main__ - INFO - ============================================================
2026-01-05 10:16:15,114 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:16:15,114 - __main__ - INFO - ============================================================
2026-01-05 10:16:15,115 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:16:15,115 - __main__ - INFO - Port: 5000
2026-01-05 10:16:15,115 - __main__ - INFO - Debug: True
2026-01-05 10:16:15,115 - __main__ - INFO - ============================================================
2026-01-05 10:16:15,116 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:16:15,367 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:16:15,380 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:16:18,397 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:16:18,974 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:16:34,115 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:16:34,115 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 10:16:34,130 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:16:34] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 10:16:34,378 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:16:34] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:18:11,595 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:18:11,595 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:18:11,595 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:18:11,625 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:18:11,625 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:18:11,625 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:18:11,702 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:18:11,702 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:18:11,703 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:18:11,708 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:18:11,709 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:18:11,710 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:18:11,711 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:18:11,710 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:18:11,712 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:18:17,030 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:18:17,061 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:18:17,063 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 10:18:17,064 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:18:17,065 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 5 more times]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:18:17,068 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 10:18:17,096 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:18:17,097 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 5 more times]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:18:17,107 - services.rag_service - WARNING - ML models not loaded for context retrieval
2026-01-05 10:18:17,107 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:18:17,108 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:18:17,108 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:18:17,112 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:18:17,112 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:18:20,945 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:18:20,952 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:18:20,961 - services.rag_service - ERROR - Failed to load model for streaming
2026-01-05 10:18:20,962 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:18:20] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 10:19:04,920 - routes.chat_routes - INFO - [OK] Created new chat 0d84abf7-1c59-45ef-b37d-3e36acd1843c for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:19:04,923 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:19:04] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:19:04,932 - routes.chat_routes - INFO - [OK] Created new chat 6754b74b-800c-4360-9c29-22b9ab14aa5c for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:19:04,934 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:19:04] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:19:04,953 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:19:04] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:19:05,175 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:19:05] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:19:09,005 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:19:09] "OPTIONS /chat/history?chatId=43e3b2f0-3651-45ec-bb42-351d6d90ccd7 HTTP/1.1" 200 -
2026-01-05 10:19:09,316 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:19:09] "GET /chat/history?chatId=43e3b2f0-3651-45ec-bb42-351d6d90ccd7 HTTP/1.1" 200 -
2026-01-05 10:19:32,213 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:19:33,813 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:19:34,325 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:19:34,325 - __main__ - INFO - CORS enabled
2026-01-05 10:19:34,325 - __main__ - INFO - JWT initialized
2026-01-05 10:19:34,328 - __main__ - INFO - Blueprints registered
2026-01-05 10:19:34,329 - __main__ - INFO - ============================================================
2026-01-05 10:19:34,329 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:19:34,329 - __main__ - INFO - ============================================================
2026-01-05 10:19:34,329 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:19:34,330 - __main__ - INFO - Port: 5000
2026-01-05 10:19:34,330 - __main__ - INFO - Debug: True
2026-01-05 10:19:34,330 - __main__ - INFO - ============================================================
2026-01-05 10:19:34,331 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:19:34,358 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:19:34,363 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:19:34,481 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:19:34,509 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:19:39,646 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:19:39,661 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:19:39,661 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:19:39,734 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:19:39,734 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:19:40,553 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 10:19:41,585 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:19:42,044 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:19:42,044 - __main__ - INFO - CORS enabled
2026-01-05 10:19:42,044 - __main__ - INFO - JWT initialized
2026-01-05 10:19:42,048 - __main__ - INFO - Blueprints registered
2026-01-05 10:19:42,049 - __main__ - INFO - ============================================================
2026-01-05 10:19:42,049 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:19:42,049 - __main__ - INFO - ============================================================
2026-01-05 10:19:42,049 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:19:42,049 - __main__ - INFO - Port: 5000
2026-01-05 10:19:42,049 - __main__ - INFO - Debug: True
2026-01-05 10:19:42,049 - __main__ - INFO - ============================================================
2026-01-05 10:19:42,050 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:19:42,078 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:19:42,082 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:19:42,175 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:19:42,191 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:19:47,168 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:19:47,183 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:19:47,184 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:19:47,252 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:19:47,253 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:19:51,742 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:19:51,792 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:19:51,835 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:19:52,985 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:19:53,290 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:19:54,319 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:19:54,750 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:19:54,751 - __main__ - INFO - CORS enabled
2026-01-05 10:19:54,751 - __main__ - INFO - JWT initialized
2026-01-05 10:19:54,755 - __main__ - INFO - Blueprints registered
2026-01-05 10:19:54,756 - __main__ - INFO - ============================================================
2026-01-05 10:19:54,756 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:19:54,756 - __main__ - INFO - ============================================================
2026-01-05 10:19:54,756 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:19:54,756 - __main__ - INFO - Port: 5000
2026-01-05 10:19:54,756 - __main__ - INFO - Debug: True
2026-01-05 10:19:54,757 - __main__ - INFO - ============================================================
2026-01-05 10:19:54,757 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:19:54,783 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:19:54,791 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:19:54,897 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:19:54,915 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:19:57,139 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:19:57,665 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:19:58,071 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:19:58,072 - __main__ - INFO - CORS enabled
2026-01-05 10:19:58,072 - __main__ - INFO - JWT initialized
2026-01-05 10:19:58,075 - __main__ - INFO - Blueprints registered
2026-01-05 10:19:58,075 - __main__ - INFO - ============================================================
2026-01-05 10:19:58,076 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:19:58,076 - __main__ - INFO - ============================================================
2026-01-05 10:19:58,076 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:19:58,076 - __main__ - INFO - Port: 5000
2026-01-05 10:19:58,076 - __main__ - INFO - Debug: True
2026-01-05 10:19:58,076 - __main__ - INFO - ============================================================
2026-01-05 10:19:58,077 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:19:58,105 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:19:58,109 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:19:58,212 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:19:58,231 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:20:03,798 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:20:03,815 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:20:03,816 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:20:03,883 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:20:03,883 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:20:08,520 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:20:08,542 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:20:08,575 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:20:09,072 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:21:09,510 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:21:09,510 - __main__ - INFO - CORS enabled
2026-01-05 10:21:09,511 - __main__ - INFO - JWT initialized
2026-01-05 10:21:09,514 - __main__ - INFO - Blueprints registered
2026-01-05 10:21:09,515 - __main__ - INFO - ============================================================
2026-01-05 10:21:09,515 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:21:09,515 - __main__ - INFO - ============================================================
2026-01-05 10:21:09,515 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:21:09,515 - __main__ - INFO - Port: 5000
2026-01-05 10:21:09,515 - __main__ - INFO - Debug: True
2026-01-05 10:21:09,515 - __main__ - INFO - ============================================================
2026-01-05 10:21:09,516 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:21:09,563 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 10:21:09,563 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 10:21:09,565 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:21:09,654 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:21:09,670 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:21:10,012 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:21:10,012 - __main__ - INFO - CORS enabled
2026-01-05 10:21:10,012 - __main__ - INFO - JWT initialized
2026-01-05 10:21:10,016 - __main__ - INFO - Blueprints registered
2026-01-05 10:21:10,016 - __main__ - INFO - ============================================================
2026-01-05 10:21:10,016 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:21:10,016 - __main__ - INFO - ============================================================
2026-01-05 10:21:10,017 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:21:10,017 - __main__ - INFO - Port: 5000
2026-01-05 10:21:10,017 - __main__ - INFO - Debug: True
2026-01-05 10:21:10,017 - __main__ - INFO - ============================================================
2026-01-05 10:21:10,017 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:21:10,042 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:21:10,046 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:21:10,139 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:21:10,155 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:21:15,134 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:21:15,137 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 10:21:19,010 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:21:19,037 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:21:19,038 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:21:19,101 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:21:19,101 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:21:19,113 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:21:19,114 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:21:19,114 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:21:19,135 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:21:19,135 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:21:19,135 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:21:19,135 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:21:19,135 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:21:19,193 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:21:19,197 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:21:19,198 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:21:19,198 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:21:19,198 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:21:19,198 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:21:19,199 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:21:23,641 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:21:23,680 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:21:23,734 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:21:23,844 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:21:23,854 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:21:23,860 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 10:21:24,077 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:21:24,082 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:21:24,098 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 10:21:24,186 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:21:24,218 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:21:24,270 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:21:24,390 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:21:25,013 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:21:26,656 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:21:26,724 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<3 lines>...
        use_cache=True,  # Enable KV cache for faster generation
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5140, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\big_modeling.py", line 502, in dispatch_model
    model.to(device)
    ~~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 4343, in to
    return super().to(*args, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:21:26,726 - services.rag_service - WARNING - ML models not loaded for context retrieval
2026-01-05 10:21:26,727 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:21:26,727 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:21:26,727 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:21:26,749 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:21:26,750 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:21:30,761 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:21:30,764 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:21:30,769 - services.rag_service - ERROR - Failed to load model for streaming
2026-01-05 10:21:30,770 - routes.chat_routes - ERROR - Streaming error: Model not available. Please try again.
2026-01-05 10:21:30,775 - routes.chat_routes - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\routes\chat_routes.py", line 426, in generate
    for chunk in stream_answer(prompt, max_tokens=150):
                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 463, in stream_answer
    raise RuntimeError("Model not available. Please try again.")
RuntimeError: Model not available. Please try again.

2026-01-05 10:21:30,776 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:21:30] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 10:21:30,805 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:21:30,806 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:21:30,807 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:21:30,816 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:21:30,817 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:21:31,205 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:21:31,205 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:21:31,206 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 12.19s - Ready for FAST inference on CUDA
2026-01-05 10:21:31,206 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:21:32,236 - services.rag_service - INFO - [OK] Response generated in 1.03s (146 chars)
2026-01-05 10:21:32,236 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever is an indication of infection or inflammatio...
2026-01-05 10:21:32,237 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:21:34,971 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:21:34,973 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:21:34,976 - services.rag_service - WARNING - ML models not loaded for context retrieval
2026-01-05 10:21:34,976 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:21:34,976 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:21:34,977 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:21:34,980 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:21:34,981 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:21:40,215 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 10:21:40,220 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 10:21:40,233 - services.rag_service - ERROR - Failed to load model
2026-01-05 10:21:40,241 - routes.chat_routes - INFO - Response generated for chat 6754b74b-800c-4360-9c29-22b9ab14aa5c (type: medical)
2026-01-05 10:21:40,246 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:21:40] "POST /chat/ask HTTP/1.1" 200 -
2026-01-05 10:21:40,576 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:21:40] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:22:24,426 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:22:24,426 - __main__ - INFO - CORS enabled
2026-01-05 10:22:24,427 - __main__ - INFO - JWT initialized
2026-01-05 10:22:24,432 - __main__ - INFO - Blueprints registered
2026-01-05 10:22:24,434 - __main__ - INFO - ============================================================
2026-01-05 10:22:24,434 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:22:24,434 - __main__ - INFO - ============================================================
2026-01-05 10:22:24,434 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:22:24,434 - __main__ - INFO - Port: 5000
2026-01-05 10:22:24,435 - __main__ - INFO - Debug: True
2026-01-05 10:22:24,435 - __main__ - INFO - ============================================================
2026-01-05 10:22:24,435 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:22:24,480 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 10:22:24,481 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 10:22:24,486 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:22:24,568 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:22:24,587 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:22:24,934 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:22:24,935 - __main__ - INFO - CORS enabled
2026-01-05 10:22:24,935 - __main__ - INFO - JWT initialized
2026-01-05 10:22:24,939 - __main__ - INFO - Blueprints registered
2026-01-05 10:22:24,940 - __main__ - INFO - ============================================================
2026-01-05 10:22:24,940 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:22:24,941 - __main__ - INFO - ============================================================
2026-01-05 10:22:24,941 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:22:24,941 - __main__ - INFO - Port: 5000
2026-01-05 10:22:24,944 - __main__ - INFO - Debug: True
2026-01-05 10:22:24,944 - __main__ - INFO - ============================================================
2026-01-05 10:22:24,944 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:22:24,976 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:22:24,980 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:22:25,101 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:22:25,118 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:22:29,850 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:22:29,866 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:22:29,867 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:22:29,921 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:22:29,921 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:22:30,306 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:22:30,320 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:22:30,320 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:22:30,362 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:22:30,362 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:22:34,786 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:22:34,807 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:22:34,842 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:22:35,172 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:22:35,732 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:22:35,758 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:22:35,793 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:22:36,011 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:22:37,319 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:22:37,320 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:22:37,320 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 7.47s - Ready for FAST inference on CUDA
2026-01-05 10:22:37,320 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:22:38,201 - services.rag_service - INFO - [OK] Response generated in 0.88s (146 chars)
2026-01-05 10:22:38,202 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever is the body's natural response to infection ...
2026-01-05 10:22:38,202 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:22:38,394 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:22:38,394 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:22:38,395 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 8.09s - Ready for FAST inference on CUDA
2026-01-05 10:22:38,395 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:22:39,266 - services.rag_service - INFO - [OK] Response generated in 0.87s (154 chars)
2026-01-05 10:22:39,267 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever is a body temperature that is higher than th...
2026-01-05 10:22:39,269 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:22:50,048 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:22:50,048 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 10:22:50,049 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:22:50,206 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 10:22:50,532 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:22:50] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 10:22:52,242 - services.rag_service - INFO - [OK] Response generated in 2.19s (148 chars)
2026-01-05 10:22:52,243 - __main__ - INFO - [OK] Model warmup complete - Test response: A person's body temperature rises above normal lev...
2026-01-05 10:22:52,244 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:22:57,236 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:22:57] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:25:04,646 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:25:05,977 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:25:06,470 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:25:06,471 - __main__ - INFO - CORS enabled
2026-01-05 10:25:06,471 - __main__ - INFO - JWT initialized
2026-01-05 10:25:06,475 - __main__ - INFO - Blueprints registered
2026-01-05 10:25:06,476 - __main__ - INFO - ============================================================
2026-01-05 10:25:06,476 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:25:06,476 - __main__ - INFO - ============================================================
2026-01-05 10:25:06,476 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:25:06,477 - __main__ - INFO - Port: 5000
2026-01-05 10:25:06,477 - __main__ - INFO - Debug: True
2026-01-05 10:25:06,477 - __main__ - INFO - ============================================================
2026-01-05 10:25:06,477 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:25:06,505 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:25:06,509 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:25:06,615 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:25:06,630 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:25:12,564 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:25:12,581 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:25:12,582 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:25:12,641 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:25:12,641 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:25:14,013 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:25:15,113 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:25:15,552 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:25:15,553 - __main__ - INFO - CORS enabled
2026-01-05 10:25:15,553 - __main__ - INFO - JWT initialized
2026-01-05 10:25:15,557 - __main__ - INFO - Blueprints registered
2026-01-05 10:25:15,557 - __main__ - INFO - ============================================================
2026-01-05 10:25:15,558 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:25:15,558 - __main__ - INFO - ============================================================
2026-01-05 10:25:15,558 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:25:15,558 - __main__ - INFO - Port: 5000
2026-01-05 10:25:15,558 - __main__ - INFO - Debug: True
2026-01-05 10:25:15,558 - __main__ - INFO - ============================================================
2026-01-05 10:25:15,558 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:25:15,586 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:25:15,590 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:25:15,691 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:25:15,708 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:25:21,224 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:25:21,242 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:25:21,243 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:25:21,303 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:25:21,304 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:25:21,916 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:25:22,899 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:25:23,392 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:25:23,393 - __main__ - INFO - CORS enabled
2026-01-05 10:25:23,393 - __main__ - INFO - JWT initialized
2026-01-05 10:25:23,397 - __main__ - INFO - Blueprints registered
2026-01-05 10:25:23,398 - __main__ - INFO - ============================================================
2026-01-05 10:25:23,398 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:25:23,398 - __main__ - INFO - ============================================================
2026-01-05 10:25:23,398 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:25:23,398 - __main__ - INFO - Port: 5000
2026-01-05 10:25:23,399 - __main__ - INFO - Debug: True
2026-01-05 10:25:23,399 - __main__ - INFO - ============================================================
2026-01-05 10:25:23,399 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:25:23,429 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:25:23,433 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:25:23,529 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:25:23,545 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:25:28,636 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:25:28,651 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:25:28,652 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:25:28,708 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:25:28,708 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:25:33,813 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:25:33,886 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:25:33,941 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:25:34,327 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:25:39,725 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:25:39,726 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:25:39,727 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 11.09s - Ready for FAST inference on CUDA
2026-01-05 10:25:39,728 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:25:39,757 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:25:41,921 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:25:42,387 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:25:42,388 - __main__ - INFO - CORS enabled
2026-01-05 10:25:42,388 - __main__ - INFO - JWT initialized
2026-01-05 10:25:42,391 - __main__ - INFO - Blueprints registered
2026-01-05 10:25:42,394 - __main__ - INFO - ============================================================
2026-01-05 10:25:42,395 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:25:42,396 - __main__ - INFO - ============================================================
2026-01-05 10:25:42,396 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:25:42,396 - __main__ - INFO - Port: 5000
2026-01-05 10:25:42,396 - __main__ - INFO - Debug: True
2026-01-05 10:25:42,396 - __main__ - INFO - ============================================================
2026-01-05 10:25:42,397 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:25:42,419 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:25:42,430 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:25:42,576 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:25:42,590 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:25:43,607 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:25:43,609 - torch._subclasses.fake_tensor - INFO - FakeTensor cache stats:
2026-01-05 10:25:43,609 - torch._subclasses.fake_tensor - INFO -   cache_hits: 0
2026-01-05 10:25:43,610 - torch._subclasses.fake_tensor - INFO -   cache_misses: 0
2026-01-05 10:25:44,162 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:25:44,547 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:25:44,553 - __main__ - INFO - CORS enabled
2026-01-05 10:25:44,556 - __main__ - INFO - JWT initialized
2026-01-05 10:25:44,561 - __main__ - INFO - Blueprints registered
2026-01-05 10:25:44,562 - __main__ - INFO - ============================================================
2026-01-05 10:25:44,588 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:25:44,588 - __main__ - INFO - ============================================================
2026-01-05 10:25:44,588 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:25:44,589 - __main__ - INFO - Port: 5000
2026-01-05 10:25:44,589 - __main__ - INFO - Debug: True
2026-01-05 10:25:44,589 - __main__ - INFO - ============================================================
2026-01-05 10:25:44,591 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:25:44,652 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:25:44,659 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:25:44,760 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:25:44,781 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:25:46,408 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:25:46,408 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 10:25:51,460 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:25:51,461 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:25:51,461 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:25:51,481 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:25:51,481 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:25:51,482 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:25:51,481 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:25:51,481 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:25:51,544 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:25:51,547 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:25:51,547 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:25:51,547 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:25:51,547 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:25:51,547 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:25:51,548 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:25:56,845 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:25:56,856 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:25:56,867 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:25:56,904 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:25:56,904 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:25:56,941 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:26:12,798 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:26:12,799 - __main__ - INFO - CORS enabled
2026-01-05 10:26:12,799 - __main__ - INFO - JWT initialized
2026-01-05 10:26:12,802 - __main__ - INFO - Blueprints registered
2026-01-05 10:26:12,803 - __main__ - INFO - ============================================================
2026-01-05 10:26:12,803 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:26:12,803 - __main__ - INFO - ============================================================
2026-01-05 10:26:12,803 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:26:12,803 - __main__ - INFO - Port: 5000
2026-01-05 10:26:12,804 - __main__ - INFO - Debug: True
2026-01-05 10:26:12,804 - __main__ - INFO - ============================================================
2026-01-05 10:26:12,804 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:26:12,841 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 10:26:12,842 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 10:26:12,844 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:26:12,921 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:26:12,936 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:26:13,271 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:26:13,271 - __main__ - INFO - CORS enabled
2026-01-05 10:26:13,271 - __main__ - INFO - JWT initialized
2026-01-05 10:26:13,274 - __main__ - INFO - Blueprints registered
2026-01-05 10:26:13,275 - __main__ - INFO - ============================================================
2026-01-05 10:26:13,276 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:26:13,276 - __main__ - INFO - ============================================================
2026-01-05 10:26:13,276 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:26:13,276 - __main__ - INFO - Port: 5000
2026-01-05 10:26:13,276 - __main__ - INFO - Debug: True
2026-01-05 10:26:13,276 - __main__ - INFO - ============================================================
2026-01-05 10:26:13,276 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:26:13,302 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:26:13,306 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:26:13,406 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:26:13,420 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:26:17,924 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:26:17,939 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:26:17,939 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:26:17,996 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:26:17,996 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:26:18,296 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:26:18,310 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:26:18,310 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:26:18,349 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:26:18,349 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:26:22,626 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:26:22,645 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:26:22,679 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:26:22,936 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:26:22,957 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:26:22,989 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:26:23,093 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:26:23,174 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 10:26:25,972 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:26:25,973 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:26:25,973 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 8.05s - Ready for FAST inference on CUDA
2026-01-05 10:26:25,973 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:26:26,584 - services.rag_service - INFO - [OK] Model compiled with torch.compile for faster inference
2026-01-05 10:26:26,584 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 2.29 GB VRAM
2026-01-05 10:26:26,585 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 8.29s - Ready for FAST inference on CUDA
2026-01-05 10:26:26,585 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:26:27,299 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:26:27,300 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 10:26:27,300 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 10:26:27,304 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:26:27] "GET /chat/history?chatId=43e3b2f0-3651-45ec-bb42-351d6d90ccd7 HTTP/1.1" 200 -
2026-01-05 10:26:27,745 - services.rag_service - INFO - [OK] Response generated in 1.77s (146 chars)
2026-01-05 10:26:27,746 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever refers to the body's response to infection o...
2026-01-05 10:26:27,747 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:26:29,341 - services.rag_service - INFO - [OK] Response generated in 2.76s (121 chars)
2026-01-05 10:26:29,346 - __main__ - INFO - [OK] Model warmup complete - Test response: A temperature of 100F (38C) or higher, usually a...
2026-01-05 10:26:29,360 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:26:29,909 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:26:29] "OPTIONS /chat/delete/43e3b2f0-3651-45ec-bb42-351d6d90ccd7 HTTP/1.1" 200 -
2026-01-05 10:26:30,003 - services.rag_service - INFO - [OK] Response generated in 2.70s (142 chars)
2026-01-05 10:26:30,006 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever is the body's natural response to infection ...
2026-01-05 10:26:30,007 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 10:26:30,230 - routes.chat_routes - INFO - Deleted chat 43e3b2f0-3651-45ec-bb42-351d6d90ccd7 for user 6958bd2f226bdd90f9c905fb
2026-01-05 10:26:30,231 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:26:30] "DELETE /chat/delete/43e3b2f0-3651-45ec-bb42-351d6d90ccd7 HTTP/1.1" 200 -
2026-01-05 10:26:31,267 - routes.chat_routes - INFO - [OK] Created new chat f5be5415-5e64-460e-98fa-1d5933666c6f for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 10:26:31,268 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:26:31] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 10:26:34,259 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 10:26:34,734 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:26:34] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 10:26:49,909 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 10:26:49] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 10:28:08,864 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:28:10,289 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:28:10,724 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:28:10,724 - __main__ - INFO - CORS enabled
2026-01-05 10:28:10,724 - __main__ - INFO - JWT initialized
2026-01-05 10:28:10,727 - __main__ - INFO - Blueprints registered
2026-01-05 10:28:10,727 - __main__ - INFO - ============================================================
2026-01-05 10:28:10,728 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:28:10,728 - __main__ - INFO - ============================================================
2026-01-05 10:28:10,728 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:28:10,728 - __main__ - INFO - Port: 5000
2026-01-05 10:28:10,728 - __main__ - INFO - Debug: True
2026-01-05 10:28:10,728 - __main__ - INFO - ============================================================
2026-01-05 10:28:10,729 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:28:10,757 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:28:10,765 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:28:10,872 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:28:10,888 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:28:15,996 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:28:16,010 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:28:16,011 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:28:16,062 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:28:16,062 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:28:18,253 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:28:19,351 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:28:19,848 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:28:19,848 - __main__ - INFO - CORS enabled
2026-01-05 10:28:19,849 - __main__ - INFO - JWT initialized
2026-01-05 10:28:19,854 - __main__ - INFO - Blueprints registered
2026-01-05 10:28:19,855 - __main__ - INFO - ============================================================
2026-01-05 10:28:19,855 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:28:19,855 - __main__ - INFO - ============================================================
2026-01-05 10:28:19,855 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:28:19,856 - __main__ - INFO - Port: 5000
2026-01-05 10:28:19,856 - __main__ - INFO - Debug: True
2026-01-05 10:28:19,856 - __main__ - INFO - ============================================================
2026-01-05 10:28:19,857 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:28:19,889 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:28:19,894 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:28:19,995 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:28:20,011 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:28:25,074 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:28:25,094 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:28:25,094 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:28:25,161 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:28:25,161 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:28:25,985 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 10:28:27,036 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:28:27,579 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:28:27,579 - __main__ - INFO - CORS enabled
2026-01-05 10:28:27,579 - __main__ - INFO - JWT initialized
2026-01-05 10:28:27,582 - __main__ - INFO - Blueprints registered
2026-01-05 10:28:27,583 - __main__ - INFO - ============================================================
2026-01-05 10:28:27,583 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:28:27,583 - __main__ - INFO - ============================================================
2026-01-05 10:28:27,583 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:28:27,583 - __main__ - INFO - Port: 5000
2026-01-05 10:28:27,583 - __main__ - INFO - Debug: True
2026-01-05 10:28:27,583 - __main__ - INFO - ============================================================
2026-01-05 10:28:27,584 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:28:27,610 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:28:27,614 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:28:27,699 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:28:27,713 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:28:32,806 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:28:32,822 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:28:32,822 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:28:32,879 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:28:32,879 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:28:38,589 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:28:38,609 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:28:38,644 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:28:40,499 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2026-01-05 10:28:44,766 - services.rag_service - ERROR - Failed to load ML models: No package metadata was found for bitsandbytes
2026-01-05 10:28:44,782 - services.rag_service - ERROR - Traceback (most recent call last):
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\Lib\importlib\metadata\__init__.py", line 407, in from_name
    return next(iter(cls.discover(name=name)))
StopIteration

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 104, in _load_models
    quantization_config = BitsAndBytesConfig(
        load_in_4bit=True,
    ...<2 lines>...
        bnb_4bit_quant_type="nf4"
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\utils\quantization_config.py", line 510, in __init__
    self.post_init()
    ~~~~~~~~~~~~~~^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\utils\quantization_config.py", line 568, in post_init
    if self.load_in_4bit and not version.parse(importlib.metadata.version("bitsandbytes")) >= version.parse(
                                               ~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\Lib\importlib\metadata\__init__.py", line 987, in version
    return distribution(distribution_name).version
           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\Lib\importlib\metadata\__init__.py", line 960, in distribution
    return Distribution.from_name(distribution_name)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.2544.0_x64__qbz5n2kfra8p0\Lib\importlib\metadata\__init__.py", line 409, in from_name
    raise PackageNotFoundError(name)
importlib.metadata.PackageNotFoundError: No package metadata was found for bitsandbytes

2026-01-05 10:28:44,783 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 10:29:34,120 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:29:34,120 - __main__ - INFO - CORS enabled
2026-01-05 10:29:34,120 - __main__ - INFO - JWT initialized
2026-01-05 10:29:34,123 - __main__ - INFO - Blueprints registered
2026-01-05 10:29:34,124 - __main__ - INFO - ============================================================
2026-01-05 10:29:34,124 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:29:34,124 - __main__ - INFO - ============================================================
2026-01-05 10:29:34,124 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:29:34,124 - __main__ - INFO - Port: 5000
2026-01-05 10:29:34,124 - __main__ - INFO - Debug: True
2026-01-05 10:29:34,125 - __main__ - INFO - ============================================================
2026-01-05 10:29:34,125 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:29:34,161 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 10:29:34,162 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 10:29:34,164 - werkzeug - INFO -  * Restarting with stat
2026-01-05 10:29:34,250 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:29:34,264 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:29:34,645 - __main__ - INFO - Configuration loaded: Config
2026-01-05 10:29:34,646 - __main__ - INFO - CORS enabled
2026-01-05 10:29:34,646 - __main__ - INFO - JWT initialized
2026-01-05 10:29:34,650 - __main__ - INFO - Blueprints registered
2026-01-05 10:29:34,650 - __main__ - INFO - ============================================================
2026-01-05 10:29:34,651 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 10:29:34,651 - __main__ - INFO - ============================================================
2026-01-05 10:29:34,651 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 10:29:34,652 - __main__ - INFO - Port: 5000
2026-01-05 10:29:34,652 - __main__ - INFO - Debug: True
2026-01-05 10:29:34,652 - __main__ - INFO - ============================================================
2026-01-05 10:29:34,652 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 10:29:34,682 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 10:29:34,687 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 10:29:34,786 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 10:29:34,800 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 10:29:39,483 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:29:39,502 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:29:39,502 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:29:39,562 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:29:39,562 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:29:39,959 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 10:29:39,974 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 10:29:39,975 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 10:29:40,015 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 10:29:40,016 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 10:29:45,429 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:29:45,451 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:29:45,487 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:29:46,021 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 10:29:46,042 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 10:29:46,075 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 10:29:48,681 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2026-01-05 10:29:48,687 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2026-01-05 10:29:48,717 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2026-01-05 11:08:27,794 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:08:27,795 - __main__ - INFO - CORS enabled
2026-01-05 11:08:27,795 - __main__ - INFO - JWT initialized
2026-01-05 11:08:27,802 - __main__ - INFO - Blueprints registered
2026-01-05 11:08:27,803 - __main__ - INFO - ============================================================
2026-01-05 11:08:27,803 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:08:27,803 - __main__ - INFO - ============================================================
2026-01-05 11:08:27,804 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:08:27,804 - __main__ - INFO - Port: 5000
2026-01-05 11:08:27,804 - __main__ - INFO - Debug: True
2026-01-05 11:08:27,804 - __main__ - INFO - ============================================================
2026-01-05 11:08:27,805 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:08:27,865 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 11:08:27,866 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 11:08:27,867 - werkzeug - INFO -  * Restarting with stat
2026-01-05 11:08:27,948 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:08:27,976 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:08:28,330 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:08:28,331 - __main__ - INFO - CORS enabled
2026-01-05 11:08:28,331 - __main__ - INFO - JWT initialized
2026-01-05 11:08:28,334 - __main__ - INFO - Blueprints registered
2026-01-05 11:08:28,335 - __main__ - INFO - ============================================================
2026-01-05 11:08:28,335 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:08:28,336 - __main__ - INFO - ============================================================
2026-01-05 11:08:28,336 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:08:28,336 - __main__ - INFO - Port: 5000
2026-01-05 11:08:28,336 - __main__ - INFO - Debug: True
2026-01-05 11:08:28,336 - __main__ - INFO - ============================================================
2026-01-05 11:08:28,336 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:08:28,373 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:08:28,377 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 11:08:28,480 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:08:28,494 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:08:34,398 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 11:08:34,398 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 11:08:34,423 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 11:08:34,423 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 11:08:34,423 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 11:08:34,423 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 11:08:34,540 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 11:08:34,541 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:08:34,542 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 11:08:34,542 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:08:39,411 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 11:08:39,457 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:08:39,495 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:08:39,622 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 11:08:39,647 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:08:39,679 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:08:50,251 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2026-01-05 11:10:43,790 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:10:43,795 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:43] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 11:10:43,799 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 11:10:43,799 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:10:43,823 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:43] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 11:10:43,823 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 11:10:43,826 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:43] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 11:10:43,839 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:43] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 11:10:43,846 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 11:10:43,881 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 11:10:43,887 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:10:44,026 - routes.chat_routes - INFO - [OK] Created new chat ebe2882c-6a6f-4e5a-be1a-15aa2a22673f for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:10:44,028 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:44] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:10:44,112 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:44] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:10:44,151 - routes.chat_routes - INFO - [OK] Created new chat 5317061b-e9fa-4937-8e9d-c067861259d1 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:10:44,153 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:44] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:10:44,183 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:10:44] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:10:50,375 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 11:10:50,424 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:10:50,501 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:13:18,312 - huggingface_hub.file_download - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
2026-01-05 11:13:18,333 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 11:13:20,669 - services.rag_service - INFO - [OK] GPT-2 Medium loaded on GPU
2026-01-05 11:13:20,670 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 0.92 GB VRAM
2026-01-05 11:13:20,670 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 286.27s - Ready for FAST inference on CUDA
2026-01-05 11:13:20,670 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:13:21,908 - services.rag_service - INFO - [OK] Response generated in 1.24s (161 chars)
2026-01-05 11:13:21,909 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever means the body's response to an infectious o...
2026-01-05 11:13:21,909 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:18:09,142 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 11:18:09,152 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 11:18:11,233 - services.rag_service - INFO - [OK] GPT-2 Medium loaded on GPU
2026-01-05 11:18:11,233 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 0.93 GB VRAM
2026-01-05 11:18:11,233 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 447.41s - Ready for FAST inference on CUDA
2026-01-05 11:18:11,234 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:18:11,297 - services.rag_service - INFO - [OK] GPT-2 Medium loaded on GPU
2026-01-05 11:18:11,297 - services.rag_service - INFO - [OK] Model loaded on GPU - Using 0.83 GB VRAM
2026-01-05 11:18:11,297 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 576.90s - Ready for FAST inference on CUDA
2026-01-05 11:18:11,298 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:18:11,780 - services.rag_service - INFO - [OK] Response generated in 0.55s (142 chars)
2026-01-05 11:18:11,781 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever, which means the body's response to infectio...
2026-01-05 11:18:11,781 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:18:12,069 - services.rag_service - INFO - [OK] Response generated in 0.77s (141 chars)
2026-01-05 11:18:12,070 - __main__ - INFO - [OK] Model warmup complete - Test response: Fever, also known as heat stroke or hypothermia (h...
2026-01-05 11:18:12,070 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:18:33,292 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:33] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-05 11:18:33,851 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-05 11:18:33,852 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:33] "POST /auth/login HTTP/1.1" 200 -
2026-01-05 11:18:33,918 - routes.chat_routes - INFO - [OK] Created new chat ea235f89-40c8-49df-851a-17cba91dce7f for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:18:33,919 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:33] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:18:34,228 - routes.chat_routes - INFO - [OK] Created new chat 4156501a-1568-4bf0-a0fc-2c2fb0fc22b0 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:18:34,231 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:34] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:18:34,234 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:34] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:18:34,554 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:34] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:18:36,455 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:36] "OPTIONS /chat/stream HTTP/1.1" 200 -
2026-01-05 11:18:37,012 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 11:18:37,075 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:18:37] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:19:01,407 - routes.chat_routes - INFO - [OK] Created new chat bf663e2b-b90e-4597-b013-20960a6a6275 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:19:01,408 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:01] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:19:01,710 - routes.chat_routes - INFO - [OK] Created new chat 70b2bbd7-3169-44dc-afdc-f024f0963559 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:19:01,712 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:01] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:19:01,723 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:01] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:19:02,037 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:02] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:19:06,213 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:06] "OPTIONS /chat/history?chatId=6754b74b-800c-4360-9c29-22b9ab14aa5c HTTP/1.1" 200 -
2026-01-05 11:19:06,529 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:06] "GET /chat/history?chatId=6754b74b-800c-4360-9c29-22b9ab14aa5c HTTP/1.1" 200 -
2026-01-05 11:19:07,271 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:07] "OPTIONS /chat/history?chatId=f5be5415-5e64-460e-98fa-1d5933666c6f HTTP/1.1" 200 -
2026-01-05 11:19:07,588 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:07] "GET /chat/history?chatId=f5be5415-5e64-460e-98fa-1d5933666c6f HTTP/1.1" 200 -
2026-01-05 11:19:08,678 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:08] "OPTIONS /chat/history?chatId=4156501a-1568-4bf0-a0fc-2c2fb0fc22b0 HTTP/1.1" 200 -
2026-01-05 11:19:08,990 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:08] "GET /chat/history?chatId=4156501a-1568-4bf0-a0fc-2c2fb0fc22b0 HTTP/1.1" 200 -
2026-01-05 11:19:21,575 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 11:19:21,728 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:21] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:19:35,883 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 11:19:37,086 - werkzeug - INFO -  * Restarting with stat
2026-01-05 11:19:37,657 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:19:37,657 - __main__ - INFO - CORS enabled
2026-01-05 11:19:37,657 - __main__ - INFO - JWT initialized
2026-01-05 11:19:37,660 - __main__ - INFO - Blueprints registered
2026-01-05 11:19:37,661 - __main__ - INFO - ============================================================
2026-01-05 11:19:37,661 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:19:37,661 - __main__ - INFO - ============================================================
2026-01-05 11:19:37,661 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:19:37,661 - __main__ - INFO - Port: 5000
2026-01-05 11:19:37,661 - __main__ - INFO - Debug: True
2026-01-05 11:19:37,661 - __main__ - INFO - ============================================================
2026-01-05 11:19:37,662 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:19:37,692 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:19:37,701 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 11:19:37,766 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:19:37,766 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:19:37,768 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:19:37] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:19:37,814 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:19:37,829 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:19:43,919 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 11:19:43,936 - services.rag_service - INFO - [LOADING] Loading ML models with MAXIMUM optimization...
2026-01-05 11:19:43,938 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 11:19:43,938 - services.rag_service - INFO - [OK] GPU detected: NVIDIA GeForce RTX 3050 6GB Laptop GPU
2026-01-05 11:19:43,938 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 11:19:43,938 - services.rag_service - INFO - [OK] GPU Memory: 6.44 GB
2026-01-05 11:19:44,001 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 11:19:44,001 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cuda:0
2026-01-05 11:19:44,001 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:19:44,001 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:19:48,941 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:19:48,949 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")  # Faster than mpnet
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:19:48,954 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:19:49,037 - services.rag_service - INFO - [OK] Embedder loaded on CUDA
2026-01-05 11:19:49,098 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:19:49,156 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:19:51,463 - accelerate.utils.modeling - INFO - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2026-01-05 11:19:51,481 - accelerate.utils.modeling - WARNING - The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.
2026-01-05 11:19:53,979 - services.rag_service - ERROR - Failed to load ML models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:19:53,996 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 103, in _load_models
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
    ...<2 lines>...
        use_cache=True,
    )
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\models\auto\auto_factory.py", line 604, in from_pretrained
    return model_class.from_pretrained(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        pretrained_model_name_or_path, *model_args, config=config, **hub_kwargs, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 277, in _wrapper
    return func(*args, **kwargs)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 5140, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
    ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\accelerate\big_modeling.py", line 502, in dispatch_model
    model.to(device)
    ~~~~~~~~^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\transformers\modeling_utils.py", line 4343, in to
    return super().to(*args, **kwargs)
           ~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1355, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 915, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 942, in _apply
    param_applied = fn(param)
  File "D:\OneDrive\Desktop\Final Year Project\Backend\venv\Lib\site-packages\torch\nn\modules\module.py", line 1348, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:19:54,001 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:36:20,528 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:36:20,529 - __main__ - INFO - CORS enabled
2026-01-05 11:36:20,529 - __main__ - INFO - JWT initialized
2026-01-05 11:36:20,535 - __main__ - INFO - Blueprints registered
2026-01-05 11:36:20,536 - __main__ - INFO - ============================================================
2026-01-05 11:36:20,536 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:36:20,537 - __main__ - INFO - ============================================================
2026-01-05 11:36:20,537 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:36:20,538 - __main__ - INFO - Port: 5000
2026-01-05 11:36:20,538 - __main__ - INFO - Debug: True
2026-01-05 11:36:20,539 - __main__ - INFO - ============================================================
2026-01-05 11:36:20,540 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:36:20,668 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 11:36:20,668 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 11:36:20,879 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:36:22,632 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:36:22,632 - __main__ - INFO - CORS enabled
2026-01-05 11:36:22,633 - __main__ - INFO - JWT initialized
2026-01-05 11:36:22,636 - __main__ - INFO - Blueprints registered
2026-01-05 11:36:22,637 - __main__ - INFO - ============================================================
2026-01-05 11:36:22,637 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:36:22,638 - __main__ - INFO - ============================================================
2026-01-05 11:36:22,638 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:36:22,638 - __main__ - INFO - Port: 5000
2026-01-05 11:36:22,638 - __main__ - INFO - Debug: True
2026-01-05 11:36:22,638 - __main__ - INFO - ============================================================
2026-01-05 11:36:22,638 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:36:22,651 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:36:22,657 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:36:23,685 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:36:23,687 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:36:23,835 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:36:23,835 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:36:28,144 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\__init__.py', reloading
2026-01-05 11:36:28,144 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\__init__.py', reloading
2026-01-05 11:36:28,145 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\__init__.py', reloading
2026-01-05 11:36:28,145 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\answer.py', reloading
2026-01-05 11:36:28,146 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\answer.py', reloading
2026-01-05 11:36:28,146 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\caching.py', reloading
2026-01-05 11:36:28,147 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\caching.py', reloading
2026-01-05 11:36:28,148 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\client.py', reloading
2026-01-05 11:36:28,148 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\client.py', reloading
2026-01-05 11:36:28,149 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\embedding.py', reloading
2026-01-05 11:36:28,150 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\embedding.py', reloading
2026-01-05 11:36:28,152 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\files.py', reloading
2026-01-05 11:36:28,153 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\files.py', reloading
2026-01-05 11:36:28,154 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\generative_models.py', reloading
2026-01-05 11:36:28,154 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\generative_models.py', reloading
2026-01-05 11:36:28,155 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\models.py', reloading
2026-01-05 11:36:28,156 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\models.py', reloading
2026-01-05 11:36:28,156 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\operations.py', reloading
2026-01-05 11:36:28,157 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\operations.py', reloading
2026-01-05 11:36:28,158 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\permission.py', reloading
2026-01-05 11:36:28,158 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\permission.py', reloading
2026-01-05 11:36:28,159 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\protos.py', reloading
2026-01-05 11:36:28,159 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\protos.py', reloading
2026-01-05 11:36:28,160 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\responder.py', reloading
2026-01-05 11:36:28,160 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\responder.py', reloading
2026-01-05 11:36:28,160 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\retriever.py', reloading
2026-01-05 11:36:28,161 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\retriever.py', reloading
2026-01-05 11:36:28,162 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\string_utils.py', reloading
2026-01-05 11:36:28,163 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\string_utils.py', reloading
2026-01-05 11:36:28,164 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\utils.py', reloading
2026-01-05 11:36:28,165 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\utils.py', reloading
2026-01-05 11:36:28,165 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\version.py', reloading
2026-01-05 11:36:28,167 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\version.py', reloading
2026-01-05 11:36:28,167 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\argument_parser.py', reloading
2026-01-05 11:36:28,167 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\cmd_line_parser.py', reloading
2026-01-05 11:36:28,168 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\__init__.py', reloading
2026-01-05 11:36:28,168 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\__init__.py', reloading
2026-01-05 11:36:28,168 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\__init__.py', reloading
2026-01-05 11:36:28,169 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\argument_parser.py', reloading
2026-01-05 11:36:28,169 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\argument_parser.py', reloading
2026-01-05 11:36:28,169 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\cmd_line_parser.py', reloading
2026-01-05 11:36:28,169 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\cmd_line_parser.py', reloading
2026-01-05 11:36:28,170 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\command.py', reloading
2026-01-05 11:36:28,170 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\command.py', reloading
2026-01-05 11:36:28,170 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\command_utils.py', reloading
2026-01-05 11:36:28,170 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\command_utils.py', reloading
2026-01-05 11:36:28,171 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\compare_cmd.py', reloading
2026-01-05 11:36:28,171 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\compare_cmd.py', reloading
2026-01-05 11:36:28,171 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\compile_cmd.py', reloading
2026-01-05 11:36:28,172 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\compile_cmd.py', reloading
2026-01-05 11:36:28,172 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\eval_cmd.py', reloading
2026-01-05 11:36:28,173 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\eval_cmd.py', reloading
2026-01-05 11:36:28,173 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\flag_def.py', reloading
2026-01-05 11:36:28,174 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\flag_def.py', reloading
2026-01-05 11:36:28,174 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\gspread_client.py', reloading
2026-01-05 11:36:28,175 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\gspread_client.py', reloading
2026-01-05 11:36:28,175 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\html_utils.py', reloading
2026-01-05 11:36:28,175 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\html_utils.py', reloading
2026-01-05 11:36:28,176 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\input_utils.py', reloading
2026-01-05 11:36:28,176 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\input_utils.py', reloading
2026-01-05 11:36:28,176 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\ipython_env.py', reloading
2026-01-05 11:36:28,177 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\ipython_env.py', reloading
2026-01-05 11:36:28,177 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\ipython_env_impl.py', reloading
2026-01-05 11:36:28,177 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\ipython_env_impl.py', reloading
2026-01-05 11:36:28,178 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\magics.py', reloading
2026-01-05 11:36:28,178 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\magics.py', reloading
2026-01-05 11:36:28,179 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\magics_engine.py', reloading
2026-01-05 11:36:28,179 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\magics_engine.py', reloading
2026-01-05 11:36:28,180 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\model_registry.py', reloading
2026-01-05 11:36:28,180 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\model_registry.py', reloading
2026-01-05 11:36:28,180 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\output_utils.py', reloading
2026-01-05 11:36:28,180 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\output_utils.py', reloading
2026-01-05 11:36:28,181 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\parsed_args_lib.py', reloading
2026-01-05 11:36:28,181 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\parsed_args_lib.py', reloading
2026-01-05 11:36:28,182 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\post_process_utils.py', reloading
2026-01-05 11:36:28,182 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\post_process_utils.py', reloading
2026-01-05 11:36:28,183 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\post_process_utils_test_helper.py', reloading
2026-01-05 11:36:28,183 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\post_process_utils_test_helper.py', reloading
2026-01-05 11:36:28,183 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\py_utils.py', reloading
2026-01-05 11:36:28,184 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\py_utils.py', reloading
2026-01-05 11:36:28,184 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\run_cmd.py', reloading
2026-01-05 11:36:28,185 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\run_cmd.py', reloading
2026-01-05 11:36:28,185 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\sheets_id.py', reloading
2026-01-05 11:36:28,186 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\sheets_id.py', reloading
2026-01-05 11:36:28,186 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\sheets_sanitize_url.py', reloading
2026-01-05 11:36:28,187 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\sheets_sanitize_url.py', reloading
2026-01-05 11:36:28,187 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\sheets_utils.py', reloading
2026-01-05 11:36:28,188 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\sheets_utils.py', reloading
2026-01-05 11:36:28,188 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\text_model.py', reloading
2026-01-05 11:36:28,188 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\text_model.py', reloading
2026-01-05 11:36:28,189 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llm_function.py', reloading
2026-01-05 11:36:28,189 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\__init__.py', reloading
2026-01-05 11:36:28,190 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\__init__.py', reloading
2026-01-05 11:36:28,190 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\__init__.py', reloading
2026-01-05 11:36:28,190 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llm_function.py', reloading
2026-01-05 11:36:28,191 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llm_function.py', reloading
2026-01-05 11:36:28,191 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_input_utils.py', reloading
2026-01-05 11:36:28,191 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_input_utils.py', reloading
2026-01-05 11:36:28,192 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_inputs_source.py', reloading
2026-01-05 11:36:28,192 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_inputs_source.py', reloading
2026-01-05 11:36:28,193 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_output_row.py', reloading
2026-01-05 11:36:28,193 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_output_row.py', reloading
2026-01-05 11:36:28,193 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_outputs.py', reloading
2026-01-05 11:36:28,194 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_outputs.py', reloading
2026-01-05 11:36:28,194 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_post_process.py', reloading
2026-01-05 11:36:28,194 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_post_process.py', reloading
2026-01-05 11:36:28,195 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_post_process_cmds.py', reloading
2026-01-05 11:36:28,195 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\llmfn_post_process_cmds.py', reloading
2026-01-05 11:36:28,196 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\model.py', reloading
2026-01-05 11:36:28,196 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\model.py', reloading
2026-01-05 11:36:28,197 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\prompt_utils.py', reloading
2026-01-05 11:36:28,197 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\prompt_utils.py', reloading
2026-01-05 11:36:28,197 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\unique_fn.py', reloading
2026-01-05 11:36:28,198 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\notebook\\lib\\unique_fn.py', reloading
2026-01-05 11:36:28,198 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\__init__.py', reloading
2026-01-05 11:36:28,199 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\__init__.py', reloading
2026-01-05 11:36:28,200 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\__init__.py', reloading
2026-01-05 11:36:28,200 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\answer_types.py', reloading
2026-01-05 11:36:28,201 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\answer_types.py', reloading
2026-01-05 11:36:28,202 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\caching_types.py', reloading
2026-01-05 11:36:28,202 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\caching_types.py', reloading
2026-01-05 11:36:28,202 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\citation_types.py', reloading
2026-01-05 11:36:28,203 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\citation_types.py', reloading
2026-01-05 11:36:28,203 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\content_types.py', reloading
2026-01-05 11:36:28,203 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\content_types.py', reloading
2026-01-05 11:36:28,204 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\file_types.py', reloading
2026-01-05 11:36:28,204 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\file_types.py', reloading
2026-01-05 11:36:28,204 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\generation_types.py', reloading
2026-01-05 11:36:28,205 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\generation_types.py', reloading
2026-01-05 11:36:28,205 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\helper_types.py', reloading
2026-01-05 11:36:28,206 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\helper_types.py', reloading
2026-01-05 11:36:28,206 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\model_types.py', reloading
2026-01-05 11:36:28,207 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\model_types.py', reloading
2026-01-05 11:36:28,207 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\palm_safety_types.py', reloading
2026-01-05 11:36:28,207 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\palm_safety_types.py', reloading
2026-01-05 11:36:28,207 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\permission_types.py', reloading
2026-01-05 11:36:28,208 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\permission_types.py', reloading
2026-01-05 11:36:28,208 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\retriever_types.py', reloading
2026-01-05 11:36:28,208 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\retriever_types.py', reloading
2026-01-05 11:36:28,208 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\safety_types.py', reloading
2026-01-05 11:36:28,208 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\safety_types.py', reloading
2026-01-05 11:36:28,209 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\text_types.py', reloading
2026-01-05 11:36:28,209 - werkzeug - INFO -  * Detected change in 'C:\\Users\\prasa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\google\\generativeai\\types\\text_types.py', reloading
2026-01-05 11:36:31,593 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:36:32,547 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:36:32,547 - __main__ - INFO - CORS enabled
2026-01-05 11:36:32,548 - __main__ - INFO - JWT initialized
2026-01-05 11:36:32,551 - __main__ - INFO - Blueprints registered
2026-01-05 11:36:32,552 - __main__ - INFO - ============================================================
2026-01-05 11:36:32,553 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:36:32,553 - __main__ - INFO - ============================================================
2026-01-05 11:36:32,554 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:36:32,555 - __main__ - INFO - Port: 5000
2026-01-05 11:36:32,555 - __main__ - INFO - Debug: True
2026-01-05 11:36:32,555 - __main__ - INFO - ============================================================
2026-01-05 11:36:32,556 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:36:32,570 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:36:32,574 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:36:32,702 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:36:32,719 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:36:43,825 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:36:43,825 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:36:43,827 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:43] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-05 11:36:44,389 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-05 11:36:44,391 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:44] "POST /auth/login HTTP/1.1" 200 -
2026-01-05 11:36:44,447 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:44] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 11:36:44,756 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:44] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 11:36:44,759 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:44] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 11:36:44,761 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:44] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 11:36:44,772 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:44] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:36:45,074 - routes.chat_routes - INFO - [OK] Created new chat 0c8471bf-bde0-46ea-8c0c-3b2d218fab3e for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:36:45,076 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:45] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:36:45,087 - routes.chat_routes - INFO - [OK] Created new chat 8f5ea235-5da3-4df7-8996-5936f1b820a7 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:36:45,092 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:45] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:36:45,093 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:45] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:36:47,808 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:36:47] "OPTIONS /chat/stream HTTP/1.1" 200 -
2026-01-05 11:37:28,688 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:28] "OPTIONS /chat/ask HTTP/1.1" 200 -
2026-01-05 11:37:29,064 - routes.chat_routes - INFO - [OK] Created new chat fa8a0850-c166-482e-a8d8-8e0e064ea421 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:37:29,065 - routes.chat_routes - INFO - [OK] Created new chat bf27caa2-f332-4ebf-b50f-d9b88e48375b for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:37:29,067 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:29] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:37:29,069 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:29] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:37:29,075 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:37:29,314 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:37:29,796 - routes.chat_routes - INFO - [OK] Created new chat 9ed8b403-6d1d-4913-80ed-2bfdd1dd55bc for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:37:29,797 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:29] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:37:30,101 - routes.chat_routes - INFO - [OK] Created new chat afba34cf-8f66-46ce-be8d-6c670ac7860b for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:37:30,102 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:30] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:37:30,103 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:37:30,426 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:30] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:37:56,445 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:56] "OPTIONS /chat/delete/4156501a-1568-4bf0-a0fc-2c2fb0fc22b0 HTTP/1.1" 200 -
2026-01-05 11:37:56,759 - routes.chat_routes - INFO - Deleted chat 4156501a-1568-4bf0-a0fc-2c2fb0fc22b0 for user 6958bd2f226bdd90f9c905fb
2026-01-05 11:37:56,759 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:56] "DELETE /chat/delete/4156501a-1568-4bf0-a0fc-2c2fb0fc22b0 HTTP/1.1" 200 -
2026-01-05 11:37:58,977 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:58] "OPTIONS /chat/delete/f5be5415-5e64-460e-98fa-1d5933666c6f HTTP/1.1" 200 -
2026-01-05 11:37:59,303 - routes.chat_routes - INFO - Deleted chat f5be5415-5e64-460e-98fa-1d5933666c6f for user 6958bd2f226bdd90f9c905fb
2026-01-05 11:37:59,304 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:37:59] "DELETE /chat/delete/f5be5415-5e64-460e-98fa-1d5933666c6f HTTP/1.1" 200 -
2026-01-05 11:38:01,130 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:38:01] "OPTIONS /chat/delete/6754b74b-800c-4360-9c29-22b9ab14aa5c HTTP/1.1" 200 -
2026-01-05 11:38:01,440 - routes.chat_routes - INFO - Deleted chat 6754b74b-800c-4360-9c29-22b9ab14aa5c for user 6958bd2f226bdd90f9c905fb
2026-01-05 11:38:01,441 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:38:01] "DELETE /chat/delete/6754b74b-800c-4360-9c29-22b9ab14aa5c HTTP/1.1" 200 -
2026-01-05 11:39:49,573 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:39:49,573 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:39:49,575 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:39:49,575 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:39:49,576 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:39:49,576 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:40:02,620 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:40:02,646 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:40:16,524 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:40:16,525 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:40:16,533 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:40:16,533 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:40:16,534 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:40:16,533 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:40:16,535 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:40:16,533 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:40:16,536 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:40:16,534 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:40:16,535 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:40:16,534 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:40:16,544 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:40:16,548 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:40:16,553 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:40:16,564 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:40:16,566 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:40:16,569 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:40:16,569 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:40:16,571 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:40:21,949 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:40:21,967 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:40:21,968 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:40:22,014 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:40:22,016 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:40:22,021 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:40:22,025 - services.rag_service - WARNING - Models not loaded for context retrieval
2026-01-05 11:40:22,027 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:40:22,028 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:40:22,031 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:40:22,040 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:40:22,040 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:40:22,108 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:40:22,108 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 5.57s - Ready for inference
2026-01-05 11:40:22,108 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:40:22,143 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:40:22,206 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:40:22,207 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 5.68s - Ready for inference
2026-01-05 11:40:22,207 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:40:22,231 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 11:40:22,244 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:40:22,280 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:40:22,335 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:40:22,336 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 5.80s - Ready for inference
2026-01-05 11:40:22,336 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:40:22,827 - services.rag_service - ERROR - Error generating answer: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2026-01-05 11:40:22,833 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 356, in generate_answer
    response = gemini_model.generate_content(prompt)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.NotFound: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.

2026-01-05 11:40:22,834 - __main__ - INFO - [OK] Model warmup complete - Test response: Error processing question. Please try again....
2026-01-05 11:40:22,834 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:40:22,842 - services.rag_service - ERROR - Error streaming answer: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2026-01-05 11:40:22,843 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:40:22] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:40:22,881 - services.rag_service - ERROR - Error generating answer: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2026-01-05 11:40:22,887 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 356, in generate_answer
    response = gemini_model.generate_content(prompt)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.NotFound: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.

2026-01-05 11:40:22,889 - __main__ - INFO - [OK] Model warmup complete - Test response: Error processing question. Please try again....
2026-01-05 11:40:22,889 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:40:26,033 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:40:26,071 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:40:26,123 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:40:26,123 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 4.10s - Ready for inference
2026-01-05 11:40:26,231 - services.rag_service - ERROR - Error streaming answer: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.
2026-01-05 11:40:26,232 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:40:26] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:41:29,372 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:41:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:41:29,375 - routes.chat_routes - INFO - [OK] Created new chat 44ac24b6-4050-4141-9134-4511f6c919b0 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:41:29,377 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:41:29] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:41:29,380 - routes.chat_routes - INFO - [OK] Created new chat 8d5e21e7-9db1-4e22-a2e9-a75c3d248004 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:41:29,381 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:41:29] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:41:29,623 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:41:29] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:42:12,127 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\config.py', reloading
2026-01-05 11:42:12,130 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\config.py', reloading
2026-01-05 11:42:16,555 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:42:17,066 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:42:17,066 - __main__ - INFO - CORS enabled
2026-01-05 11:42:17,066 - __main__ - INFO - JWT initialized
2026-01-05 11:42:17,069 - __main__ - INFO - Blueprints registered
2026-01-05 11:42:17,070 - __main__ - INFO - ============================================================
2026-01-05 11:42:17,070 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:42:17,070 - __main__ - INFO - ============================================================
2026-01-05 11:42:17,070 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:42:17,070 - __main__ - INFO - Port: 5000
2026-01-05 11:42:17,071 - __main__ - INFO - Debug: True
2026-01-05 11:42:17,071 - __main__ - INFO - ============================================================
2026-01-05 11:42:17,071 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:42:17,082 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:42:17,086 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:42:17,299 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:42:17,330 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:42:22,314 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:42:22,314 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:42:22,317 - routes.chat_routes - INFO - [OK] Created new chat 9ae9a58c-81c4-4e1e-8479-ab54db58fd3a for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:42:22,320 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:42:22] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:42:22,321 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:42:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:42:22,323 - routes.chat_routes - INFO - [OK] Created new chat a42ede36-9ad3-4866-b887-e2be7e83ff12 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:42:22,326 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:42:22] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:42:22,584 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:42:22] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:42:30,640 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:42:31,051 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:42:31,053 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:42:31,054 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:42:31,812 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:42:31,812 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:42:31,812 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:42:31,812 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:42:31,812 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:42:31,813 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:42:31,818 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:42:31,818 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:42:31,820 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:42:31,820 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:42:31,820 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:42:31,820 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:42:36,158 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:42:36,165 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 5 more times]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:42:36,171 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:42:36,188 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:42:36,193 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:42:36,197 - services.rag_service - WARNING - Models not loaded for context retrieval
2026-01-05 11:42:36,199 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:42:36,200 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:42:36,208 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:42:36,208 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:42:36,429 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:42:36,430 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:42:36,431 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:42:39,933 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:42:39,935 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:42:39,938 - services.rag_service - ERROR - Failed to load models
2026-01-05 11:42:39,938 - routes.chat_routes - ERROR - Streaming error: Model not available. Please try again.
2026-01-05 11:42:39,940 - routes.chat_routes - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\routes\chat_routes.py", line 426, in generate
    for chunk in stream_answer(prompt, max_tokens=150):
                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 384, in stream_answer
    raise RuntimeError("Model not available. Please try again.")
RuntimeError: Model not available. Please try again.

2026-01-05 11:42:39,940 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:42:39] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:46:03,244 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 11:46:03,245 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 11:46:03,245 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 11:46:04,728 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:46:05,132 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:46:05,132 - __main__ - INFO - CORS enabled
2026-01-05 11:46:05,132 - __main__ - INFO - JWT initialized
2026-01-05 11:46:05,135 - __main__ - INFO - Blueprints registered
2026-01-05 11:46:05,136 - __main__ - INFO - ============================================================
2026-01-05 11:46:05,136 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:46:05,136 - __main__ - INFO - ============================================================
2026-01-05 11:46:05,136 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:46:05,137 - __main__ - INFO - Port: 5000
2026-01-05 11:46:05,137 - __main__ - INFO - Debug: True
2026-01-05 11:46:05,137 - __main__ - INFO - ============================================================
2026-01-05 11:46:05,137 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:46:05,149 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:46:05,154 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:46:05,265 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:46:05,278 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:46:10,452 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 11:46:10,453 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 11:46:11,939 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:46:12,365 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:46:12,366 - __main__ - INFO - CORS enabled
2026-01-05 11:46:12,366 - __main__ - INFO - JWT initialized
2026-01-05 11:46:12,369 - __main__ - INFO - Blueprints registered
2026-01-05 11:46:12,370 - __main__ - INFO - ============================================================
2026-01-05 11:46:12,370 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:46:12,370 - __main__ - INFO - ============================================================
2026-01-05 11:46:12,370 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:46:12,371 - __main__ - INFO - Port: 5000
2026-01-05 11:46:12,371 - __main__ - INFO - Debug: True
2026-01-05 11:46:12,371 - __main__ - INFO - ============================================================
2026-01-05 11:46:12,371 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:46:12,382 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:46:12,387 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:46:12,493 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:46:12,509 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:46:20,780 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 11:46:20,799 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 11:46:21,760 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:46:22,179 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:46:22,180 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:46:22,181 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:46:23,021 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:46:23,021 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:46:23,027 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:46:23,027 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:46:24,590 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:46:24,967 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:46:24,967 - __main__ - INFO - CORS enabled
2026-01-05 11:46:24,967 - __main__ - INFO - JWT initialized
2026-01-05 11:46:24,971 - __main__ - INFO - Blueprints registered
2026-01-05 11:46:24,972 - __main__ - INFO - ============================================================
2026-01-05 11:46:24,972 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:46:24,972 - __main__ - INFO - ============================================================
2026-01-05 11:46:24,973 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:46:24,973 - __main__ - INFO - Port: 5000
2026-01-05 11:46:24,973 - __main__ - INFO - Debug: True
2026-01-05 11:46:24,973 - __main__ - INFO - ============================================================
2026-01-05 11:46:24,973 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:46:24,984 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:46:24,990 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:46:25,101 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:46:25,115 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:46:28,796 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\app.py', reloading
2026-01-05 11:46:28,797 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\app.py', reloading
2026-01-05 11:46:30,057 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:46:30,545 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:46:30,545 - __main__ - INFO - CORS enabled
2026-01-05 11:46:30,545 - __main__ - INFO - JWT initialized
2026-01-05 11:46:30,549 - __main__ - INFO - Blueprints registered
2026-01-05 11:46:30,549 - __main__ - INFO - ============================================================
2026-01-05 11:46:30,550 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:46:30,550 - __main__ - INFO - ============================================================
2026-01-05 11:46:30,550 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:46:30,550 - __main__ - INFO - Port: 5000
2026-01-05 11:46:30,550 - __main__ - INFO - Debug: True
2026-01-05 11:46:30,550 - __main__ - INFO - ============================================================
2026-01-05 11:46:30,551 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:46:30,561 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:46:30,567 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:46:30,681 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:46:30,711 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:46:39,318 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:46:39,722 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:46:39,723 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:46:39,724 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:46:40,510 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:46:40,511 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:46:40,514 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:46:40,514 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:46:42,120 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 11:46:42,121 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 11:46:42,121 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 11:46:44,783 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:46:45,149 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:46:45,149 - __main__ - INFO - CORS enabled
2026-01-05 11:46:45,149 - __main__ - INFO - JWT initialized
2026-01-05 11:46:45,152 - __main__ - INFO - Blueprints registered
2026-01-05 11:46:45,153 - __main__ - INFO - ============================================================
2026-01-05 11:46:45,153 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:46:45,153 - __main__ - INFO - ============================================================
2026-01-05 11:46:45,153 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:46:45,153 - __main__ - INFO - Port: 5000
2026-01-05 11:46:45,153 - __main__ - INFO - Debug: True
2026-01-05 11:46:45,154 - __main__ - INFO - ============================================================
2026-01-05 11:46:45,154 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:46:45,167 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:46:45,173 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:46:45,276 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:46:45,289 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:46:53,791 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:46:54,191 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:46:54,193 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:46:54,194 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:46:54,956 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:46:54,956 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:46:54,959 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:46:54,960 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:46:58,852 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:46:58,880 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:46:58,912 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:46:58,912 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 3.96s - Ready for inference
2026-01-05 11:46:58,912 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:46:59,212 - services.rag_service - WARNING - Rate limit hit: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 18.857642851s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 18
}
]
2026-01-05 11:46:59,214 - __main__ - INFO - [OK] Model warmup complete - Test response: The service is temporarily busy. Please try again ...
2026-01-05 11:46:59,215 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:47:10,953 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:47:10,953 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:47:10,954 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:47:11,009 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 11:47:11,096 - services.rag_service - WARNING - Rate limit hit: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 6.962846135s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 6
}
]
2026-01-05 11:47:11,096 - __main__ - INFO - [OK] Model warmup complete - Test response: The service is temporarily busy. Please try again ...
2026-01-05 11:47:11,096 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:47:11,286 - services.rag_service - ERROR - Error streaming answer: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 6.774079071s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 6
}
]
2026-01-05 11:47:11,287 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:47:11] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:47:37,856 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 11:47:38,029 - services.rag_service - ERROR - Error streaming answer: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
Please retry in 40.035101119s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 40
}
]
2026-01-05 11:47:38,030 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:47:38] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:49:58,079 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:49:58,080 - __main__ - INFO - CORS enabled
2026-01-05 11:49:58,080 - __main__ - INFO - JWT initialized
2026-01-05 11:49:58,083 - __main__ - INFO - Blueprints registered
2026-01-05 11:49:58,084 - __main__ - INFO - ============================================================
2026-01-05 11:49:58,084 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:49:58,084 - __main__ - INFO - ============================================================
2026-01-05 11:49:58,084 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:49:58,085 - __main__ - INFO - Port: 5000
2026-01-05 11:49:58,085 - __main__ - INFO - Debug: True
2026-01-05 11:49:58,085 - __main__ - INFO - ============================================================
2026-01-05 11:49:58,086 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:49:58,123 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 11:49:58,123 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 11:49:58,127 - werkzeug - INFO -  * Restarting with stat
2026-01-05 11:49:58,239 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:49:58,255 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:49:58,524 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:49:58,525 - __main__ - INFO - CORS enabled
2026-01-05 11:49:58,525 - __main__ - INFO - JWT initialized
2026-01-05 11:49:58,528 - __main__ - INFO - Blueprints registered
2026-01-05 11:49:58,529 - __main__ - INFO - ============================================================
2026-01-05 11:49:58,529 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:49:58,529 - __main__ - INFO - ============================================================
2026-01-05 11:49:58,529 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:49:58,530 - __main__ - INFO - Port: 5000
2026-01-05 11:49:58,530 - __main__ - INFO - Debug: True
2026-01-05 11:49:58,530 - __main__ - INFO - ============================================================
2026-01-05 11:49:58,530 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:49:58,561 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:49:58,566 - werkzeug - INFO -  * Debugger PIN: 101-352-286
2026-01-05 11:49:58,667 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:49:58,683 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:50:11,261 - services.rag_service - ERROR - Failed to load models: No module named 'google'
2026-01-05 11:50:11,261 - services.rag_service - ERROR - Failed to load models: No module named 'google'
2026-01-05 11:50:11,262 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 49, in _load_models
    import google.generativeai as genai
ModuleNotFoundError: No module named 'google'

2026-01-05 11:50:11,263 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:50:11,263 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 49, in _load_models
    import google.generativeai as genai
ModuleNotFoundError: No module named 'google'

2026-01-05 11:50:11,263 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:50:13,796 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:50:13,796 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:50:13,798 - services.rag_service - ERROR - Failed to load models: No module named 'google'
2026-01-05 11:50:13,801 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 49, in _load_models
    import google.generativeai as genai
ModuleNotFoundError: No module named 'google'

2026-01-05 11:50:13,814 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:50:14,060 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-05 11:50:14,062 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:50:14] "POST /auth/login HTTP/1.1" 200 -
2026-01-05 11:50:14,082 - routes.chat_routes - INFO - [OK] Created new chat 90a3ce4b-56c6-4840-a230-0cc1c279ec23 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:50:14,084 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:50:14] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:50:14,392 - routes.chat_routes - INFO - [OK] Created new chat 9df8667b-a5b0-42ea-86a4-6b2b3c17db9a for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 11:50:14,393 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:50:14] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 11:50:14,394 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:50:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:50:14,704 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:50:14] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 11:50:16,803 - services.rag_service - ERROR - Failed to load models: No module named 'google'
2026-01-05 11:50:16,805 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 49, in _load_models
    import google.generativeai as genai
ModuleNotFoundError: No module named 'google'

2026-01-05 11:50:16,806 - services.rag_service - WARNING - Models not loaded for context retrieval
2026-01-05 11:50:16,808 - services.rag_service - ERROR - Failed to load models: No module named 'google'
2026-01-05 11:50:16,812 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 49, in _load_models
    import google.generativeai as genai
ModuleNotFoundError: No module named 'google'

2026-01-05 11:50:16,813 - services.rag_service - ERROR - Failed to load models
2026-01-05 11:50:16,814 - routes.chat_routes - ERROR - Streaming error: Model not available. Please try again.
2026-01-05 11:50:16,817 - routes.chat_routes - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\routes\chat_routes.py", line 426, in generate
    for chunk in stream_answer(prompt, max_tokens=150):
                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 548, in stream_answer
    raise RuntimeError("Model not available. Please try again.")
RuntimeError: Model not available. Please try again.

2026-01-05 11:50:16,818 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:50:16] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:52:20,878 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:52:20,879 - __main__ - INFO - CORS enabled
2026-01-05 11:52:20,879 - __main__ - INFO - JWT initialized
2026-01-05 11:52:20,884 - __main__ - INFO - Blueprints registered
2026-01-05 11:52:20,885 - __main__ - INFO - ============================================================
2026-01-05 11:52:20,885 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:52:20,885 - __main__ - INFO - ============================================================
2026-01-05 11:52:20,885 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:52:20,885 - __main__ - INFO - Port: 5000
2026-01-05 11:52:20,885 - __main__ - INFO - Debug: True
2026-01-05 11:52:20,886 - __main__ - INFO - ============================================================
2026-01-05 11:52:20,886 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:52:20,922 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 11:52:20,922 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 11:52:20,940 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:52:21,049 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:52:21,065 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:52:21,342 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:52:21,342 - __main__ - INFO - CORS enabled
2026-01-05 11:52:21,343 - __main__ - INFO - JWT initialized
2026-01-05 11:52:21,345 - __main__ - INFO - Blueprints registered
2026-01-05 11:52:21,346 - __main__ - INFO - ============================================================
2026-01-05 11:52:21,346 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:52:21,346 - __main__ - INFO - ============================================================
2026-01-05 11:52:21,347 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:52:21,347 - __main__ - INFO - Port: 5000
2026-01-05 11:52:21,347 - __main__ - INFO - Debug: True
2026-01-05 11:52:21,347 - __main__ - INFO - ============================================================
2026-01-05 11:52:21,347 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:52:21,360 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:52:21,371 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:52:21,498 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:52:21,512 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:52:28,295 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:52:28,296 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:52:32,213 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:52:32,214 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:52:32,215 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:52:32,216 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:52:32,218 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:52:32,218 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:52:36,239 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:52:36,282 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:52:36,933 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:52:36,934 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:52:36,940 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:52:36,940 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:52:36,951 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:52:36,951 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:52:36,951 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:52:36,952 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:52:36,953 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:52:36,953 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:52:36,972 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:52:36,972 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:52:36,972 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:52:36,974 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:52:36,974 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:52:36,976 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:52:41,913 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:52:41,944 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:52:41,978 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:52:41,978 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 5.04s - Ready for inference
2026-01-05 11:52:41,979 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:52:42,337 - services.rag_service - WARNING - Rate limit hit: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 35.727378701s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 35
}
]
2026-01-05 11:52:42,338 - __main__ - INFO - [OK] Model warmup complete - Test response: The service is temporarily busy. Please try again ...
2026-01-05 11:52:42,338 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:56:30,859 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:56:30,860 - __main__ - INFO - CORS enabled
2026-01-05 11:56:30,860 - __main__ - INFO - JWT initialized
2026-01-05 11:56:30,864 - __main__ - INFO - Blueprints registered
2026-01-05 11:56:30,865 - __main__ - INFO - ============================================================
2026-01-05 11:56:30,865 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:56:30,865 - __main__ - INFO - ============================================================
2026-01-05 11:56:30,865 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:56:30,865 - __main__ - INFO - Port: 5000
2026-01-05 11:56:30,866 - __main__ - INFO - Debug: True
2026-01-05 11:56:30,866 - __main__ - INFO - ============================================================
2026-01-05 11:56:30,866 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:56:30,904 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 11:56:30,905 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 11:56:30,919 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:56:31,024 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:56:31,040 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:56:31,306 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:56:31,306 - __main__ - INFO - CORS enabled
2026-01-05 11:56:31,307 - __main__ - INFO - JWT initialized
2026-01-05 11:56:31,309 - __main__ - INFO - Blueprints registered
2026-01-05 11:56:31,310 - __main__ - INFO - ============================================================
2026-01-05 11:56:31,310 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:56:31,311 - __main__ - INFO - ============================================================
2026-01-05 11:56:31,311 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:56:31,311 - __main__ - INFO - Port: 5000
2026-01-05 11:56:31,311 - __main__ - INFO - Debug: True
2026-01-05 11:56:31,311 - __main__ - INFO - ============================================================
2026-01-05 11:56:31,312 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:56:31,323 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:56:31,327 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:56:31,427 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:56:31,440 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:56:37,809 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:56:37,809 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:56:41,179 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:56:41,180 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:56:41,181 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:56:41,335 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:56:41,336 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:56:41,337 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:56:46,391 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:56:46,761 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:56:47,515 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:56:47,516 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:56:47,521 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:56:47,521 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:56:47,810 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:56:47,810 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:56:47,811 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:56:47,811 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:56:47,810 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:56:47,812 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:56:47,822 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:56:47,822 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:56:47,823 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:56:47,823 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:56:47,824 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:56:47,825 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:56:52,307 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:56:52,310 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 4 more times]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:56:52,312 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:56:52,314 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:56:52,316 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:56:52,318 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:56:52,701 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:56:52,703 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:56:52,705 - services.rag_service - WARNING - Models not loaded for context retrieval
2026-01-05 11:56:52,706 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:56:52,706 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:56:52,711 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:56:52,712 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:56:52,946 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:56:52,995 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:56:53,027 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:56:53,027 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 5.51s - Ready for inference
2026-01-05 11:56:53,027 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:56:53,458 - services.rag_service - WARNING - Rate limit hit: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 24.615490045s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 24
}
]
2026-01-05 11:56:53,458 - __main__ - INFO - [OK] Model warmup complete - Test response: The service is temporarily busy. Please try again ...
2026-01-05 11:56:53,459 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:56:56,615 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:56:56,619 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:56:56,626 - services.rag_service - ERROR - Failed to load models
2026-01-05 11:56:56,626 - routes.chat_routes - ERROR - Streaming error: Model not available. Please try again.
2026-01-05 11:56:56,630 - routes.chat_routes - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\routes\chat_routes.py", line 426, in generate
    for chunk in stream_answer(prompt, max_tokens=150):
                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 548, in stream_answer
    raise RuntimeError("Model not available. Please try again.")
RuntimeError: Model not available. Please try again.

2026-01-05 11:56:56,631 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:56:56] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:58:13,452 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:58:13,452 - __main__ - INFO - CORS enabled
2026-01-05 11:58:13,452 - __main__ - INFO - JWT initialized
2026-01-05 11:58:13,455 - __main__ - INFO - Blueprints registered
2026-01-05 11:58:13,456 - __main__ - INFO - ============================================================
2026-01-05 11:58:13,456 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:58:13,457 - __main__ - INFO - ============================================================
2026-01-05 11:58:13,457 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:58:13,457 - __main__ - INFO - Port: 5000
2026-01-05 11:58:13,457 - __main__ - INFO - Debug: True
2026-01-05 11:58:13,457 - __main__ - INFO - ============================================================
2026-01-05 11:58:13,458 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:58:13,489 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 11:58:13,489 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 11:58:13,499 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 11:58:13,597 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:58:13,618 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:58:13,949 - __main__ - INFO - Configuration loaded: Config
2026-01-05 11:58:13,950 - __main__ - INFO - CORS enabled
2026-01-05 11:58:13,950 - __main__ - INFO - JWT initialized
2026-01-05 11:58:13,953 - __main__ - INFO - Blueprints registered
2026-01-05 11:58:13,953 - __main__ - INFO - ============================================================
2026-01-05 11:58:13,954 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 11:58:13,954 - __main__ - INFO - ============================================================
2026-01-05 11:58:13,954 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 11:58:13,954 - __main__ - INFO - Port: 5000
2026-01-05 11:58:13,954 - __main__ - INFO - Debug: True
2026-01-05 11:58:13,954 - __main__ - INFO - ============================================================
2026-01-05 11:58:13,955 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:58:13,966 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 11:58:13,970 - werkzeug - INFO -  * Debugger PIN: 796-598-797
2026-01-05 11:58:14,082 - faiss.loader - INFO - Loading faiss with AVX2 support.
2026-01-05 11:58:14,096 - faiss.loader - INFO - Successfully loaded faiss with AVX2 support.
2026-01-05 11:58:19,383 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 11:58:19,383 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 11:58:25,771 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:58:25,772 - datasets - INFO - PyTorch version 2.9.1 available.
2026-01-05 11:58:25,773 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:58:25,773 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:58:25,774 - datasets - INFO - Polars version 1.36.1 available.
2026-01-05 11:58:25,774 - datasets - INFO - TensorFlow version 2.20.0 available.
2026-01-05 11:58:29,199 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:58:29,343 - tensorflow - WARNING - From C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\tf_keras\src\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.

2026-01-05 11:58:29,686 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:58:29,686 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:58:29,689 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:58:29,689 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:58:29,796 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:58:29,797 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:58:29,797 - services.rag_service - INFO - [LOADING] Loading models and initializing Gemini API...
2026-01-05 11:58:29,797 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:58:29,797 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:58:29,798 - services.rag_service - INFO - [OK] Gemini API initialized successfully
2026-01-05 11:58:29,802 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:58:29,803 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:58:29,804 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:58:29,805 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:58:29,807 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device_name: cpu
2026-01-05 11:58:29,808 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2
2026-01-05 11:58:34,638 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:58:34,638 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:58:34,640 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:58:34,643 - __main__ - WARNING - [WARN] Model warmup failed - models will load on first request
2026-01-05 11:58:34,660 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:58:34,691 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:58:34,691 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 4.89s - Ready for inference
2026-01-05 11:58:34,691 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:58:34,834 - services.rag_service - ERROR - Failed to load models: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.
2026-01-05 11:58:34,838 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 81, in _load_models
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\sentence_transformers\SentenceTransformer.py", line 367, in __init__
    self.to(device)
    ~~~~~~~^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1371, in to
    return self._apply(convert)
           ~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 930, in _apply
    module._apply(fn)
    ~~~~~~~~~~~~~^^^^
  [Previous line repeated 1 more time]
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 957, in _apply
    param_applied = fn(param)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\torch\nn\modules\module.py", line 1364, in convert
    raise NotImplementedError(
    ...<2 lines>...
    ) from None
NotImplementedError: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.

2026-01-05 11:58:34,843 - services.rag_service - WARNING - Models not loaded for context retrieval
2026-01-05 11:58:34,914 - services.rag_service - INFO - [OK] Embedder loaded successfully
2026-01-05 11:58:34,944 - services.rag_service - INFO - [OK] FAISS index loaded successfully
2026-01-05 11:58:34,989 - services.rag_service - INFO - [OK] Loaded 15419 documents
2026-01-05 11:58:34,989 - services.rag_service - INFO - [OK] ALL MODELS LOADED in 5.30s - Ready for inference
2026-01-05 11:58:34,989 - __main__ - INFO - [OK] Models loaded successfully
2026-01-05 11:58:35,045 - services.rag_service - ERROR - Error streaming answer: 400 API key expired. Please renew the API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key expired. Please renew the API key."
]
2026-01-05 11:58:35,046 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 11:58:35] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 11:58:35,205 - services.rag_service - ERROR - Error generating answer: 400 API key expired. Please renew the API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key expired. Please renew the API key."
]
2026-01-05 11:58:35,223 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 507, in generate_answer
    response = gemini_model.generate_content(
        prompt,
    ...<5 lines>...
        }
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 API key expired. Please renew the API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key expired. Please renew the API key."
]

2026-01-05 11:58:35,224 - __main__ - INFO - [OK] Model warmup complete - Test response: Error processing question. Please try again....
2026-01-05 11:58:35,225 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 11:58:35,319 - services.rag_service - ERROR - Error generating answer: 400 API key expired. Please renew the API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key expired. Please renew the API key."
]
2026-01-05 11:58:35,328 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 507, in generate_answer
    response = gemini_model.generate_content(
        prompt,
    ...<5 lines>...
        }
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.InvalidArgument: 400 API key expired. Please renew the API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key expired. Please renew the API key."
]

2026-01-05 11:58:35,330 - __main__ - INFO - [OK] Model warmup complete - Test response: Error processing question. Please try again....
2026-01-05 11:58:35,330 - __main__ - INFO - [READY] Server is ready for FAST responses!
2026-01-05 12:03:18,775 - services.rag_service - ERROR - Error retrieving context: 
2026-01-05 12:03:19,057 - services.rag_service - ERROR - Error streaming answer: 400 API key expired. Please renew the API key. [reason: "API_KEY_INVALID"
domain: "googleapis.com"
metadata {
  key: "service"
  value: "generativelanguage.googleapis.com"
}
, locale: "en-US"
message: "API key expired. Please renew the API key."
]
2026-01-05 12:03:19,058 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:03:19] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 12:32:30,506 - __main__ - INFO - Configuration loaded: Config
2026-01-05 12:32:30,507 - __main__ - INFO - CORS enabled
2026-01-05 12:32:30,507 - __main__ - INFO - JWT initialized
2026-01-05 12:32:30,510 - __main__ - INFO - Blueprints registered
2026-01-05 12:32:30,511 - __main__ - INFO - ============================================================
2026-01-05 12:32:30,511 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 12:32:30,512 - __main__ - INFO - ============================================================
2026-01-05 12:32:30,512 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 12:32:30,512 - __main__ - INFO - Port: 5000
2026-01-05 12:32:30,513 - __main__ - INFO - Debug: True
2026-01-05 12:32:30,513 - __main__ - INFO - ============================================================
2026-01-05 12:32:30,513 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 12:32:30,514 - __main__ - ERROR - Model warmup error: cannot import name '_load_models' from 'services.rag_service' (D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py)
2026-01-05 12:32:30,577 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://10.171.86.48:5000
2026-01-05 12:32:30,577 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2026-01-05 12:32:30,672 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 12:32:31,033 - __main__ - INFO - Configuration loaded: Config
2026-01-05 12:32:31,033 - __main__ - INFO - CORS enabled
2026-01-05 12:32:31,033 - __main__ - INFO - JWT initialized
2026-01-05 12:32:31,036 - __main__ - INFO - Blueprints registered
2026-01-05 12:32:31,037 - __main__ - INFO - ============================================================
2026-01-05 12:32:31,037 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 12:32:31,037 - __main__ - INFO - ============================================================
2026-01-05 12:32:31,037 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 12:32:31,037 - __main__ - INFO - Port: 5000
2026-01-05 12:32:31,038 - __main__ - INFO - Debug: True
2026-01-05 12:32:31,038 - __main__ - INFO - ============================================================
2026-01-05 12:32:31,038 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 12:32:31,038 - __main__ - ERROR - Model warmup error: cannot import name '_load_models' from 'services.rag_service' (D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py)
2026-01-05 12:32:31,045 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 12:32:31,051 - werkzeug - INFO -  * Debugger PIN: 120-788-681
2026-01-05 12:33:24,117 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 12:33:24,117 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 12:33:24,118 - __main__ - ERROR - Model warmup error: cannot import name '_load_models' from 'services.rag_service' (D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py)
2026-01-05 12:33:24,121 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:24] "OPTIONS /auth/login HTTP/1.1" 200 -
2026-01-05 12:33:24,716 - routes.auth_routes - INFO - User logged in: prasad8790237@gmail.com
2026-01-05 12:33:24,717 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:24] "POST /auth/login HTTP/1.1" 200 -
2026-01-05 12:33:24,766 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:24] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 12:33:25,069 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:25] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 12:33:25,071 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:25] "OPTIONS /chat/list HTTP/1.1" 200 -
2026-01-05 12:33:25,076 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:25] "OPTIONS /chat/new HTTP/1.1" 200 -
2026-01-05 12:33:25,193 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:25] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 12:33:25,413 - routes.chat_routes - INFO - [OK] Created new chat fa5d9e39-0f84-4eea-92f1-12de06104c50 for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 12:33:25,413 - routes.chat_routes - INFO - [OK] Created new chat 71aab751-199b-4e1a-88cc-8fc5ddd33cfa for user 6958bd2f226bdd90f9c905fb with 0 messages
2026-01-05 12:33:25,414 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:25] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 12:33:25,415 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:25] "[35m[1mPOST /chat/new HTTP/1.1[0m" 201 -
2026-01-05 12:33:25,512 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:25] "GET /chat/list HTTP/1.1" 200 -
2026-01-05 12:33:28,031 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:28] "OPTIONS /chat/stream HTTP/1.1" 200 -
2026-01-05 12:33:28,307 - routes.chat_routes - ERROR - Error in stream endpoint: name 'retrieve_context' is not defined
2026-01-05 12:33:28,309 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:28] "[35m[1mPOST /chat/stream HTTP/1.1[0m" 500 -
2026-01-05 12:33:28,345 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:28] "OPTIONS /chat/ask HTTP/1.1" 200 -
2026-01-05 12:33:46,988 - services.rag_service - INFO - [LOADING] Initializing Google Gemini API...
2026-01-05 12:33:46,988 - services.rag_service - INFO - [OK] Gemini API initialized successfully in 0.00s
2026-01-05 12:33:47,343 - services.rag_service - ERROR - Error generating answer: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 30.556474102s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 30
}
]
2026-01-05 12:33:47,441 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 364, in generate_answer
    response = gemini_model.generate_content(
        prompt,
    ...<5 lines>...
        }
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\generativeai\generative_models.py", line 331, in generate_content
    response = self._client.generate_content(
        request,
        **request_options,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\ai\generativelanguage_v1beta\services\generative_service\client.py", line 835, in generate_content
    response = rpc(
        request,
    ...<2 lines>...
        metadata=metadata,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\gapic_v1\method.py", line 131, in __call__
    return wrapped_func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 294, in retry_wrapped_func
    return retry_target(
        target,
    ...<3 lines>...
        on_error=on_error,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 156, in retry_target
    next_sleep = _retry_error_helper(
        exc,
    ...<6 lines>...
        timeout,
    )
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_base.py", line 214, in _retry_error_helper
    raise final_exc from source_exc
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\retry\retry_unary.py", line 147, in retry_target
    result = target()
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\timeout.py", line 130, in func_with_timeout
    return func(*args, **kwargs)
  File "C:\Users\prasa\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\google\api_core\grpc_helpers.py", line 77, in error_remapped_callable
    raise exceptions.from_grpc_error(exc) from exc
google.api_core.exceptions.ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash
Please retry in 30.556474102s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_input_token_count"
  quota_id: "GenerateContentInputTokensPerModelPerMinute-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerMinutePerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.0-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
}
, retry_delay {
  seconds: 30
}
]

2026-01-05 12:33:47,447 - routes.chat_routes - INFO - Response generated for chat 71aab751-199b-4e1a-88cc-8fc5ddd33cfa (type: medical) in ~medical mode
2026-01-05 12:33:47,448 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:33:47] "POST /chat/ask HTTP/1.1" 200 -
2026-01-05 12:34:40,206 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:34:40,207 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:34:43,439 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 12:34:43,944 - __main__ - INFO - Configuration loaded: Config
2026-01-05 12:34:43,944 - __main__ - INFO - CORS enabled
2026-01-05 12:34:43,944 - __main__ - INFO - JWT initialized
2026-01-05 12:34:43,947 - __main__ - INFO - Blueprints registered
2026-01-05 12:34:43,948 - __main__ - INFO - ============================================================
2026-01-05 12:34:43,948 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 12:34:43,948 - __main__ - INFO - ============================================================
2026-01-05 12:34:43,948 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 12:34:43,948 - __main__ - INFO - Port: 5000
2026-01-05 12:34:43,948 - __main__ - INFO - Debug: True
2026-01-05 12:34:43,949 - __main__ - INFO - ============================================================
2026-01-05 12:34:43,949 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 12:34:43,949 - __main__ - ERROR - Model warmup error: cannot import name '_load_models' from 'services.rag_service' (D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py)
2026-01-05 12:34:43,956 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 12:34:43,961 - werkzeug - INFO -  * Debugger PIN: 120-788-681
2026-01-05 12:34:48,624 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 12:34:48,625 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 12:34:48,625 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 12:34:49,644 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 12:34:50,064 - __main__ - INFO - Configuration loaded: Config
2026-01-05 12:34:50,064 - __main__ - INFO - CORS enabled
2026-01-05 12:34:50,065 - __main__ - INFO - JWT initialized
2026-01-05 12:34:50,068 - __main__ - INFO - Blueprints registered
2026-01-05 12:34:50,069 - __main__ - INFO - ============================================================
2026-01-05 12:34:50,069 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 12:34:50,070 - __main__ - INFO - ============================================================
2026-01-05 12:34:50,070 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 12:34:50,070 - __main__ - INFO - Port: 5000
2026-01-05 12:34:50,070 - __main__ - INFO - Debug: True
2026-01-05 12:34:50,071 - __main__ - INFO - ============================================================
2026-01-05 12:34:50,071 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 12:34:50,071 - __main__ - ERROR - Model warmup error: cannot import name '_load_models' from 'services.rag_service' (D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py)
2026-01-05 12:34:50,079 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 12:34:50,085 - werkzeug - INFO -  * Debugger PIN: 120-788-681
2026-01-05 12:35:36,903 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 12:35:36,903 - __main__ - INFO - [INFO] Model warmup thread started
2026-01-05 12:35:36,903 - __main__ - ERROR - Model warmup error: cannot import name '_load_models' from 'services.rag_service' (D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py)
2026-01-05 12:35:36,909 - services.rag_service - ERROR - Failed to initialize Gemini API: No module named 'google.genai'
2026-01-05 12:35:36,911 - services.rag_service - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 24, in _load_gemini
    import google.genai as genai
ModuleNotFoundError: No module named 'google.genai'

2026-01-05 12:35:36,913 - services.rag_service - ERROR - Failed to load Gemini model
2026-01-05 12:35:36,914 - routes.chat_routes - ERROR - Streaming error: Model not available. Please try again.
2026-01-05 12:35:36,924 - routes.chat_routes - ERROR - Traceback (most recent call last):
  File "D:\OneDrive\Desktop\Final Year Project\Backend\routes\chat_routes.py", line 449, in generate
    for chunk in stream_answer(full_prompt, max_tokens=150):
                 ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py", line 438, in stream_answer
    raise RuntimeError("Model not available. Please try again.")
RuntimeError: Model not available. Please try again.

2026-01-05 12:35:36,926 - werkzeug - INFO - 127.0.0.1 - - [05/Jan/2026 12:35:36] "POST /chat/stream HTTP/1.1" 200 -
2026-01-05 12:38:06,455 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:38:06,455 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 12:38:06,455 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\routes\\chat_routes.py', reloading
2026-01-05 12:38:06,456 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:38:07,324 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
2026-01-05 12:38:07,758 - __main__ - INFO - Configuration loaded: Config
2026-01-05 12:38:07,758 - __main__ - INFO - CORS enabled
2026-01-05 12:38:07,759 - __main__ - INFO - JWT initialized
2026-01-05 12:38:07,762 - __main__ - INFO - Blueprints registered
2026-01-05 12:38:07,763 - __main__ - INFO - ============================================================
2026-01-05 12:38:07,763 - __main__ - INFO - Starting Medical Chatbot API Server
2026-01-05 12:38:07,763 - __main__ - INFO - ============================================================
2026-01-05 12:38:07,763 - __main__ - INFO - Host: 0.0.0.0
2026-01-05 12:38:07,763 - __main__ - INFO - Port: 5000
2026-01-05 12:38:07,764 - __main__ - INFO - Debug: True
2026-01-05 12:38:07,764 - __main__ - INFO - ============================================================
2026-01-05 12:38:07,764 - __main__ - INFO - [WARMUP] Starting model warmup in background...
2026-01-05 12:38:07,765 - __main__ - ERROR - Model warmup error: cannot import name '_load_models' from 'services.rag_service' (D:\OneDrive\Desktop\Final Year Project\Backend\services\rag_service.py)
2026-01-05 12:38:07,772 - werkzeug - WARNING -  * Debugger is active!
2026-01-05 12:38:07,777 - werkzeug - INFO -  * Debugger PIN: 120-788-681
2026-01-05 12:39:51,041 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:39:51,043 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:39:51,043 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:39:51,043 - werkzeug - INFO -  * Detected change in 'D:\\OneDrive\\Desktop\\Final Year Project\\Backend\\services\\rag_service.py', reloading
2026-01-05 12:39:51,963 - werkzeug - INFO -  * Restarting with watchdog (windowsapi)
